{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ, getcwd\n",
    "import sys\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Neural Net imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Import utils functions\n",
    "curr_dir = !pwd\n",
    "\n",
    "sys.path.append(curr_dir[0]+\"/utils\")\n",
    "from prop_threshold_funcs import create_negatives_datasets_combined, create_positives_datasets_combined\n",
    "from prediction_general_funcs import ligands, score_cols_suffix, get_features_cols, remove_unimportant_features\n",
    "from CV_funcs import add_domain_name_from_table_idx, calc_CV_idx_iterative\n",
    "from generate_hyperparameter_trials import *\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples positions #: 42535\n"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"31\"\n",
    "datafile_date = \"06.20.18\"\n",
    "input_path = curr_dir[0]+\"/domains_similarity/filtered_features_table/\"\n",
    "filename = \"windowed_positions_features_mediode_filter_\"+datafile_date+\".csv\"\n",
    "out_dir = \"mediode_NegLigand_NoFilter\"\n",
    "\n",
    "#flags for creating negatives\n",
    "zero_prop = True\n",
    "no_prop = True\n",
    "all_ligands = False\n",
    "prec_th_str = \"dna0.5_rna0.25_ion0.75\"\n",
    "folds_num = 5\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "#Features columns names, without the labels (the binding scores)\n",
    "features_cols = get_features_cols(features_all)\n",
    "remove_unimportant_features(features_all, features_cols)\n",
    "\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#CV splits dictionary\n",
    "# with open(curr_dir[0]+\"/CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_\"+str(prec_th)+\"_prec_dict.pik\", 'rb') as handle:\n",
    "#         splits_dict = pickle.load(handle)\n",
    "with open(curr_dir[0]+\"/CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_combined_\"+prec_th_str+\"_prec_dict.pik\", 'rb') as handle:\n",
    "        splits_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:41680\n",
      "dnabase non-binding #:42089\n",
      "dnabackbone non-binding #:41689\n",
      "dna combined non binding #: 41555\n",
      "rna non-binding #:41613\n",
      "rnabase non-binding #:41828\n",
      "rnabackbone non-binding #:41619\n",
      "rna combined non binding #: 41401\n",
      "peptide non-binding #:38794\n",
      "ion non-binding #:37525\n",
      "metabolite non-binding #:37463\n",
      "sm non-binding #:30978\n"
     ]
    }
   ],
   "source": [
    "ligands_negatives_df = create_negatives_datasets_combined(zero_prop, no_prop, features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 239\n",
      "dnabase #: 170\n",
      "dnabackbone #: 244\n",
      "dna combined #: 353\n",
      "rna #: 360\n",
      "rnabase #: 246\n",
      "rnabackbone #: 346\n",
      "rna combined #: 468\n",
      "peptide #: 462\n",
      "ion #: 350\n",
      "metabolite #: 504\n",
      "sm #: 708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madhumithashridharan/anaconda/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "ligands_positives_df = create_positives_datasets_combined(features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dna\n",
      "fold = 1\n",
      "classifier_method = XGB\n",
      "trial idx = 0\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dna\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    fold = environ['fold']\n",
    "except:\n",
    "    fold = \"1\"\n",
    "print \"fold = \"+fold\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"XGB\"\n",
    "print \"classifier_method = \"+classifier_method\n",
    "\n",
    "# Reading the index to generate model\n",
    "try:\n",
    "    trial_idx = int(environ[\"trial\"])\n",
    "except:\n",
    "    trial_idx = 0\n",
    "print \"trial idx = \"+ str(trial_idx)\n",
    "\n",
    "if classifier_method == \"NN\":\n",
    "    try:\n",
    "        learning_rate_ub = int(environ['learning_rate_ub'])\n",
    "        learning_rate_lb = int(environ['learning_rate_lb'])\n",
    "        batch_size_ub = int(environ['batch_size_ub'])\n",
    "        batch_size_lb = int(environ['batch_size_lb'])\n",
    "        weight_decay_ub = int(environ['weight_decay_ub'])\n",
    "        weight_decay_lb = int(environ['weight_decay_lb'])\n",
    "        beta_ub = float(environ['beta_ub'])\n",
    "        beta_lb = float(environ['beta_lb'])\n",
    "        hidden_units_1_ub = int(environ['hidden_units_1_ub'])\n",
    "        hidden_units_1_lb = int(environ['hidden_units_1_lb'])\n",
    "        hidden_units_2_ub = int(environ['hidden_units_2_ub'])\n",
    "        hidden_units_2_lb = int(environ['hidden_units_2_lb'])\n",
    "\n",
    "    except:\n",
    "        learning_rate_ub = -2\n",
    "        learning_rate_lb = -3\n",
    "        batch_size_ub = 150\n",
    "        batch_size_lb = 30\n",
    "        weight_decay_ub = -7\n",
    "        weight_decay_lb = -17\n",
    "        beta_ub = 0.95\n",
    "        beta_lb = 0.85\n",
    "        hidden_units_1_ub = 300\n",
    "        hidden_units_1_lb = 50\n",
    "        hidden_units_2_ub = 800\n",
    "        hidden_units_2_lb = 350\n",
    "    \n",
    "\n",
    "elif classifier_method == \"XGB\":\n",
    "    try:\n",
    "        n_estimators_ub =int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb =int(environ[\"n_estimators_lb\"])\n",
    "        max_depth_ub = int(environ[\"max_depth_ub\"])\n",
    "        max_depth_lb = int(environ[\"max_depth_lb\"])\n",
    "        min_child_weight_ub = int(environ[\"min_child_weight_ub\"])\n",
    "        min_child_weight_lb = int(environ[\"min_child_weight_lb\"])\n",
    "        colsample_bytree_ub = float(environ[\"colsample_bytree_ub\"])\n",
    "        colsample_bytree_lb = float(environ[\"colsample_bytree_lb\"])\n",
    "        gamma_ub = int(environ[\"gamma_ub\"])\n",
    "        gamma_lb = int(environ[\"gamma_lb\"])\n",
    "        learning_rate_ub = int(environ[\"learning_rate_ub\"])\n",
    "        learning_rate_lb = int(environ[\"learning_rate_lb\"])\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        n_estimators_ub = 1500\n",
    "        n_estimators_lb = 100\n",
    "        max_depth_ub = 1500\n",
    "        max_depth_lb = 100\n",
    "        min_child_weight_ub = 2\n",
    "        min_child_weight_lb = 0\n",
    "        colsample_bytree_ub = 1\n",
    "        colsample_bytree_lb = 0.25\n",
    "        gamma_ub = 0\n",
    "        gamma_lb = -3\n",
    "        learning_rate_ub = 0\n",
    "        learning_rate_lb = -1\n",
    "        \n",
    "elif classifier_method == \"RF\":\n",
    "    try:\n",
    "        n_estimators_ub = int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb = int(environ[\"n_estimators_lb\"])\n",
    "        max_depth_ub = int(environ[\"max_depth_ub\"])\n",
    "        max_depth_lb = int(environ[\"max_depth_lb\"])\n",
    "        min_samples_leaf_ub = int(environ[\"min_samples_leaf_ub\"])\n",
    "        min_samples_leaf_lb = int(environ[\"min_samples_leaf_lb\"])\n",
    "        min_samples_split_ub = int(environ[\"min_samples_split_ub\"])\n",
    "        min_samples_split_lb = int(environ[\"min_samples_split_lb\"])\n",
    "    except:\n",
    "        n_estimators_ub = 5\n",
    "        n_estimators_lb = 2\n",
    "        max_depth_ub = 20\n",
    "        max_depth_lb = 2\n",
    "        min_samples_leaf_ub = 50\n",
    "        min_samples_leaf_lb = 1\n",
    "        min_samples_split_ub = 50\n",
    "        min_samples_split_lb = 1\n",
    "\n",
    "elif classifier_method == \"Logistic\":\n",
    "    try:\n",
    "        C_ub = int(environ[\"C_ub\"])\n",
    "        C_lb = int(environ[\"C_lb\"])\n",
    "    except:\n",
    "        C_ub = 3\n",
    "        C_lb = 1\n",
    "\n",
    "elif classifier_method == \"KNN\":\n",
    "    try:\n",
    "        n_neighbors_ub = int(environ[\"n_neighbors_ub\"])\n",
    "        n_neighbors_lb = int(environ[\"n_neighbors_lb\"])\n",
    "\n",
    "    except:\n",
    "        n_neighbors_ub = 100\n",
    "        n_neighbors_lb = 5\n",
    "        \n",
    "elif classifier_method == \"ADA\":\n",
    "    try:\n",
    "        n_estimators_ub = int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb = int(environ[\"n_estimators_lb\"])\n",
    "        learning_rate_ub = int(environ[\"learning_rate_ub\"])\n",
    "        learning_rate_lb = int(environ[\"learning_rate_lb\"])\n",
    "    except:\n",
    "        n_estimators_ub = 6\n",
    "        n_estimators_lb = 3\n",
    "        learning_rate_ub = 0\n",
    "        learning_rate_lb = -4\n",
    "        \n",
    "elif classifier_method == \"SVM\":\n",
    "    try:\n",
    "        C_ub = int(environ[\"C_ub\"])\n",
    "        C_lb = int(environ[\"C_lb\"])\n",
    "        gamma_ub = int(environ[\"gamma_ub\"])\n",
    "        gamma_lb = int(environ[\"gamma_lb\"])\n",
    "    except:\n",
    "        C_ub = 4\n",
    "        C_lb = 2\n",
    "        gamma_ub = -4\n",
    "        gamma_lb = -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hyperparameter trials\n",
    "\n",
    "Choose hyperparameters and generate hyperparameters through random search in a grid, as explained by this video: https://www.youtube.com/watch?v=WrICwRrvuIc&index=66&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K\n",
    "\n",
    "Use logarithmic scale for search for learnining rate and weight decay for NN, as explained by this video: https://www.youtube.com/watch?v=VUbrW8OK3uo&index=67&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K\n",
    "\n",
    "Utilize nested cross validation to choose between models, as described here: https://stats.stackexchange.com/questions/266225/step-by-step-explanation-of-k-fold-cross-validation-with-grid-search-to-optimise/266229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n",
      "[{'colsample_bytree': 0.7020725320537329, 'scale_pos_weight': 0.1, 'learning_rate': 0.26524963767594756, 'min_child_weight': 1.430378732744839, 'n_estimators': 784, 'max_depth': 659, 'gamma': 0.04311710058685491}, {'colsample_bytree': 0.9727470703757719, 'scale_pos_weight': 0.1, 'learning_rate': 0.6190490166774184, 'min_child_weight': 1.7835460015641595, 'n_estimators': 377, 'max_depth': 699, 'gamma': 0.014135935551752292}, {'colsample_bytree': 0.9441974787194958, 'scale_pos_weight': 'balanced', 'learning_rate': 0.12221634728708944, 'min_child_weight': 1.1360891221878646, 'n_estimators': 187, 'max_depth': 274, 'gamma': 0.0016334587611069498}, {'colsample_bytree': 0.8336175632123879, 'scale_pos_weight': 1, 'learning_rate': 0.9519592150539826, 'min_child_weight': 1.665239691095876, 'n_estimators': 215, 'max_depth': 1076, 'gamma': 0.40741446541662296}, {'colsample_bytree': 0.7591596475892202, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3819616775589123, 'min_child_weight': 1.0409549591024096, 'n_estimators': 1301, 'max_depth': 855, 'gamma': 0.14517704896094835}, {'colsample_bytree': 0.32943070539084407, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1535791796043299, 'min_child_weight': 1.5172312486447144, 'n_estimators': 797, 'max_depth': 739, 'gamma': 0.026351252231361928}, {'colsample_bytree': 0.35141363005408904, 'scale_pos_weight': 0.1, 'learning_rate': 0.14114804498181488, 'min_child_weight': 0.43310070884874374, 'n_estimators': 982, 'max_depth': 1307, 'gamma': 0.009384756816024659}, {'colsample_bytree': 0.7613652243276126, 'scale_pos_weight': 1, 'learning_rate': 0.2735469984777898, 'min_child_weight': 1.8874961570292483, 'n_estimators': 856, 'max_depth': 373, 'gamma': 0.011981845126013866}, {'colsample_bytree': 0.7529784022136196, 'scale_pos_weight': 'balanced', 'learning_rate': 0.13456319729640445, 'min_child_weight': 1.3335334308913354, 'n_estimators': 1445, 'max_depth': 157, 'gamma': 0.004277083049962071}, {'colsample_bytree': 0.6776475778134097, 'scale_pos_weight': 'balanced', 'learning_rate': 0.9735849191844885, 'min_child_weight': 0.7274215418852452, 'n_estimators': 498, 'max_depth': 711, 'gamma': 0.020692098656538337}, {'colsample_bytree': 0.37098213841374716, 'scale_pos_weight': 0.1, 'learning_rate': 0.17918085415440999, 'min_child_weight': 0.4177535121896694, 'n_estimators': 1064, 'max_depth': 1171, 'gamma': 0.09105944026265277}, {'colsample_bytree': 0.5035057111291688, 'scale_pos_weight': 'balanced', 'learning_rate': 0.20758775973690646, 'min_child_weight': 1.2470202022637364, 'n_estimators': 1267, 'max_depth': 1351, 'gamma': 0.10574430003444459}, {'colsample_bytree': 0.322825956844796, 'scale_pos_weight': 1, 'learning_rate': 0.12476661940792175, 'min_child_weight': 1.6419864596958702, 'n_estimators': 269, 'max_depth': 1219, 'gamma': 0.3264635677523521}, {'colsample_bytree': 0.588369410890696, 'scale_pos_weight': 0.1, 'learning_rate': 0.27651005032334997, 'min_child_weight': 0.11142938740321262, 'n_estimators': 487, 'max_depth': 1073, 'gamma': 0.001148055797995468}, {'colsample_bytree': 0.6106701481271222, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7594092613374688, 'min_child_weight': 0.718888927938643, 'n_estimators': 655, 'max_depth': 1054, 'gamma': 0.11640819317908095}, {'colsample_bytree': 0.6738916499536565, 'scale_pos_weight': 1, 'learning_rate': 0.32282633872057603, 'min_child_weight': 0.43364427525508575, 'n_estimators': 834, 'max_depth': 223, 'gamma': 0.3938289920376665}, {'colsample_bytree': 0.3123343694729518, 'scale_pos_weight': 0.1, 'learning_rate': 0.10217783699569047, 'min_child_weight': 1.8423152204743996, 'n_estimators': 882, 'max_depth': 1165, 'gamma': 0.006810134414375388}, {'colsample_bytree': 0.8810395893980159, 'scale_pos_weight': 0.1, 'learning_rate': 0.24993136020245224, 'min_child_weight': 1.294348280375111, 'n_estimators': 870, 'max_depth': 407, 'gamma': 0.006225733021242983}, {'colsample_bytree': 0.527356069561255, 'scale_pos_weight': 0.1, 'learning_rate': 0.3712089219920516, 'min_child_weight': 0.32988092048376827, 'n_estimators': 1495, 'max_depth': 1308, 'gamma': 0.0027499531070615496}, {'colsample_bytree': 0.574966046486533, 'scale_pos_weight': 0.1, 'learning_rate': 0.24894205793717045, 'min_child_weight': 0.5769528740970573, 'n_estimators': 194, 'max_depth': 1350, 'gamma': 0.18548982077619477}, {'colsample_bytree': 0.9645617586377387, 'scale_pos_weight': 1, 'learning_rate': 0.7021156807204884, 'min_child_weight': 0.4461632652812366, 'n_estimators': 550, 'max_depth': 1372, 'gamma': 0.02194704913043539}, {'colsample_bytree': 0.8603483647768579, 'scale_pos_weight': 0.1, 'learning_rate': 0.7605069672357748, 'min_child_weight': 0.5948739017102673, 'n_estimators': 849, 'max_depth': 239, 'gamma': 0.015470958549309933}, {'colsample_bytree': 0.7693986925583244, 'scale_pos_weight': 0.1, 'learning_rate': 0.3171935751176198, 'min_child_weight': 1.7634707237097056, 'n_estimators': 1276, 'max_depth': 1025, 'gamma': 0.1498866107685077}, {'colsample_bytree': 0.6061506365567065, 'scale_pos_weight': 0.1, 'learning_rate': 0.5200852430421803, 'min_child_weight': 1.2376171291827143, 'n_estimators': 773, 'max_depth': 1028, 'gamma': 0.025727439628506717}, {'colsample_bytree': 0.9088391427070315, 'scale_pos_weight': 'balanced', 'learning_rate': 0.12370119339460328, 'min_child_weight': 1.4983396743054493, 'n_estimators': 1276, 'max_depth': 691, 'gamma': 0.0020351202519752485}, {'colsample_bytree': 0.7399006148928502, 'scale_pos_weight': 1, 'learning_rate': 0.270033991160404, 'min_child_weight': 1.1486504976991576, 'n_estimators': 1473, 'max_depth': 1253, 'gamma': 0.09042943346173951}, {'colsample_bytree': 0.9880316810231098, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3443677883129969, 'min_child_weight': 0.19451985412634776, 'n_estimators': 1107, 'max_depth': 334, 'gamma': 0.006039803128987408}, {'colsample_bytree': 0.5142337459003998, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6936495834111065, 'min_child_weight': 0.19913817822162216, 'n_estimators': 655, 'max_depth': 132, 'gamma': 0.025570988797875227}, {'colsample_bytree': 0.37513563478637474, 'scale_pos_weight': 0.1, 'learning_rate': 0.7327119853926455, 'min_child_weight': 1.0166308971577818, 'n_estimators': 723, 'max_depth': 870, 'gamma': 0.21734670410044998}, {'colsample_bytree': 0.9869312198688952, 'scale_pos_weight': 0.1, 'learning_rate': 0.2630724502302743, 'min_child_weight': 0.06644477053235454, 'n_estimators': 1049, 'max_depth': 647, 'gamma': 0.013178690305790589}, {'colsample_bytree': 0.25878556313875145, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5370201263548504, 'min_child_weight': 1.711606684785222, 'n_estimators': 976, 'max_depth': 877, 'gamma': 0.01202082275041248}, {'colsample_bytree': 0.2907534912544402, 'scale_pos_weight': 0.1, 'learning_rate': 0.10435705015393308, 'min_child_weight': 1.0420732124082586, 'n_estimators': 1168, 'max_depth': 902, 'gamma': 0.003980976140397891}, {'colsample_bytree': 0.9580898131881727, 'scale_pos_weight': 1, 'learning_rate': 0.3950530383446488, 'min_child_weight': 1.749145915289993, 'n_estimators': 390, 'max_depth': 297, 'gamma': 0.0667972522062166}, {'colsample_bytree': 0.28777754256815785, 'scale_pos_weight': 0.1, 'learning_rate': 0.9826444348404075, 'min_child_weight': 1.0000525954586028, 'n_estimators': 309, 'max_depth': 1492, 'gamma': 0.12511063378806395}, {'colsample_bytree': 0.6924324822659282, 'scale_pos_weight': 'balanced', 'learning_rate': 0.20509024102762677, 'min_child_weight': 1.0712656060499166, 'n_estimators': 423, 'max_depth': 608, 'gamma': 0.15501227443631754}, {'colsample_bytree': 0.38964475441025215, 'scale_pos_weight': 1, 'learning_rate': 0.5489727596641779, 'min_child_weight': 0.4196874979502443, 'n_estimators': 321, 'max_depth': 440, 'gamma': 0.6809530508136838}, {'colsample_bytree': 0.3139716743940254, 'scale_pos_weight': 0.1, 'learning_rate': 0.3074947493589922, 'min_child_weight': 1.361089382385559, 'n_estimators': 1446, 'max_depth': 191, 'gamma': 0.0014765732560531632}, {'colsample_bytree': 0.7132434370719101, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7155064948271145, 'min_child_weight': 1.952808773186085, 'n_estimators': 1067, 'max_depth': 374, 'gamma': 0.04241273949596576}, {'colsample_bytree': 0.6524344083315416, 'scale_pos_weight': 0.1, 'learning_rate': 0.9780002085490747, 'min_child_weight': 0.9073936891120906, 'n_estimators': 301, 'max_depth': 598, 'gamma': 0.4897944719001141}, {'colsample_bytree': 0.4219144923149346, 'scale_pos_weight': 0.1, 'learning_rate': 0.802462923540816, 'min_child_weight': 0.2744408401943892, 'n_estimators': 1140, 'max_depth': 206, 'gamma': 0.4413226300006937}, {'colsample_bytree': 0.6397833952437072, 'scale_pos_weight': 1, 'learning_rate': 0.20505021107666452, 'min_child_weight': 0.6493659441329307, 'n_estimators': 1052, 'max_depth': 959, 'gamma': 0.0010003824647975084}, {'colsample_bytree': 0.7599095923050772, 'scale_pos_weight': 'balanced', 'learning_rate': 0.30437474632070965, 'min_child_weight': 1.770675319219171, 'n_estimators': 1211, 'max_depth': 1137, 'gamma': 0.02335550791438111}, {'colsample_bytree': 0.9102232023362534, 'scale_pos_weight': 0.1, 'learning_rate': 0.906673360503355, 'min_child_weight': 0.45888366894209076, 'n_estimators': 1032, 'max_depth': 381, 'gamma': 0.008731265160089033}, {'colsample_bytree': 0.5685141015636297, 'scale_pos_weight': 1, 'learning_rate': 0.2907872928845631, 'min_child_weight': 0.4149401508822188, 'n_estimators': 1351, 'max_depth': 990, 'gamma': 0.013258974672122958}, {'colsample_bytree': 0.8978917044424235, 'scale_pos_weight': 1, 'learning_rate': 0.32913881950217044, 'min_child_weight': 1.1735686929163376, 'n_estimators': 1331, 'max_depth': 563, 'gamma': 0.002252140953021267}, {'colsample_bytree': 0.6740659838938817, 'scale_pos_weight': 0.1, 'learning_rate': 0.1395878954008348, 'min_child_weight': 0.7921194056145875, 'n_estimators': 1106, 'max_depth': 1343, 'gamma': 0.003546822939411305}, {'colsample_bytree': 0.8114977148879104, 'scale_pos_weight': 1, 'learning_rate': 0.12117762474274964, 'min_child_weight': 1.5306505076139305, 'n_estimators': 537, 'max_depth': 1120, 'gamma': 0.5142321426791348}, {'colsample_bytree': 0.9714522839104218, 'scale_pos_weight': 'balanced', 'learning_rate': 0.17411203034456033, 'min_child_weight': 1.1689521379115377, 'n_estimators': 1218, 'max_depth': 159, 'gamma': 0.007523892475314567}, {'colsample_bytree': 0.2569300551149056, 'scale_pos_weight': 1, 'learning_rate': 0.9645604140898281, 'min_child_weight': 1.1112984855402903, 'n_estimators': 1424, 'max_depth': 989, 'gamma': 0.31558350297517956}, {'colsample_bytree': 0.6342950974719278, 'scale_pos_weight': 0.1, 'learning_rate': 0.6131153029376062, 'min_child_weight': 0.36326240098409746, 'n_estimators': 1116, 'max_depth': 634, 'gamma': 0.055124087265135756}, {'colsample_bytree': 0.9619891168117611, 'scale_pos_weight': 0.1, 'learning_rate': 0.629799900013625, 'min_child_weight': 0.463403252942409, 'n_estimators': 568, 'max_depth': 500, 'gamma': 0.6670111812059986}, {'colsample_bytree': 0.46976521338084753, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4148362425557292, 'min_child_weight': 1.748575933249894, 'n_estimators': 405, 'max_depth': 443, 'gamma': 0.35223350627705396}, {'colsample_bytree': 0.83531998832801, 'scale_pos_weight': 1, 'learning_rate': 0.5669824375133657, 'min_child_weight': 1.724619554700566, 'n_estimators': 1153, 'max_depth': 1029, 'gamma': 0.901772187506922}, {'colsample_bytree': 0.5578691035708427, 'scale_pos_weight': 1, 'learning_rate': 0.19853716612014977, 'min_child_weight': 0.5389588679162354, 'n_estimators': 1109, 'max_depth': 237, 'gamma': 0.019260674699596053}, {'colsample_bytree': 0.9855247555180144, 'scale_pos_weight': 'balanced', 'learning_rate': 0.37086065421699316, 'min_child_weight': 0.24131398237223944, 'n_estimators': 1108, 'max_depth': 1383, 'gamma': 0.016533373579346547}, {'colsample_bytree': 0.8305354995239791, 'scale_pos_weight': 0.1, 'learning_rate': 0.12053172997893831, 'min_child_weight': 1.813110998442358, 'n_estimators': 750, 'max_depth': 337, 'gamma': 0.009987009341166649}, {'colsample_bytree': 0.4939827288692473, 'scale_pos_weight': 1, 'learning_rate': 0.10326386974968807, 'min_child_weight': 1.8524258603526298, 'n_estimators': 1389, 'max_depth': 703, 'gamma': 0.7221243957737429}, {'colsample_bytree': 0.4379670401454141, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6462850223374825, 'min_child_weight': 1.765719996087582, 'n_estimators': 1349, 'max_depth': 1008, 'gamma': 0.10770490659177065}, {'colsample_bytree': 0.8722016859457893, 'scale_pos_weight': 0.1, 'learning_rate': 0.12489631065582871, 'min_child_weight': 1.5042690419758675, 'n_estimators': 392, 'max_depth': 455, 'gamma': 0.01371201615695837}, {'colsample_bytree': 0.607357900412373, 'scale_pos_weight': 'balanced', 'learning_rate': 0.2874183899474959, 'min_child_weight': 1.1838703163768993, 'n_estimators': 1408, 'max_depth': 936, 'gamma': 0.02909401825264376}, {'colsample_bytree': 0.462639134936625, 'scale_pos_weight': 0.1, 'learning_rate': 0.15175777892340378, 'min_child_weight': 1.3912508912777144, 'n_estimators': 1029, 'max_depth': 737, 'gamma': 0.013796879387439818}, {'colsample_bytree': 0.40494595530645205, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4801303164322281, 'min_child_weight': 1.320079724445898, 'n_estimators': 1447, 'max_depth': 202, 'gamma': 0.3481977556728324}, {'colsample_bytree': 0.5281395994134166, 'scale_pos_weight': 0.1, 'learning_rate': 0.288307462513147, 'min_child_weight': 0.545643804848934, 'n_estimators': 1026, 'max_depth': 1273, 'gamma': 0.003900882244919025}, {'colsample_bytree': 0.6021237271959063, 'scale_pos_weight': 'balanced', 'learning_rate': 0.30790026305284757, 'min_child_weight': 0.9816372257017558, 'n_estimators': 1213, 'max_depth': 1198, 'gamma': 0.4447621983542005}, {'colsample_bytree': 0.606467081431462, 'scale_pos_weight': 'balanced', 'learning_rate': 0.36010522857767197, 'min_child_weight': 0.34822390445426454, 'n_estimators': 132, 'max_depth': 1239, 'gamma': 0.224359206505158}, {'colsample_bytree': 0.45819707329882453, 'scale_pos_weight': 'balanced', 'learning_rate': 0.24698789941043997, 'min_child_weight': 1.3627850212076758, 'n_estimators': 1256, 'max_depth': 193, 'gamma': 0.0024354638990657157}, {'colsample_bytree': 0.6578544625579947, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7621516781639505, 'min_child_weight': 1.807967909856474, 'n_estimators': 475, 'max_depth': 802, 'gamma': 0.023481955729256935}, {'colsample_bytree': 0.5492689912773265, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4898070368872746, 'min_child_weight': 1.4483352732230865, 'n_estimators': 519, 'max_depth': 685, 'gamma': 0.5153866664021131}, {'colsample_bytree': 0.2703017385828926, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5847409452429984, 'min_child_weight': 1.4324883484360373, 'n_estimators': 1175, 'max_depth': 1098, 'gamma': 0.1563838929285332}, {'colsample_bytree': 0.6932381239927636, 'scale_pos_weight': 1, 'learning_rate': 0.2865652026974929, 'min_child_weight': 0.9162776545200857, 'n_estimators': 427, 'max_depth': 706, 'gamma': 0.3742552769737321}, {'colsample_bytree': 0.8655753405259863, 'scale_pos_weight': 1, 'learning_rate': 0.6539187930284103, 'min_child_weight': 1.1515023240897448, 'n_estimators': 1039, 'max_depth': 694, 'gamma': 0.5327594418289823}, {'colsample_bytree': 0.5488256939647578, 'scale_pos_weight': 1, 'learning_rate': 0.2654802707527337, 'min_child_weight': 1.2577968781234008, 'n_estimators': 841, 'max_depth': 1343, 'gamma': 0.0015421934564332134}, {'colsample_bytree': 0.5165266363539472, 'scale_pos_weight': 'balanced', 'learning_rate': 0.10383135047815754, 'min_child_weight': 1.917965443726947, 'n_estimators': 880, 'max_depth': 948, 'gamma': 0.011752240523075753}, {'colsample_bytree': 0.9469685629770355, 'scale_pos_weight': 'balanced', 'learning_rate': 0.8816608033710761, 'min_child_weight': 0.8025190016072175, 'n_estimators': 796, 'max_depth': 1244, 'gamma': 0.0019899620338785676}, {'colsample_bytree': 0.314899367649541, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6910555620849614, 'min_child_weight': 0.11193165669889571, 'n_estimators': 1362, 'max_depth': 1295, 'gamma': 0.005146593662942004}, {'colsample_bytree': 0.73737398014259, 'scale_pos_weight': 1, 'learning_rate': 0.10776191380142862, 'min_child_weight': 1.026149726343091, 'n_estimators': 934, 'max_depth': 704, 'gamma': 0.04303012742410711}, {'colsample_bytree': 0.5321699307041404, 'scale_pos_weight': 0.1, 'learning_rate': 0.9586049790315697, 'min_child_weight': 1.5421780963399294, 'n_estimators': 794, 'max_depth': 945, 'gamma': 0.02972173945010838}, {'colsample_bytree': 0.2842447314917338, 'scale_pos_weight': 0.1, 'learning_rate': 0.6784524261938246, 'min_child_weight': 0.7486463932744414, 'n_estimators': 492, 'max_depth': 866, 'gamma': 0.00851535817161396}, {'colsample_bytree': 0.46629887299862044, 'scale_pos_weight': 0.1, 'learning_rate': 0.4597318278003059, 'min_child_weight': 1.5664688766276262, 'n_estimators': 1243, 'max_depth': 496, 'gamma': 0.005299755817243635}, {'colsample_bytree': 0.568066741326887, 'scale_pos_weight': 0.1, 'learning_rate': 0.1936651693371716, 'min_child_weight': 1.0346170344045775, 'n_estimators': 1257, 'max_depth': 799, 'gamma': 0.04613849520176798}, {'colsample_bytree': 0.5204091703644191, 'scale_pos_weight': 0.1, 'learning_rate': 0.8413310398376074, 'min_child_weight': 0.829713738667128, 'n_estimators': 1249, 'max_depth': 818, 'gamma': 0.3061757170872131}, {'colsample_bytree': 0.9529632729383175, 'scale_pos_weight': 0.1, 'learning_rate': 0.24085729645857118, 'min_child_weight': 0.8981668554025792, 'n_estimators': 764, 'max_depth': 425, 'gamma': 0.005911537602431929}, {'colsample_bytree': 0.9940084325608556, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1276163017582049, 'min_child_weight': 0.5931125301280598, 'n_estimators': 562, 'max_depth': 853, 'gamma': 0.005600929719451105}, {'colsample_bytree': 0.7673261988083129, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5379093572149319, 'min_child_weight': 0.4668405109361926, 'n_estimators': 437, 'max_depth': 1281, 'gamma': 0.001496473659586649}, {'colsample_bytree': 0.5342926720580714, 'scale_pos_weight': 0.1, 'learning_rate': 0.5607745009412582, 'min_child_weight': 0.544873790931925, 'n_estimators': 736, 'max_depth': 509, 'gamma': 0.013270538612281325}, {'colsample_bytree': 0.472181791278357, 'scale_pos_weight': 1, 'learning_rate': 0.22483843874091622, 'min_child_weight': 1.007867223758871, 'n_estimators': 685, 'max_depth': 246, 'gamma': 0.4548694891072422}, {'colsample_bytree': 0.6613893222098577, 'scale_pos_weight': 0.1, 'learning_rate': 0.22324547464456343, 'min_child_weight': 0.40303542664643666, 'n_estimators': 209, 'max_depth': 279, 'gamma': 0.036218335579295005}, {'colsample_bytree': 0.9958005922357596, 'scale_pos_weight': 0.1, 'learning_rate': 0.11772529250569351, 'min_child_weight': 1.9359311332084541, 'n_estimators': 590, 'max_depth': 1445, 'gamma': 0.022670706161121983}, {'colsample_bytree': 0.5631147810970089, 'scale_pos_weight': 0.1, 'learning_rate': 0.40189981290904947, 'min_child_weight': 0.3047094113754609, 'n_estimators': 1304, 'max_depth': 404, 'gamma': 0.0024766690981938002}, {'colsample_bytree': 0.26447545483830326, 'scale_pos_weight': 'balanced', 'learning_rate': 0.14075962064759423, 'min_child_weight': 0.1448688949315946, 'n_estimators': 985, 'max_depth': 712, 'gamma': 0.8683998816479346}, {'colsample_bytree': 0.6849342987988792, 'scale_pos_weight': 0.1, 'learning_rate': 0.18750329383236625, 'min_child_weight': 0.4310576231290897, 'n_estimators': 267, 'max_depth': 1028, 'gamma': 0.8457754120740337}, {'colsample_bytree': 0.48278561948485854, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3349426424455048, 'min_child_weight': 1.0117327676506167, 'n_estimators': 834, 'max_depth': 1398, 'gamma': 0.013155416174536916}, {'colsample_bytree': 0.8967389101269267, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1793256956530083, 'min_child_weight': 1.8483175332415271, 'n_estimators': 272, 'max_depth': 401, 'gamma': 0.0013998157895346944}, {'colsample_bytree': 0.632971680202135, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3389135526365699, 'min_child_weight': 1.0249033175181743, 'n_estimators': 1015, 'max_depth': 1286, 'gamma': 0.014470430799511038}, {'colsample_bytree': 0.7578357998749136, 'scale_pos_weight': 0.1, 'learning_rate': 0.3534771443434167, 'min_child_weight': 1.785724493934567, 'n_estimators': 465, 'max_depth': 205, 'gamma': 0.0826194222128685}, {'colsample_bytree': 0.7262925992366122, 'scale_pos_weight': 0.1, 'learning_rate': 0.2885490882613549, 'min_child_weight': 1.712605953667093, 'n_estimators': 1162, 'max_depth': 366, 'gamma': 0.00792374485419772}, {'colsample_bytree': 0.3171209087746751, 'scale_pos_weight': 0.1, 'learning_rate': 0.10575799281061614, 'min_child_weight': 1.844222923534386, 'n_estimators': 470, 'max_depth': 790, 'gamma': 0.016513037452481373}, {'colsample_bytree': 0.4593009611714488, 'scale_pos_weight': 1, 'learning_rate': 0.13052786465860491, 'min_child_weight': 1.2444621176795898, 'n_estimators': 728, 'max_depth': 281, 'gamma': 0.004258433297085862}, {'colsample_bytree': 0.9616457655403805, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4438095608782328, 'min_child_weight': 1.3439142811916447, 'n_estimators': 220, 'max_depth': 445, 'gamma': 0.0010188485733850711}, {'colsample_bytree': 0.26265375502752975, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6511464088300172, 'min_child_weight': 1.9255406396804848, 'n_estimators': 1022, 'max_depth': 1282, 'gamma': 0.12287040565803549}]\n"
     ]
    }
   ],
   "source": [
    "no_trials = 100\n",
    "print classifier_method\n",
    "if classifier_method == \"NN\":\n",
    "    hyperparameter_trials = generate_trials_NN(no_trials, learning_rate_ub, learning_rate_lb, batch_size_ub, batch_size_lb,weight_decay_ub, \n",
    "                                               weight_decay_lb, beta_ub, beta_lb, hidden_units_1_ub, hidden_units_1_lb, hidden_units_2_ub, \n",
    "                                               hidden_units_2_lb)\n",
    "elif classifier_method == \"XGB\":\n",
    "    hyperparameter_trials = generate_trials_XGB(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                                max_depth_ub, max_depth_lb, min_child_weight_ub,\n",
    "                                                min_child_weight_lb, colsample_bytree_ub, colsample_bytree_lb,\n",
    "                                               gamma_ub, gamma_lb, learning_rate_lb, learning_rate_ub)\n",
    "elif classifier_method == \"RF\":\n",
    "    hyperparameter_trials = generate_trials_RF(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                              max_depth_ub, max_depth_lb, min_samples_leaf_ub,\n",
    "                                              min_samples_leaf_lb, min_samples_split_ub, min_samples_split_lb)\n",
    "elif classifier_method == \"Logistic\":\n",
    "    hyperparameter_trials = generate_trials_Log(no_trials, C_ub, C_lb)\n",
    "    \n",
    "elif classifier_method == \"KNN\":\n",
    "    hyperparameter_trials = generate_trials_KNN(no_trials, n_neighbors_ub, n_neighbors_lb)\n",
    "    \n",
    "elif classifier_method == \"ADA\":\n",
    "    hyperparameter_trials = generate_trials_ADA(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                               learning_rate_lb,learning_rate_ub)\n",
    "    \n",
    "elif classifier_method == \"SVM\":\n",
    "    hyperparameter_trials = generate_trials_SVM(no_trials, C_ub, C_lb, gamma_ub, gamma_lb)\n",
    "\n",
    "print hyperparameter_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Network\n",
    "\n",
    "Tutorial for Neural Net Architecture: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "Utilize batch normalization, as explained here: https://www.youtube.com/watch?v=fv1Luwd-LOI&index=69&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the network with batch normalization\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "        hidden_units_1 = hyperparameters[\"hidden_units_1\"]\n",
    "        hidden_units_2 = hyperparameters[\"hidden_units_2\"]\n",
    "        super(Net, self).__init__()\n",
    "        self.input = nn.Linear(len(features_cols), hidden_units_1) # read input size from the .shape of data table\n",
    "        self.hidden1 = nn.Linear(hidden_units_1, hidden_units_2)\n",
    "        self.hidden1_bn = nn.BatchNorm1d(hidden_units_2)\n",
    "        self.hidden2 = nn.Linear(hidden_units_2, hidden_units_2)\n",
    "        self.hidden2_bn = nn.BatchNorm1d(hidden_units_2)\n",
    "        self.hidden3 = nn.Linear(hidden_units_2, hidden_units_1)\n",
    "        self.hidden3_bn = nn.BatchNorm1d(hidden_units_1)\n",
    "        self.output = nn.Linear(hidden_units_1,2)\n",
    "        self.batch_size = hyperparameters[\"batch_size\"]\n",
    "        self.learning_rate = hyperparameters[\"learning_rate\"]\n",
    "        self.beta = hyperparameters[\"beta\"]\n",
    "        self.weight_decay = hyperparameters[\"weight_decay\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden1_bn(self.hidden1(x)))\n",
    "        x = F.relu(self.hidden2_bn(self.hidden2(x)))\n",
    "        x = F.relu(self.hidden3_bn(self.hidden3(x)))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X_train, y_train_label, X_valid, y_valid, weight):\n",
    "\n",
    "        # set random seed for weights and biases\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # dataset\n",
    "        dataset = pd.concat([X_train,y_train_label],axis=1)\n",
    "        dataset = shuffle(dataset, random_state = 0)\n",
    "\n",
    "        X_train = dataset.iloc[:,:dataset.shape[1]-1]\n",
    "        y_train_label = dataset.iloc[:,dataset.shape[1]-1]\n",
    "\n",
    "\n",
    "        # create loss function\n",
    "        loss = nn.CrossEntropyLoss(weight = weight)\n",
    "        # mini-batching\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        # create adam optimizer for Phase 1\n",
    "        optimizer_1 = optim.Adam(self.parameters(), lr=self.learning_rate,betas=(self.beta,0.999), \n",
    "                                 weight_decay = self.weight_decay)\n",
    "        no_batch_minus_1 = X_train.shape[0] / batch_size \n",
    "\n",
    "        # Repeated Stratified K Fold to ensure positives are evenly distributed across batches\n",
    "        skf_1 = RepeatedStratifiedKFold(n_splits=no_batch_minus_1,n_repeats=301,random_state=0)\n",
    "        \n",
    "        count = 0\n",
    "        epoch_count = 0\n",
    "        max_auprc = 0\n",
    "        ideal_epoch_count = 0 \n",
    "        patience = 100\n",
    "        patience_j = 0\n",
    "\n",
    "        for train,test in skf_1.split(X_train,y_train_label):\n",
    "            data = X_train.iloc[test,:]\n",
    "            data = torch.Tensor(data.values.astype(np.float32))\n",
    "             # forward pass\n",
    "            output = self.forward(data)\n",
    "            output.data = output.data.view(data.shape[0],2)\n",
    "\n",
    "            labels = y_train_label[test]\n",
    "            labels = torch.Tensor(labels.astype(np.float32))\n",
    "            labels = torch.autograd.Variable(labels).long()\n",
    "\n",
    "            # zero the gradient buffers\n",
    "            optimizer_1.zero_grad()\n",
    "            # compute loss and gradients\n",
    "            loss_output = loss(output,labels)\n",
    "            loss_output.backward()\n",
    "            # Does the update\n",
    "            optimizer_1.step()\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if count == no_batch_minus_1 + 1:\n",
    "                count = 0\n",
    "                epoch_count = epoch_count + 1\n",
    "                probs = self.predict_proba(X_valid)\n",
    "                precision, recall, _ = precision_recall_curve(y_valid, probs)\n",
    "                auprc = auc(recall, precision)\n",
    "                if auprc > max_auprc:\n",
    "                    max_auprc = auprc\n",
    "                    ideal_epoch_count = epoch_count\n",
    "                    patience = patience + epoch_count\n",
    "                    patience_j = 0\n",
    "                else:\n",
    "                    patience_j = patience_j + 1 \n",
    "                    if patience_j == patience: break\n",
    "                \n",
    "                self.train()                   \n",
    "                #score = roc_auc_score(y_valid, probs)\n",
    "        return max_auprc, ideal_epoch_count\n",
    "\n",
    "        \n",
    "    #prediction probabilities array\n",
    "    def predict_proba(self, X_test):\n",
    "        self.eval()\n",
    "        #forward pass\n",
    "        test = torch.Tensor(X_test.values.astype(np.float32))\n",
    "        output = self.forward(test)\n",
    "        sf = nn.Softmax()\n",
    "        probs = sf(output.data)\n",
    "        return probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models tested (and their hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model(classifier_method, hyperparameters, no_pos=1, no_neg=1):\n",
    "    \n",
    "    if (classifier_method == \"XGB\"):\n",
    "        if (hyperparameters[\"scale_pos_weight\"] == \"balanced\"):\n",
    "            scale_weight = no_neg/float(no_pos)\n",
    "        else:\n",
    "            scale_weight = hyperparameters[\"scale_pos_weight\"]\n",
    "        model = XGBClassifier(n_estimators=hyperparameters[\"n_estimators\"], n_jobs=-1, random_state=0, max_depth=hyperparameters[\"max_depth\"], \n",
    "                              min_child_weight=hyperparameters[\"min_child_weight\"], colsample_bytree=hyperparameters[\"colsample_bytree\"], \n",
    "                              gamma=hyperparameters[\"gamma\"], learning_rate=hyperparameters[\"learning_rate\"], scale_pos_weight=scale_weight)\n",
    "        \n",
    "    elif (classifier_method == \"RF\"):\n",
    "        model = RandomForestClassifier(n_estimators=hyperparameters[\"n_estimators\"], n_jobs=-1, random_state=0,\n",
    "                                      max_depth=hyperparameters[\"max_depth\"], min_samples_leaf=hyperparameters[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=hyperparameters[\"min_samples_split\"], class_weight=hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif(classifier_method == \"Logistic\"):\n",
    "        model = LogisticRegression(C=hyperparameters[\"C\"], random_state=0, n_jobs=-1, class_weight=hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif (classifier_method == \"KNN\"):\n",
    "        model = KNeighborsClassifier(n_neighbors=hyperparameters[\"n_neighbors\"], n_jobs=-1, weights=hyperparameters[\"weights\"])\n",
    "        \n",
    "    elif (classifier_method == \"ADA\"):\n",
    "        model = AdaBoostClassifier(n_estimators=hyperparameters[\"n_estimators\"], random_state=0, learning_rate=hyperparameters[\"learning_rate\"])\n",
    "        \n",
    "    elif (classifier_method == \"SVM\"):\n",
    "        model = SVC(C=hyperparameters[\"C\"], gamma = hyperparameters[\"gamma\"], kernel=hyperparameters[\"kernel\"], probability=True, random_state=0, cache_size=400,\n",
    "                    class_weight = hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif (classifier_method ==\"NN\"):\n",
    "        torch.manual_seed(0)\n",
    "        model = Net(hyperparameters)\n",
    "        # sets model in training mode because batch normalization behavior in training and testing modes are different\n",
    "        model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7020725320537329, 'scale_pos_weight': 0.1, 'learning_rate': 0.26524963767594756, 'min_child_weight': 1.430378732744839, 'n_estimators': 784, 'max_depth': 659, 'gamma': 0.04311710058685491}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.702072532054, gamma=0.0431171005869,\n",
      "       learning_rate=0.265249637676, max_delta_step=0, max_depth=659,\n",
      "       min_child_weight=1.43037873274, missing=None, n_estimators=784,\n",
      "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=0.1,\n",
      "       seed=None, silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "# Generate trial for model\n",
    "hyperparameters = hyperparameter_trials[trial_idx]\n",
    "model = generate_model(classifier_method, hyperparameters)\n",
    "print hyperparameters\n",
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with model imbalance\n",
    "Weight Vector: https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2 (look at section on \"Cost-sensitive Learning\")\n",
    "\n",
    "Implementing Early Stopping for XGBoost: https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_iterative_fixed(hyperparameters_dict,ligand_bind_features, ligand_negatives_features, ligand_name, features=[]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test different models in k-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "    \n",
    "    models_req_scaling = [\"SVM\", \"KNN\", \"Logistic\", \"NN\"]\n",
    "    classifier = classifier_method\n",
    "\n",
    "    #Create X and y with included features\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    y_df = pd.DataFrame(y)\n",
    "    y_df.index = X.index\n",
    "    y_df.columns = [\"label\"]\n",
    "    \n",
    "    #Get the fold indices\n",
    "    cv_idx = calc_CV_idx_iterative(X, splits_dict)\n",
    "    k = (int(fold)-1)\n",
    "    \n",
    "    pred_idx = k+1\n",
    "    print \"fold #: \"+str(pred_idx)\n",
    "    #test_index = cv_idx[k][\"test\"]\n",
    "    full_train_index = cv_idx[k][\"train\"]\n",
    "        \n",
    "    # phase 1: testing on validation set, hyperparameter tuning\n",
    "    \n",
    "    trial_results = np.zeros(folds_num-1)\n",
    "    epoch_counts = np.zeros(folds_num-1, dtype = \"int\")\n",
    "    for i in range(folds_num-1):\n",
    "        valid_k = (k + 1 + i) % folds_num\n",
    "        valid_index = cv_idx[valid_k][\"test\"]\n",
    "\n",
    "        train_index = [index for index in full_train_index if index not in valid_index]\n",
    "        X_train, X_valid = X.loc[train_index,:], X.loc[valid_index,:]\n",
    "        y_train, y_valid = y_df.loc[train_index,:], y_df.loc[valid_index,:]\n",
    "\n",
    "        if (classifier in models_req_scaling):\n",
    "            cols = X_train.columns\n",
    "\n",
    "            # phase 1 scaling with just training data\n",
    "            scaler_1 = StandardScaler() \n",
    "            scaler_1.fit(X_train) \n",
    "            X_train = pd.DataFrame(scaler_1.transform(X_train))\n",
    "            # apply same transformation to validation data\n",
    "            X_valid = pd.DataFrame(scaler_1.transform(X_valid))\n",
    "\n",
    "            #Restoring indices after scaling\n",
    "            X_train.index = train_index \n",
    "            X_valid.index = valid_index\n",
    "\n",
    "            #Restoring features names\n",
    "            X_train.columns = cols\n",
    "            X_valid.columns = cols\n",
    "\n",
    "        #No down-sampling\n",
    "        X_train_sampled = X_train\n",
    "        y_train_sampled = y_train\n",
    "\n",
    "\n",
    "        #fit to training data\n",
    "        if (classifier == \"NN\"):\n",
    "            if hyperparameters[\"weight\"] == \"balanced\":\n",
    "                #pos and neg numbers in the training\n",
    "                no_pos = np.count_nonzero(y_train_sampled[\"label\"] == 1)\n",
    "                no_neg = np.count_nonzero(y_train_sampled[\"label\"] == 0)                \n",
    "                #weight vector\n",
    "                neg_weight = float(no_pos) / float(no_neg + no_pos) \n",
    "                pos_weight = 1 - neg_weight\n",
    "            elif hyperparameters[\"weight\"] == \"0.1\":\n",
    "                neg_weight = 10\n",
    "                pos_weight = 1\n",
    "            \n",
    "            weight = torch.Tensor([neg_weight, pos_weight])\n",
    "            auprc_score,epoch_count = model.fit(X_train_sampled, y_train_sampled[\"label\"],X_valid, y_valid[\"label\"], weight)\n",
    "        \n",
    "\n",
    "        elif (classifier == \"XGB\"):\n",
    "            num_early_stopping_rounds = 10\n",
    "            model.fit(X_train_sampled, y_train_sampled[\"label\"], eval_set = [(X_valid,y_valid[\"label\"])], eval_metric = \"map\", \n",
    "                      early_stopping_rounds = num_early_stopping_rounds)\n",
    "            probs_list = []\n",
    "            probs = model.predict_proba(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "            precision, recall, _ = precision_recall_curve(y_valid, probs_list)\n",
    "            auprc_score = auc(recall, precision)\n",
    "            epoch_count = model.best_iteration + 1\n",
    "            \n",
    "\n",
    "        else:\n",
    "            model.fit(X_train_sampled, y_train_sampled[\"label\"])\n",
    "            probs_list = []\n",
    "            probs = model.predict_proba(X_valid)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "            precision, recall, _ = precision_recall_curve(y_valid, probs_list)\n",
    "            auprc_score = auc(recall, precision)\n",
    "\n",
    "        trial_results[i] = auprc_score \n",
    "        if classifier == \"NN\" or classifier == \"XGB\": epoch_counts[i] = epoch_count\n",
    "\n",
    "    mean_result = np.mean(trial_results)\n",
    "    if classifier == \"NN\" or classifier == \"XGB\":\n",
    "        mean_epoch_count = int(np.mean(epoch_counts))\n",
    "        hyperparameters_dict[\"mean_epoch_count\"] = mean_epoch_count\n",
    "\n",
    "    hyperparameters_dict[\"mean_AUPRC\"] = mean_result\n",
    "\n",
    "    # Update dictionary with all hyperparameters\n",
    "    keys = hyperparameters.keys()\n",
    "    for key in keys:\n",
    "        hyperparameters_dict[key].append(hyperparameters[key])\n",
    "    pred_idx += 1\n",
    "\n",
    "    print \"Finished \"+ligand+\" \"+classifier+\" fold: \"+fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #: 1\n",
      "[0]\tvalidation_0-map:0.007397\n",
      "Will train until validation_0-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.007397\n",
      "[2]\tvalidation_0-map:0.007397\n",
      "[3]\tvalidation_0-map:0.007397\n",
      "[4]\tvalidation_0-map:0.007397\n",
      "[5]\tvalidation_0-map:0.007397\n",
      "[6]\tvalidation_0-map:0.011787\n",
      "[7]\tvalidation_0-map:0.011973\n",
      "[8]\tvalidation_0-map:0.012547\n",
      "[9]\tvalidation_0-map:0.012915\n",
      "[10]\tvalidation_0-map:0.014044\n",
      "[11]\tvalidation_0-map:0.01315\n",
      "[12]\tvalidation_0-map:0.047057\n",
      "[13]\tvalidation_0-map:0.042874\n",
      "[14]\tvalidation_0-map:0.049259\n",
      "[15]\tvalidation_0-map:0.051136\n",
      "[16]\tvalidation_0-map:0.047964\n",
      "[17]\tvalidation_0-map:0.046541\n",
      "[18]\tvalidation_0-map:0.047479\n",
      "[19]\tvalidation_0-map:0.044798\n",
      "[20]\tvalidation_0-map:0.044612\n",
      "[21]\tvalidation_0-map:0.04708\n",
      "[22]\tvalidation_0-map:0.047493\n",
      "[23]\tvalidation_0-map:0.052771\n",
      "[24]\tvalidation_0-map:0.054295\n",
      "[25]\tvalidation_0-map:0.06297\n",
      "[26]\tvalidation_0-map:0.072346\n",
      "[27]\tvalidation_0-map:0.079502\n",
      "[28]\tvalidation_0-map:0.075641\n",
      "[29]\tvalidation_0-map:0.079101\n",
      "[30]\tvalidation_0-map:0.096431\n",
      "[31]\tvalidation_0-map:0.099627\n",
      "[32]\tvalidation_0-map:0.102534\n",
      "[33]\tvalidation_0-map:0.104074\n",
      "[34]\tvalidation_0-map:0.118548\n",
      "[35]\tvalidation_0-map:0.116964\n",
      "[36]\tvalidation_0-map:0.125095\n",
      "[37]\tvalidation_0-map:0.12404\n",
      "[38]\tvalidation_0-map:0.12535\n",
      "[39]\tvalidation_0-map:0.142514\n",
      "[40]\tvalidation_0-map:0.137552\n",
      "[41]\tvalidation_0-map:0.141796\n",
      "[42]\tvalidation_0-map:0.145358\n",
      "[43]\tvalidation_0-map:0.145155\n",
      "[44]\tvalidation_0-map:0.146872\n",
      "[45]\tvalidation_0-map:0.156433\n",
      "[46]\tvalidation_0-map:0.159398\n",
      "[47]\tvalidation_0-map:0.154362\n",
      "[48]\tvalidation_0-map:0.153949\n",
      "[49]\tvalidation_0-map:0.156334\n",
      "[50]\tvalidation_0-map:0.152116\n",
      "[51]\tvalidation_0-map:0.152291\n",
      "[52]\tvalidation_0-map:0.154054\n",
      "[53]\tvalidation_0-map:0.150599\n",
      "[54]\tvalidation_0-map:0.151501\n",
      "[55]\tvalidation_0-map:0.146417\n",
      "[56]\tvalidation_0-map:0.146386\n",
      "Stopping. Best iteration:\n",
      "[46]\tvalidation_0-map:0.159398\n",
      "\n",
      "0.156225978919\n",
      "[0]\tvalidation_0-map:0.009681\n",
      "Will train until validation_0-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.009681\n",
      "[2]\tvalidation_0-map:0.009681\n",
      "[3]\tvalidation_0-map:0.009681\n",
      "[4]\tvalidation_0-map:0.009681\n",
      "[5]\tvalidation_0-map:0.009681\n",
      "[6]\tvalidation_0-map:0.013663\n",
      "[7]\tvalidation_0-map:0.070651\n",
      "[8]\tvalidation_0-map:0.064568\n",
      "[9]\tvalidation_0-map:0.066147\n",
      "[10]\tvalidation_0-map:0.057486\n",
      "[11]\tvalidation_0-map:0.064331\n",
      "[12]\tvalidation_0-map:0.061761\n",
      "[13]\tvalidation_0-map:0.064315\n",
      "[14]\tvalidation_0-map:0.06437\n",
      "[15]\tvalidation_0-map:0.071665\n",
      "[16]\tvalidation_0-map:0.082719\n",
      "[17]\tvalidation_0-map:0.087439\n",
      "[18]\tvalidation_0-map:0.088405\n",
      "[19]\tvalidation_0-map:0.106218\n",
      "[20]\tvalidation_0-map:0.108234\n",
      "[21]\tvalidation_0-map:0.095339\n",
      "[22]\tvalidation_0-map:0.104051\n",
      "[23]\tvalidation_0-map:0.097013\n",
      "[24]\tvalidation_0-map:0.111198\n",
      "[25]\tvalidation_0-map:0.103779\n",
      "[26]\tvalidation_0-map:0.106969\n",
      "[27]\tvalidation_0-map:0.106999\n",
      "[28]\tvalidation_0-map:0.1037\n",
      "[29]\tvalidation_0-map:0.09044\n",
      "[30]\tvalidation_0-map:0.094115\n",
      "[31]\tvalidation_0-map:0.094557\n",
      "[32]\tvalidation_0-map:0.097582\n",
      "[33]\tvalidation_0-map:0.105105\n",
      "[34]\tvalidation_0-map:0.103169\n",
      "Stopping. Best iteration:\n",
      "[24]\tvalidation_0-map:0.111198\n",
      "\n",
      "0.108103650564\n",
      "[0]\tvalidation_0-map:0.007651\n",
      "Will train until validation_0-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.007651\n",
      "[2]\tvalidation_0-map:0.007651\n",
      "[3]\tvalidation_0-map:0.007651\n",
      "[4]\tvalidation_0-map:0.007651\n",
      "[5]\tvalidation_0-map:0.011977\n",
      "[6]\tvalidation_0-map:0.012225\n",
      "[7]\tvalidation_0-map:0.068169\n",
      "[8]\tvalidation_0-map:0.05498\n",
      "[9]\tvalidation_0-map:0.035908\n",
      "[10]\tvalidation_0-map:0.036909\n",
      "[11]\tvalidation_0-map:0.045565\n",
      "[12]\tvalidation_0-map:0.041573\n",
      "[13]\tvalidation_0-map:0.046757\n",
      "[14]\tvalidation_0-map:0.075051\n",
      "[15]\tvalidation_0-map:0.096828\n",
      "[16]\tvalidation_0-map:0.104983\n",
      "[17]\tvalidation_0-map:0.112444\n",
      "[18]\tvalidation_0-map:0.120404\n",
      "[19]\tvalidation_0-map:0.130206\n",
      "[20]\tvalidation_0-map:0.122613\n",
      "[21]\tvalidation_0-map:0.120863\n",
      "[22]\tvalidation_0-map:0.126464\n",
      "[23]\tvalidation_0-map:0.133738\n",
      "[24]\tvalidation_0-map:0.147976\n",
      "[25]\tvalidation_0-map:0.168677\n",
      "[26]\tvalidation_0-map:0.183478\n",
      "[27]\tvalidation_0-map:0.192469\n",
      "[28]\tvalidation_0-map:0.198643\n",
      "[29]\tvalidation_0-map:0.212201\n",
      "[30]\tvalidation_0-map:0.226563\n",
      "[31]\tvalidation_0-map:0.22601\n",
      "[32]\tvalidation_0-map:0.21776\n",
      "[33]\tvalidation_0-map:0.221439\n",
      "[34]\tvalidation_0-map:0.22169\n",
      "[35]\tvalidation_0-map:0.224556\n",
      "[36]\tvalidation_0-map:0.218799\n",
      "[37]\tvalidation_0-map:0.216332\n",
      "[38]\tvalidation_0-map:0.211173\n",
      "[39]\tvalidation_0-map:0.208055\n",
      "[40]\tvalidation_0-map:0.206886\n",
      "Stopping. Best iteration:\n",
      "[30]\tvalidation_0-map:0.226563\n",
      "\n",
      "0.218162741599\n",
      "[0]\tvalidation_0-map:0.007874\n",
      "Will train until validation_0-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.007874\n",
      "[2]\tvalidation_0-map:0.007874\n",
      "[3]\tvalidation_0-map:0.007874\n",
      "[4]\tvalidation_0-map:0.007874\n",
      "[5]\tvalidation_0-map:0.007874\n",
      "[6]\tvalidation_0-map:0.007874\n",
      "[7]\tvalidation_0-map:0.007874\n",
      "[8]\tvalidation_0-map:0.042497\n",
      "[9]\tvalidation_0-map:0.189939\n",
      "[10]\tvalidation_0-map:0.22967\n",
      "[11]\tvalidation_0-map:0.204888\n",
      "[12]\tvalidation_0-map:0.254808\n",
      "[13]\tvalidation_0-map:0.307298\n",
      "[14]\tvalidation_0-map:0.34046\n",
      "[15]\tvalidation_0-map:0.352076\n",
      "[16]\tvalidation_0-map:0.360852\n",
      "[17]\tvalidation_0-map:0.359241\n",
      "[18]\tvalidation_0-map:0.385104\n",
      "[19]\tvalidation_0-map:0.408364\n",
      "[20]\tvalidation_0-map:0.424683\n",
      "[21]\tvalidation_0-map:0.435761\n",
      "[22]\tvalidation_0-map:0.443386\n",
      "[23]\tvalidation_0-map:0.452768\n",
      "[24]\tvalidation_0-map:0.448456\n",
      "[25]\tvalidation_0-map:0.469651\n",
      "[26]\tvalidation_0-map:0.510023\n",
      "[27]\tvalidation_0-map:0.516903\n",
      "[28]\tvalidation_0-map:0.52663\n",
      "[29]\tvalidation_0-map:0.534249\n",
      "[30]\tvalidation_0-map:0.5195\n",
      "[31]\tvalidation_0-map:0.521391\n",
      "[32]\tvalidation_0-map:0.539049\n",
      "[33]\tvalidation_0-map:0.540502\n",
      "[34]\tvalidation_0-map:0.539641\n",
      "[35]\tvalidation_0-map:0.536372\n",
      "[36]\tvalidation_0-map:0.534915\n",
      "[37]\tvalidation_0-map:0.534119\n",
      "[38]\tvalidation_0-map:0.527173\n",
      "[39]\tvalidation_0-map:0.525531\n",
      "[40]\tvalidation_0-map:0.514636\n",
      "[41]\tvalidation_0-map:0.514851\n",
      "[42]\tvalidation_0-map:0.521542\n",
      "[43]\tvalidation_0-map:0.518526\n",
      "Stopping. Best iteration:\n",
      "[33]\tvalidation_0-map:0.540502\n",
      "\n",
      "0.536906503489\n",
      "Finished dna XGB fold: 1\n",
      "Finished ligand dna\n",
      "CPU times: user 3min 28s, sys: 9.43 s, total: 3min 37s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize dictionary\n",
    "hyperparameters_dict = defaultdict(list)\n",
    "\n",
    "test_model_iterative_fixed(hyperparameters_dict,ligands_positives_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "\n",
    "hyperparameters_df = pd.DataFrame.from_dict(hyperparameters_dict)\n",
    "\n",
    "#Save to file\n",
    "hyperparameters_df.to_csv(curr_dir[0]+\"/hyperparam_tuning/phase1_initial_run/\"+datafile_date+\"_\"+prec_th_str+\"/per_trial/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_trial\"+str(trial_idx)+\"_\"+str(folds_num)+\"w_hyperparameters.csv\", sep='\\t')\n",
    "\n",
    "print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

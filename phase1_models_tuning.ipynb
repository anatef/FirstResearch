{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ, getcwd\n",
    "import sys\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Neural Net imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Import utils functions\n",
    "curr_dir = !pwd\n",
    "\n",
    "sys.path.append(curr_dir[0]+\"/utils\")\n",
    "from prop_threshold_funcs import create_negatives_datasets_combined, create_positives_datasets_combined\n",
    "from prediction_general_funcs import ligands, score_cols_suffix, get_features_cols, remove_unimportant_features\n",
    "from CV_funcs import add_domain_name_from_table_idx, calc_CV_idx_iterative\n",
    "from generate_hyperparameter_trials import *\n",
    "\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples positions #: 42535\n"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"31\"\n",
    "datafile_date = \"06.20.18\"\n",
    "input_path = curr_dir[0]+\"/domains_similarity/filtered_features_table/\"\n",
    "filename = \"windowed_positions_features_mediode_filter_\"+datafile_date+\".csv\"\n",
    "out_dir = \"mediode_NegLigand_NoFilter\"\n",
    "\n",
    "#flags for creating negatives\n",
    "zero_prop = True\n",
    "no_prop = True\n",
    "all_ligands = False\n",
    "prec_th_str = \"dna0.5_rna0.25_ion0.75\"\n",
    "folds_num = 5\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "#Features columns names, without the labels (the binding scores)\n",
    "features_cols = get_features_cols(features_all)\n",
    "remove_unimportant_features(features_all, features_cols)\n",
    "\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#CV splits dictionary\n",
    "# with open(curr_dir[0]+\"/CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_\"+str(prec_th)+\"_prec_dict.pik\", 'rb') as handle:\n",
    "#         splits_dict = pickle.load(handle)\n",
    "with open(curr_dir[0]+\"/CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_combined_\"+prec_th_str+\"_prec_dict.pik\", 'rb') as handle:\n",
    "        splits_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:41680\n",
      "dnabase non-binding #:42089\n",
      "dnabackbone non-binding #:41689\n",
      "dna combined non binding #: 41555\n",
      "rna non-binding #:41613\n",
      "rnabase non-binding #:41828\n",
      "rnabackbone non-binding #:41619\n",
      "rna combined non binding #: 41401\n",
      "peptide non-binding #:38794\n",
      "ion non-binding #:37525\n",
      "metabolite non-binding #:37463\n",
      "sm non-binding #:30978\n"
     ]
    }
   ],
   "source": [
    "ligands_negatives_df = create_negatives_datasets_combined(zero_prop, no_prop, features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 239\n",
      "dnabase #: 170\n",
      "dnabackbone #: 244\n",
      "dna combined #: 353\n",
      "rna #: 360\n",
      "rnabase #: 246\n",
      "rnabackbone #: 346\n",
      "rna combined #: 468\n",
      "peptide #: 462\n",
      "ion #: 350\n",
      "metabolite #: 504\n",
      "sm #: 708\n"
     ]
    }
   ],
   "source": [
    "ligands_positives_df = create_positives_datasets_combined(features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dna\n",
      "fold = 1\n",
      "classifier_method = XGB\n",
      "trial idx = 0\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dna\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    fold = environ['fold']\n",
    "except:\n",
    "    fold = \"1\"\n",
    "print \"fold = \"+fold\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"XGB\"\n",
    "print \"classifier_method = \"+classifier_method\n",
    "\n",
    "# Reading the index to generate model\n",
    "try:\n",
    "    trial_idx = int(environ[\"trial\"])\n",
    "except:\n",
    "    trial_idx = 0\n",
    "print \"trial idx = \"+ str(trial_idx)\n",
    "\n",
    "if classifier_method == \"NN\":\n",
    "    try:\n",
    "        learning_rate_ub = int(environ['learning_rate_ub'])\n",
    "        learning_rate_lb = int(environ['learning_rate_lb'])\n",
    "        batch_size_ub = int(environ['batch_size_ub'])\n",
    "        batch_size_lb = int(environ['batch_size_lb'])\n",
    "        weight_decay_ub = int(environ['weight_decay_ub'])\n",
    "        weight_decay_lb = int(environ['weight_decay_lb'])\n",
    "        beta_ub = float(environ['beta_ub'])\n",
    "        beta_lb = float(environ['beta_lb'])\n",
    "        hidden_units_1_ub = int(environ['hidden_units_1_ub'])\n",
    "        hidden_units_1_lb = int(environ['hidden_units_1_lb'])\n",
    "        hidden_units_2_ub = int(environ['hidden_units_2_ub'])\n",
    "        hidden_units_2_lb = int(environ['hidden_units_2_lb'])\n",
    "\n",
    "    except:\n",
    "        learning_rate_ub = -2\n",
    "        learning_rate_lb = -3\n",
    "        batch_size_ub = 150\n",
    "        batch_size_lb = 30\n",
    "        weight_decay_ub = -7\n",
    "        weight_decay_lb = -17\n",
    "        beta_ub = 0.95\n",
    "        beta_lb = 0.85\n",
    "        hidden_units_1_ub = 300\n",
    "        hidden_units_1_lb = 50\n",
    "        hidden_units_2_ub = 800\n",
    "        hidden_units_2_lb = 350\n",
    "    \n",
    "\n",
    "elif classifier_method == \"XGB\":\n",
    "    try:\n",
    "        n_estimators_ub =int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb =int(environ[\"n_estimators_lb\"])\n",
    "        max_depth_ub = int(environ[\"max_depth_ub\"])\n",
    "        max_depth_lb = int(environ[\"max_depth_lb\"])\n",
    "        min_child_weight_ub = int(environ[\"min_child_weight_ub\"])\n",
    "        min_child_weight_lb = int(environ[\"min_child_weight_lb\"])\n",
    "        colsample_bytree_ub = float(environ[\"colsample_bytree_ub\"])\n",
    "        colsample_bytree_lb = float(environ[\"colsample_bytree_lb\"])\n",
    "        gamma_ub = int(environ[\"gamma_ub\"])\n",
    "        gamma_lb = int(environ[\"gamma_lb\"])\n",
    "        learning_rate_ub = int(environ[\"learning_rate_ub\"])\n",
    "        learning_rate_lb = int(environ[\"learning_rate_lb\"])\n",
    "        \n",
    "    \n",
    "    except:\n",
    "        n_estimators_ub = 1500\n",
    "        n_estimators_lb = 100\n",
    "        max_depth_ub = 1500\n",
    "        max_depth_lb = 100\n",
    "        min_child_weight_ub = 2\n",
    "        min_child_weight_lb = 0\n",
    "        colsample_bytree_ub = 1\n",
    "        colsample_bytree_lb = 0.25\n",
    "        gamma_ub = 0\n",
    "        gamma_lb = -3\n",
    "        learning_rate_ub = 0\n",
    "        learning_rate_lb = -1\n",
    "        \n",
    "elif classifier_method == \"RF\":\n",
    "    try:\n",
    "        n_estimators_ub = int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb = int(environ[\"n_estimators_lb\"])\n",
    "        max_depth_ub = int(environ[\"max_depth_ub\"])\n",
    "        max_depth_lb = int(environ[\"max_depth_lb\"])\n",
    "        min_samples_leaf_ub = int(environ[\"min_samples_leaf_ub\"])\n",
    "        min_samples_leaf_lb = int(environ[\"min_samples_leaf_lb\"])\n",
    "        min_samples_split_ub = int(environ[\"min_samples_split_ub\"])\n",
    "        min_samples_split_lb = int(environ[\"min_samples_split_lb\"])\n",
    "    except:\n",
    "        n_estimators_ub = 5\n",
    "        n_estimators_lb = 2\n",
    "        max_depth_ub = 20\n",
    "        max_depth_lb = 2\n",
    "        min_samples_leaf_ub = 50\n",
    "        min_samples_leaf_lb = 1\n",
    "        min_samples_split_ub = 50\n",
    "        min_samples_split_lb = 1\n",
    "\n",
    "elif classifier_method == \"Logistic\":\n",
    "    try:\n",
    "        C_ub = int(environ[\"C_ub\"])\n",
    "        C_lb = int(environ[\"C_lb\"])\n",
    "    except:\n",
    "        C_ub = 3\n",
    "        C_lb = 1\n",
    "\n",
    "elif classifier_method == \"KNN\":\n",
    "    try:\n",
    "        n_neighbors_ub = int(environ[\"n_neighbors_ub\"])\n",
    "        n_neighbors_lb = int(environ[\"n_neighbors_lb\"])\n",
    "\n",
    "    except:\n",
    "        n_neighbors_ub = 100\n",
    "        n_neighbors_lb = 5\n",
    "        \n",
    "elif classifier_method == \"ADA\":\n",
    "    try:\n",
    "        n_estimators_ub = int(environ[\"n_estimators_ub\"])\n",
    "        n_estimators_lb = int(environ[\"n_estimators_lb\"])\n",
    "        learning_rate_ub = int(environ[\"learning_rate_ub\"])\n",
    "        learning_rate_lb = int(environ[\"learning_rate_lb\"])\n",
    "    except:\n",
    "        n_estimators_ub = 6\n",
    "        n_estimators_lb = 3\n",
    "        learning_rate_ub = 0\n",
    "        learning_rate_lb = -4\n",
    "        \n",
    "elif classifier_method == \"SVM\":\n",
    "    try:\n",
    "        C_ub = int(environ[\"C_ub\"])\n",
    "        C_lb = int(environ[\"C_lb\"])\n",
    "        gamma_ub = int(environ[\"gamma_ub\"])\n",
    "        gamma_lb = int(environ[\"gamma_lb\"])\n",
    "    except:\n",
    "        C_ub = 4\n",
    "        C_lb = 2\n",
    "        gamma_ub = -4\n",
    "        gamma_lb = -6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hyperparameter trials\n",
    "\n",
    "Choose hyperparameters and generate hyperparameters through random search in a grid, as explained by this video: https://www.youtube.com/watch?v=WrICwRrvuIc&index=66&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K\n",
    "\n",
    "Use logarithmic scale for search for learnining rate and weight decay for NN, as explained by this video: https://www.youtube.com/watch?v=VUbrW8OK3uo&index=67&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K\n",
    "\n",
    "Utilize nested cross validation to choose between models, as described here: https://stats.stackexchange.com/questions/266225/step-by-step-explanation-of-k-fold-cross-validation-with-grid-search-to-optimise/266229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n",
      "[{'colsample_bytree': 0.7020725320537329, 'scale_pos_weight': 0.1, 'learning_rate': 0.26524963767594756, 'min_child_weight': 1.430378732744839, 'n_estimators': 784, 'max_depth': 659, 'gamma': 0.04311710058685491}, {'colsample_bytree': 0.9727470703757719, 'scale_pos_weight': 0.1, 'learning_rate': 0.6190490166774184, 'min_child_weight': 1.7835460015641595, 'n_estimators': 377, 'max_depth': 699, 'gamma': 0.014135935551752292}, {'colsample_bytree': 0.9441974787194958, 'scale_pos_weight': 'balanced', 'learning_rate': 0.12221634728708944, 'min_child_weight': 1.1360891221878646, 'n_estimators': 187, 'max_depth': 274, 'gamma': 0.0016334587611069498}, {'colsample_bytree': 0.8336175632123879, 'scale_pos_weight': 1, 'learning_rate': 0.9519592150539826, 'min_child_weight': 1.665239691095876, 'n_estimators': 215, 'max_depth': 1076, 'gamma': 0.40741446541662296}, {'colsample_bytree': 0.7591596475892202, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3819616775589123, 'min_child_weight': 1.0409549591024096, 'n_estimators': 1301, 'max_depth': 855, 'gamma': 0.14517704896094835}, {'colsample_bytree': 0.32943070539084407, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1535791796043299, 'min_child_weight': 1.5172312486447144, 'n_estimators': 797, 'max_depth': 739, 'gamma': 0.026351252231361928}, {'colsample_bytree': 0.35141363005408904, 'scale_pos_weight': 0.1, 'learning_rate': 0.14114804498181488, 'min_child_weight': 0.43310070884874374, 'n_estimators': 982, 'max_depth': 1307, 'gamma': 0.009384756816024659}, {'colsample_bytree': 0.7613652243276126, 'scale_pos_weight': 1, 'learning_rate': 0.2735469984777898, 'min_child_weight': 1.8874961570292483, 'n_estimators': 856, 'max_depth': 373, 'gamma': 0.011981845126013866}, {'colsample_bytree': 0.7529784022136196, 'scale_pos_weight': 'balanced', 'learning_rate': 0.13456319729640445, 'min_child_weight': 1.3335334308913354, 'n_estimators': 1445, 'max_depth': 157, 'gamma': 0.004277083049962071}, {'colsample_bytree': 0.6776475778134097, 'scale_pos_weight': 'balanced', 'learning_rate': 0.9735849191844885, 'min_child_weight': 0.7274215418852452, 'n_estimators': 498, 'max_depth': 711, 'gamma': 0.020692098656538337}, {'colsample_bytree': 0.37098213841374716, 'scale_pos_weight': 0.1, 'learning_rate': 0.17918085415440999, 'min_child_weight': 0.4177535121896694, 'n_estimators': 1064, 'max_depth': 1171, 'gamma': 0.09105944026265277}, {'colsample_bytree': 0.5035057111291688, 'scale_pos_weight': 'balanced', 'learning_rate': 0.20758775973690646, 'min_child_weight': 1.2470202022637364, 'n_estimators': 1267, 'max_depth': 1351, 'gamma': 0.10574430003444459}, {'colsample_bytree': 0.322825956844796, 'scale_pos_weight': 1, 'learning_rate': 0.12476661940792175, 'min_child_weight': 1.6419864596958702, 'n_estimators': 269, 'max_depth': 1219, 'gamma': 0.3264635677523521}, {'colsample_bytree': 0.588369410890696, 'scale_pos_weight': 0.1, 'learning_rate': 0.27651005032334997, 'min_child_weight': 0.11142938740321262, 'n_estimators': 487, 'max_depth': 1073, 'gamma': 0.001148055797995468}, {'colsample_bytree': 0.6106701481271222, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7594092613374688, 'min_child_weight': 0.718888927938643, 'n_estimators': 655, 'max_depth': 1054, 'gamma': 0.11640819317908095}, {'colsample_bytree': 0.6738916499536565, 'scale_pos_weight': 1, 'learning_rate': 0.32282633872057603, 'min_child_weight': 0.43364427525508575, 'n_estimators': 834, 'max_depth': 223, 'gamma': 0.3938289920376665}, {'colsample_bytree': 0.3123343694729518, 'scale_pos_weight': 0.1, 'learning_rate': 0.10217783699569047, 'min_child_weight': 1.8423152204743996, 'n_estimators': 882, 'max_depth': 1165, 'gamma': 0.006810134414375388}, {'colsample_bytree': 0.8810395893980159, 'scale_pos_weight': 0.1, 'learning_rate': 0.24993136020245224, 'min_child_weight': 1.294348280375111, 'n_estimators': 870, 'max_depth': 407, 'gamma': 0.006225733021242983}, {'colsample_bytree': 0.527356069561255, 'scale_pos_weight': 0.1, 'learning_rate': 0.3712089219920516, 'min_child_weight': 0.32988092048376827, 'n_estimators': 1495, 'max_depth': 1308, 'gamma': 0.0027499531070615496}, {'colsample_bytree': 0.574966046486533, 'scale_pos_weight': 0.1, 'learning_rate': 0.24894205793717045, 'min_child_weight': 0.5769528740970573, 'n_estimators': 194, 'max_depth': 1350, 'gamma': 0.18548982077619477}, {'colsample_bytree': 0.9645617586377387, 'scale_pos_weight': 1, 'learning_rate': 0.7021156807204884, 'min_child_weight': 0.4461632652812366, 'n_estimators': 550, 'max_depth': 1372, 'gamma': 0.02194704913043539}, {'colsample_bytree': 0.8603483647768579, 'scale_pos_weight': 0.1, 'learning_rate': 0.7605069672357748, 'min_child_weight': 0.5948739017102673, 'n_estimators': 849, 'max_depth': 239, 'gamma': 0.015470958549309933}, {'colsample_bytree': 0.7693986925583244, 'scale_pos_weight': 0.1, 'learning_rate': 0.3171935751176198, 'min_child_weight': 1.7634707237097056, 'n_estimators': 1276, 'max_depth': 1025, 'gamma': 0.1498866107685077}, {'colsample_bytree': 0.6061506365567065, 'scale_pos_weight': 0.1, 'learning_rate': 0.5200852430421803, 'min_child_weight': 1.2376171291827143, 'n_estimators': 773, 'max_depth': 1028, 'gamma': 0.025727439628506717}, {'colsample_bytree': 0.9088391427070315, 'scale_pos_weight': 'balanced', 'learning_rate': 0.12370119339460328, 'min_child_weight': 1.4983396743054493, 'n_estimators': 1276, 'max_depth': 691, 'gamma': 0.0020351202519752485}, {'colsample_bytree': 0.7399006148928502, 'scale_pos_weight': 1, 'learning_rate': 0.270033991160404, 'min_child_weight': 1.1486504976991576, 'n_estimators': 1473, 'max_depth': 1253, 'gamma': 0.09042943346173951}, {'colsample_bytree': 0.9880316810231098, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3443677883129969, 'min_child_weight': 0.19451985412634776, 'n_estimators': 1107, 'max_depth': 334, 'gamma': 0.006039803128987408}, {'colsample_bytree': 0.5142337459003998, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6936495834111065, 'min_child_weight': 0.19913817822162216, 'n_estimators': 655, 'max_depth': 132, 'gamma': 0.025570988797875227}, {'colsample_bytree': 0.37513563478637474, 'scale_pos_weight': 0.1, 'learning_rate': 0.7327119853926455, 'min_child_weight': 1.0166308971577818, 'n_estimators': 723, 'max_depth': 870, 'gamma': 0.21734670410044998}, {'colsample_bytree': 0.9869312198688952, 'scale_pos_weight': 0.1, 'learning_rate': 0.2630724502302743, 'min_child_weight': 0.06644477053235454, 'n_estimators': 1049, 'max_depth': 647, 'gamma': 0.013178690305790589}, {'colsample_bytree': 0.25878556313875145, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5370201263548504, 'min_child_weight': 1.711606684785222, 'n_estimators': 976, 'max_depth': 877, 'gamma': 0.01202082275041248}, {'colsample_bytree': 0.2907534912544402, 'scale_pos_weight': 0.1, 'learning_rate': 0.10435705015393308, 'min_child_weight': 1.0420732124082586, 'n_estimators': 1168, 'max_depth': 902, 'gamma': 0.003980976140397891}, {'colsample_bytree': 0.9580898131881727, 'scale_pos_weight': 1, 'learning_rate': 0.3950530383446488, 'min_child_weight': 1.749145915289993, 'n_estimators': 390, 'max_depth': 297, 'gamma': 0.0667972522062166}, {'colsample_bytree': 0.28777754256815785, 'scale_pos_weight': 0.1, 'learning_rate': 0.9826444348404075, 'min_child_weight': 1.0000525954586028, 'n_estimators': 309, 'max_depth': 1492, 'gamma': 0.12511063378806395}, {'colsample_bytree': 0.6924324822659282, 'scale_pos_weight': 'balanced', 'learning_rate': 0.20509024102762677, 'min_child_weight': 1.0712656060499166, 'n_estimators': 423, 'max_depth': 608, 'gamma': 0.15501227443631754}, {'colsample_bytree': 0.38964475441025215, 'scale_pos_weight': 1, 'learning_rate': 0.5489727596641779, 'min_child_weight': 0.4196874979502443, 'n_estimators': 321, 'max_depth': 440, 'gamma': 0.6809530508136838}, {'colsample_bytree': 0.3139716743940254, 'scale_pos_weight': 0.1, 'learning_rate': 0.3074947493589922, 'min_child_weight': 1.361089382385559, 'n_estimators': 1446, 'max_depth': 191, 'gamma': 0.0014765732560531632}, {'colsample_bytree': 0.7132434370719101, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7155064948271145, 'min_child_weight': 1.952808773186085, 'n_estimators': 1067, 'max_depth': 374, 'gamma': 0.04241273949596576}, {'colsample_bytree': 0.6524344083315416, 'scale_pos_weight': 0.1, 'learning_rate': 0.9780002085490747, 'min_child_weight': 0.9073936891120906, 'n_estimators': 301, 'max_depth': 598, 'gamma': 0.4897944719001141}, {'colsample_bytree': 0.4219144923149346, 'scale_pos_weight': 0.1, 'learning_rate': 0.802462923540816, 'min_child_weight': 0.2744408401943892, 'n_estimators': 1140, 'max_depth': 206, 'gamma': 0.4413226300006937}, {'colsample_bytree': 0.6397833952437072, 'scale_pos_weight': 1, 'learning_rate': 0.20505021107666452, 'min_child_weight': 0.6493659441329307, 'n_estimators': 1052, 'max_depth': 959, 'gamma': 0.0010003824647975084}, {'colsample_bytree': 0.7599095923050772, 'scale_pos_weight': 'balanced', 'learning_rate': 0.30437474632070965, 'min_child_weight': 1.770675319219171, 'n_estimators': 1211, 'max_depth': 1137, 'gamma': 0.02335550791438111}, {'colsample_bytree': 0.9102232023362534, 'scale_pos_weight': 0.1, 'learning_rate': 0.906673360503355, 'min_child_weight': 0.45888366894209076, 'n_estimators': 1032, 'max_depth': 381, 'gamma': 0.008731265160089033}, {'colsample_bytree': 0.5685141015636297, 'scale_pos_weight': 1, 'learning_rate': 0.2907872928845631, 'min_child_weight': 0.4149401508822188, 'n_estimators': 1351, 'max_depth': 990, 'gamma': 0.013258974672122958}, {'colsample_bytree': 0.8978917044424235, 'scale_pos_weight': 1, 'learning_rate': 0.32913881950217044, 'min_child_weight': 1.1735686929163376, 'n_estimators': 1331, 'max_depth': 563, 'gamma': 0.002252140953021267}, {'colsample_bytree': 0.6740659838938817, 'scale_pos_weight': 0.1, 'learning_rate': 0.1395878954008348, 'min_child_weight': 0.7921194056145875, 'n_estimators': 1106, 'max_depth': 1343, 'gamma': 0.003546822939411305}, {'colsample_bytree': 0.8114977148879104, 'scale_pos_weight': 1, 'learning_rate': 0.12117762474274964, 'min_child_weight': 1.5306505076139305, 'n_estimators': 537, 'max_depth': 1120, 'gamma': 0.5142321426791348}, {'colsample_bytree': 0.9714522839104218, 'scale_pos_weight': 'balanced', 'learning_rate': 0.17411203034456033, 'min_child_weight': 1.1689521379115377, 'n_estimators': 1218, 'max_depth': 159, 'gamma': 0.007523892475314567}, {'colsample_bytree': 0.2569300551149056, 'scale_pos_weight': 1, 'learning_rate': 0.9645604140898281, 'min_child_weight': 1.1112984855402903, 'n_estimators': 1424, 'max_depth': 989, 'gamma': 0.31558350297517956}, {'colsample_bytree': 0.6342950974719278, 'scale_pos_weight': 0.1, 'learning_rate': 0.6131153029376062, 'min_child_weight': 0.36326240098409746, 'n_estimators': 1116, 'max_depth': 634, 'gamma': 0.055124087265135756}, {'colsample_bytree': 0.9619891168117611, 'scale_pos_weight': 0.1, 'learning_rate': 0.629799900013625, 'min_child_weight': 0.463403252942409, 'n_estimators': 568, 'max_depth': 500, 'gamma': 0.6670111812059986}, {'colsample_bytree': 0.46976521338084753, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4148362425557292, 'min_child_weight': 1.748575933249894, 'n_estimators': 405, 'max_depth': 443, 'gamma': 0.35223350627705396}, {'colsample_bytree': 0.83531998832801, 'scale_pos_weight': 1, 'learning_rate': 0.5669824375133657, 'min_child_weight': 1.724619554700566, 'n_estimators': 1153, 'max_depth': 1029, 'gamma': 0.901772187506922}, {'colsample_bytree': 0.5578691035708427, 'scale_pos_weight': 1, 'learning_rate': 0.19853716612014977, 'min_child_weight': 0.5389588679162354, 'n_estimators': 1109, 'max_depth': 237, 'gamma': 0.019260674699596053}, {'colsample_bytree': 0.9855247555180144, 'scale_pos_weight': 'balanced', 'learning_rate': 0.37086065421699316, 'min_child_weight': 0.24131398237223944, 'n_estimators': 1108, 'max_depth': 1383, 'gamma': 0.016533373579346547}, {'colsample_bytree': 0.8305354995239791, 'scale_pos_weight': 0.1, 'learning_rate': 0.12053172997893831, 'min_child_weight': 1.813110998442358, 'n_estimators': 750, 'max_depth': 337, 'gamma': 0.009987009341166649}, {'colsample_bytree': 0.4939827288692473, 'scale_pos_weight': 1, 'learning_rate': 0.10326386974968807, 'min_child_weight': 1.8524258603526298, 'n_estimators': 1389, 'max_depth': 703, 'gamma': 0.7221243957737429}, {'colsample_bytree': 0.4379670401454141, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6462850223374825, 'min_child_weight': 1.765719996087582, 'n_estimators': 1349, 'max_depth': 1008, 'gamma': 0.10770490659177065}, {'colsample_bytree': 0.8722016859457893, 'scale_pos_weight': 0.1, 'learning_rate': 0.12489631065582871, 'min_child_weight': 1.5042690419758675, 'n_estimators': 392, 'max_depth': 455, 'gamma': 0.01371201615695837}, {'colsample_bytree': 0.607357900412373, 'scale_pos_weight': 'balanced', 'learning_rate': 0.2874183899474959, 'min_child_weight': 1.1838703163768993, 'n_estimators': 1408, 'max_depth': 936, 'gamma': 0.02909401825264376}, {'colsample_bytree': 0.462639134936625, 'scale_pos_weight': 0.1, 'learning_rate': 0.15175777892340378, 'min_child_weight': 1.3912508912777144, 'n_estimators': 1029, 'max_depth': 737, 'gamma': 0.013796879387439818}, {'colsample_bytree': 0.40494595530645205, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4801303164322281, 'min_child_weight': 1.320079724445898, 'n_estimators': 1447, 'max_depth': 202, 'gamma': 0.3481977556728324}, {'colsample_bytree': 0.5281395994134166, 'scale_pos_weight': 0.1, 'learning_rate': 0.288307462513147, 'min_child_weight': 0.545643804848934, 'n_estimators': 1026, 'max_depth': 1273, 'gamma': 0.003900882244919025}, {'colsample_bytree': 0.6021237271959063, 'scale_pos_weight': 'balanced', 'learning_rate': 0.30790026305284757, 'min_child_weight': 0.9816372257017558, 'n_estimators': 1213, 'max_depth': 1198, 'gamma': 0.4447621983542005}, {'colsample_bytree': 0.606467081431462, 'scale_pos_weight': 'balanced', 'learning_rate': 0.36010522857767197, 'min_child_weight': 0.34822390445426454, 'n_estimators': 132, 'max_depth': 1239, 'gamma': 0.224359206505158}, {'colsample_bytree': 0.45819707329882453, 'scale_pos_weight': 'balanced', 'learning_rate': 0.24698789941043997, 'min_child_weight': 1.3627850212076758, 'n_estimators': 1256, 'max_depth': 193, 'gamma': 0.0024354638990657157}, {'colsample_bytree': 0.6578544625579947, 'scale_pos_weight': 'balanced', 'learning_rate': 0.7621516781639505, 'min_child_weight': 1.807967909856474, 'n_estimators': 475, 'max_depth': 802, 'gamma': 0.023481955729256935}, {'colsample_bytree': 0.5492689912773265, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4898070368872746, 'min_child_weight': 1.4483352732230865, 'n_estimators': 519, 'max_depth': 685, 'gamma': 0.5153866664021131}, {'colsample_bytree': 0.2703017385828926, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5847409452429984, 'min_child_weight': 1.4324883484360373, 'n_estimators': 1175, 'max_depth': 1098, 'gamma': 0.1563838929285332}, {'colsample_bytree': 0.6932381239927636, 'scale_pos_weight': 1, 'learning_rate': 0.2865652026974929, 'min_child_weight': 0.9162776545200857, 'n_estimators': 427, 'max_depth': 706, 'gamma': 0.3742552769737321}, {'colsample_bytree': 0.8655753405259863, 'scale_pos_weight': 1, 'learning_rate': 0.6539187930284103, 'min_child_weight': 1.1515023240897448, 'n_estimators': 1039, 'max_depth': 694, 'gamma': 0.5327594418289823}, {'colsample_bytree': 0.5488256939647578, 'scale_pos_weight': 1, 'learning_rate': 0.2654802707527337, 'min_child_weight': 1.2577968781234008, 'n_estimators': 841, 'max_depth': 1343, 'gamma': 0.0015421934564332134}, {'colsample_bytree': 0.5165266363539472, 'scale_pos_weight': 'balanced', 'learning_rate': 0.10383135047815754, 'min_child_weight': 1.917965443726947, 'n_estimators': 880, 'max_depth': 948, 'gamma': 0.011752240523075753}, {'colsample_bytree': 0.9469685629770355, 'scale_pos_weight': 'balanced', 'learning_rate': 0.8816608033710761, 'min_child_weight': 0.8025190016072175, 'n_estimators': 796, 'max_depth': 1244, 'gamma': 0.0019899620338785676}, {'colsample_bytree': 0.314899367649541, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6910555620849614, 'min_child_weight': 0.11193165669889571, 'n_estimators': 1362, 'max_depth': 1295, 'gamma': 0.005146593662942004}, {'colsample_bytree': 0.73737398014259, 'scale_pos_weight': 1, 'learning_rate': 0.10776191380142862, 'min_child_weight': 1.026149726343091, 'n_estimators': 934, 'max_depth': 704, 'gamma': 0.04303012742410711}, {'colsample_bytree': 0.5321699307041404, 'scale_pos_weight': 0.1, 'learning_rate': 0.9586049790315697, 'min_child_weight': 1.5421780963399294, 'n_estimators': 794, 'max_depth': 945, 'gamma': 0.02972173945010838}, {'colsample_bytree': 0.2842447314917338, 'scale_pos_weight': 0.1, 'learning_rate': 0.6784524261938246, 'min_child_weight': 0.7486463932744414, 'n_estimators': 492, 'max_depth': 866, 'gamma': 0.00851535817161396}, {'colsample_bytree': 0.46629887299862044, 'scale_pos_weight': 0.1, 'learning_rate': 0.4597318278003059, 'min_child_weight': 1.5664688766276262, 'n_estimators': 1243, 'max_depth': 496, 'gamma': 0.005299755817243635}, {'colsample_bytree': 0.568066741326887, 'scale_pos_weight': 0.1, 'learning_rate': 0.1936651693371716, 'min_child_weight': 1.0346170344045775, 'n_estimators': 1257, 'max_depth': 799, 'gamma': 0.04613849520176798}, {'colsample_bytree': 0.5204091703644191, 'scale_pos_weight': 0.1, 'learning_rate': 0.8413310398376074, 'min_child_weight': 0.829713738667128, 'n_estimators': 1249, 'max_depth': 818, 'gamma': 0.3061757170872131}, {'colsample_bytree': 0.9529632729383175, 'scale_pos_weight': 0.1, 'learning_rate': 0.24085729645857118, 'min_child_weight': 0.8981668554025792, 'n_estimators': 764, 'max_depth': 425, 'gamma': 0.005911537602431929}, {'colsample_bytree': 0.9940084325608556, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1276163017582049, 'min_child_weight': 0.5931125301280598, 'n_estimators': 562, 'max_depth': 853, 'gamma': 0.005600929719451105}, {'colsample_bytree': 0.7673261988083129, 'scale_pos_weight': 'balanced', 'learning_rate': 0.5379093572149319, 'min_child_weight': 0.4668405109361926, 'n_estimators': 437, 'max_depth': 1281, 'gamma': 0.001496473659586649}, {'colsample_bytree': 0.5342926720580714, 'scale_pos_weight': 0.1, 'learning_rate': 0.5607745009412582, 'min_child_weight': 0.544873790931925, 'n_estimators': 736, 'max_depth': 509, 'gamma': 0.013270538612281325}, {'colsample_bytree': 0.472181791278357, 'scale_pos_weight': 1, 'learning_rate': 0.22483843874091622, 'min_child_weight': 1.007867223758871, 'n_estimators': 685, 'max_depth': 246, 'gamma': 0.4548694891072422}, {'colsample_bytree': 0.6613893222098577, 'scale_pos_weight': 0.1, 'learning_rate': 0.22324547464456343, 'min_child_weight': 0.40303542664643666, 'n_estimators': 209, 'max_depth': 279, 'gamma': 0.036218335579295005}, {'colsample_bytree': 0.9958005922357596, 'scale_pos_weight': 0.1, 'learning_rate': 0.11772529250569351, 'min_child_weight': 1.9359311332084541, 'n_estimators': 590, 'max_depth': 1445, 'gamma': 0.022670706161121983}, {'colsample_bytree': 0.5631147810970089, 'scale_pos_weight': 0.1, 'learning_rate': 0.40189981290904947, 'min_child_weight': 0.3047094113754609, 'n_estimators': 1304, 'max_depth': 404, 'gamma': 0.0024766690981938002}, {'colsample_bytree': 0.26447545483830326, 'scale_pos_weight': 'balanced', 'learning_rate': 0.14075962064759423, 'min_child_weight': 0.1448688949315946, 'n_estimators': 985, 'max_depth': 712, 'gamma': 0.8683998816479346}, {'colsample_bytree': 0.6849342987988792, 'scale_pos_weight': 0.1, 'learning_rate': 0.18750329383236625, 'min_child_weight': 0.4310576231290897, 'n_estimators': 267, 'max_depth': 1028, 'gamma': 0.8457754120740337}, {'colsample_bytree': 0.48278561948485854, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3349426424455048, 'min_child_weight': 1.0117327676506167, 'n_estimators': 834, 'max_depth': 1398, 'gamma': 0.013155416174536916}, {'colsample_bytree': 0.8967389101269267, 'scale_pos_weight': 'balanced', 'learning_rate': 0.1793256956530083, 'min_child_weight': 1.8483175332415271, 'n_estimators': 272, 'max_depth': 401, 'gamma': 0.0013998157895346944}, {'colsample_bytree': 0.632971680202135, 'scale_pos_weight': 'balanced', 'learning_rate': 0.3389135526365699, 'min_child_weight': 1.0249033175181743, 'n_estimators': 1015, 'max_depth': 1286, 'gamma': 0.014470430799511038}, {'colsample_bytree': 0.7578357998749136, 'scale_pos_weight': 0.1, 'learning_rate': 0.3534771443434167, 'min_child_weight': 1.785724493934567, 'n_estimators': 465, 'max_depth': 205, 'gamma': 0.0826194222128685}, {'colsample_bytree': 0.7262925992366122, 'scale_pos_weight': 0.1, 'learning_rate': 0.2885490882613549, 'min_child_weight': 1.712605953667093, 'n_estimators': 1162, 'max_depth': 366, 'gamma': 0.00792374485419772}, {'colsample_bytree': 0.3171209087746751, 'scale_pos_weight': 0.1, 'learning_rate': 0.10575799281061614, 'min_child_weight': 1.844222923534386, 'n_estimators': 470, 'max_depth': 790, 'gamma': 0.016513037452481373}, {'colsample_bytree': 0.4593009611714488, 'scale_pos_weight': 1, 'learning_rate': 0.13052786465860491, 'min_child_weight': 1.2444621176795898, 'n_estimators': 728, 'max_depth': 281, 'gamma': 0.004258433297085862}, {'colsample_bytree': 0.9616457655403805, 'scale_pos_weight': 'balanced', 'learning_rate': 0.4438095608782328, 'min_child_weight': 1.3439142811916447, 'n_estimators': 220, 'max_depth': 445, 'gamma': 0.0010188485733850711}, {'colsample_bytree': 0.26265375502752975, 'scale_pos_weight': 'balanced', 'learning_rate': 0.6511464088300172, 'min_child_weight': 1.9255406396804848, 'n_estimators': 1022, 'max_depth': 1282, 'gamma': 0.12287040565803549}]\n"
     ]
    }
   ],
   "source": [
    "no_trials = 100\n",
    "print classifier_method\n",
    "if classifier_method == \"NN\":\n",
    "    hyperparameter_trials = generate_trials_NN(no_trials, learning_rate_ub, learning_rate_lb, batch_size_ub, batch_size_lb,weight_decay_ub, \n",
    "                                               weight_decay_lb, beta_ub, beta_lb, hidden_units_1_ub, hidden_units_1_lb, hidden_units_2_ub, \n",
    "                                               hidden_units_2_lb)\n",
    "elif classifier_method == \"XGB\":\n",
    "    hyperparameter_trials = generate_trials_XGB(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                                max_depth_ub, max_depth_lb, min_child_weight_ub,\n",
    "                                                min_child_weight_lb, colsample_bytree_ub, colsample_bytree_lb,\n",
    "                                               gamma_ub, gamma_lb, learning_rate_lb, learning_rate_ub)\n",
    "elif classifier_method == \"RF\":\n",
    "    hyperparameter_trials = generate_trials_RF(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                              max_depth_ub, max_depth_lb, min_samples_leaf_ub,\n",
    "                                              min_samples_leaf_lb, min_samples_split_ub, min_samples_split_lb)\n",
    "elif classifier_method == \"Logistic\":\n",
    "    hyperparameter_trials = generate_trials_Log(no_trials, C_ub, C_lb)\n",
    "    \n",
    "elif classifier_method == \"KNN\":\n",
    "    hyperparameter_trials = generate_trials_KNN(no_trials, n_neighbors_ub, n_neighbors_lb)\n",
    "    \n",
    "elif classifier_method == \"ADA\":\n",
    "    hyperparameter_trials = generate_trials_ADA(no_trials, n_estimators_ub, n_estimators_lb,\n",
    "                                               learning_rate_lb,learning_rate_ub)\n",
    "    \n",
    "elif classifier_method == \"SVM\":\n",
    "    hyperparameter_trials = generate_trials_SVM(no_trials, C_ub, C_lb, gamma_ub, gamma_lb)\n",
    "\n",
    "print hyperparameter_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models tested (and their hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_model(classifier_method, hyperparameters, no_pos=1, no_neg=1):\n",
    "    \n",
    "    if (classifier_method == \"XGB\"):\n",
    "        if (hyperparameters[\"scale_pos_weight\"] == \"balanced\"):\n",
    "            scale_weight = no_neg/float(no_pos)\n",
    "        else:\n",
    "            scale_weight = hyperparameters[\"scale_pos_weight\"]\n",
    "        model = XGBClassifier(n_estimators=hyperparameters[\"n_estimators\"], n_jobs=-1, random_state=0, max_depth=hyperparameters[\"max_depth\"], \n",
    "                              min_child_weight=1, colsample_bytree=hyperparameters[\"colsample_bytree\"], \n",
    "                              gamma=hyperparameters[\"gamma\"], learning_rate=hyperparameters[\"learning_rate\"], scale_pos_weight=scale_weight)\n",
    "        \n",
    "    elif (classifier_method == \"RF\"):\n",
    "        model = RandomForestClassifier(n_estimators=hyperparameters[\"n_estimators\"], n_jobs=-1, random_state=0,\n",
    "                                      max_depth=hyperparameters[\"max_depth\"], min_samples_leaf=hyperparameters[\"min_samples_leaf\"],\n",
    "                                      min_samples_split=hyperparameters[\"min_samples_split\"], class_weight=hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif(classifier_method == \"Logistic\"):\n",
    "        model = LogisticRegression(C=hyperparameters[\"C\"], random_state=0, n_jobs=-1, class_weight=hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif (classifier_method == \"KNN\"):\n",
    "        model = KNeighborsClassifier(n_neighbors=hyperparameters[\"n_neighbors\"], n_jobs=-1, weights=hyperparameters[\"weights\"])\n",
    "        \n",
    "    elif (classifier_method == \"ADA\"):\n",
    "        model = AdaBoostClassifier(n_estimators=hyperparameters[\"n_estimators\"], random_state=0, learning_rate=hyperparameters[\"learning_rate\"])\n",
    "        \n",
    "    elif (classifier_method == \"SVM\"):\n",
    "        model = SVC(C=hyperparameters[\"C\"], gamma = hyperparameters[\"gamma\"], kernel=hyperparameters[\"kernel\"], probability=True, random_state=0, cache_size=400,\n",
    "                    class_weight = hyperparameters[\"class_weight\"])\n",
    "        \n",
    "    elif (classifier_method ==\"NN\"):\n",
    "        torch.manual_seed(0)\n",
    "        model = Net(hyperparameters)\n",
    "        # sets model in training mode because batch normalization behavior in training and testing modes are different\n",
    "        model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7020725320537329, 'scale_pos_weight': 0.1, 'learning_rate': 0.26524963767594756, 'min_child_weight': 1.430378732744839, 'n_estimators': 784, 'max_depth': 659, 'gamma': 0.04311710058685491}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=0.702072532054, gamma=0.0431171005869,\n",
      "       learning_rate=0.5, max_delta_step=0, max_depth=659,\n",
      "       min_child_weight=1, missing=None, n_estimators=784, n_jobs=-1,\n",
      "       nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=0.1, seed=None,\n",
      "       silent=False, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "# Generate trial for model\n",
    "hyperparameters = hyperparameter_trials[trial_idx]\n",
    "model = generate_model(classifier_method, hyperparameters)\n",
    "print hyperparameters\n",
    "print model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Network\n",
    "\n",
    "Tutorial for Neural Net Architecture: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html\n",
    "\n",
    "Utilize batch normalization, as explained here: https://www.youtube.com/watch?v=fv1Luwd-LOI&index=69&list=PLBAGcD3siRDguyYYzhVwZ3tLvOyyG5k6K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the network with batch normalization\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "        hidden_units_1 = hyperparameters[\"hidden_units_1\"]\n",
    "        hidden_units_2 = hyperparameters[\"hidden_units_2\"]\n",
    "        super(Net, self).__init__()\n",
    "        self.input = nn.Linear(len(features_cols), hidden_units_1) # read input size from the .shape of data table\n",
    "        self.hidden1 = nn.Linear(hidden_units_1, hidden_units_2)\n",
    "        self.hidden1_bn = nn.BatchNorm1d(hidden_units_2)\n",
    "        self.hidden2 = nn.Linear(hidden_units_2, hidden_units_2)\n",
    "        self.hidden2_bn = nn.BatchNorm1d(hidden_units_2)\n",
    "        self.hidden3 = nn.Linear(hidden_units_2, hidden_units_1)\n",
    "        self.hidden3_bn = nn.BatchNorm1d(hidden_units_1)\n",
    "        self.output = nn.Linear(hidden_units_1,2)\n",
    "        self.batch_size = hyperparameters[\"batch_size\"]\n",
    "        self.learning_rate = hyperparameters[\"learning_rate\"]\n",
    "        self.beta = hyperparameters[\"beta\"]\n",
    "        self.weight_decay = hyperparameters[\"weight_decay\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden1_bn(self.hidden1(x)))\n",
    "        x = F.relu(self.hidden2_bn(self.hidden2(x)))\n",
    "        x = F.relu(self.hidden3_bn(self.hidden3(x)))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "    def fit(self, X_train, y_train_label, X_valid, y_valid, weight):\n",
    "\n",
    "        # set random seed for weights and biases\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        # dataset\n",
    "        dataset = pd.concat([X_train,y_train_label],axis=1)\n",
    "        dataset = shuffle(dataset, random_state = 0)\n",
    "\n",
    "        X_train = dataset.iloc[:,:dataset.shape[1]-1]\n",
    "        y_train_label = dataset.iloc[:,dataset.shape[1]-1]\n",
    "\n",
    "\n",
    "        # create loss function\n",
    "        loss = nn.CrossEntropyLoss(weight = weight)\n",
    "        # mini-batching\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        # create adam optimizer for Phase 1\n",
    "        optimizer_1 = optim.Adam(self.parameters(), lr=self.learning_rate,betas=(self.beta,0.999), \n",
    "                                 weight_decay = self.weight_decay)\n",
    "        no_batch_minus_1 = X_train.shape[0] / batch_size \n",
    "\n",
    "        # Repeated Stratified K Fold to ensure positives are evenly distributed across batches\n",
    "        skf_1 = RepeatedStratifiedKFold(n_splits=no_batch_minus_1,n_repeats=301,random_state=0)\n",
    "        count = 0\n",
    "        epoch_count = 0\n",
    "        prev_score = 0\n",
    "        patience = 100 \n",
    "\n",
    "        for train,test in skf_1.split(X_train,y_train_label):\n",
    "            data = X_train.iloc[test,:]\n",
    "            data = torch.Tensor(data.values.astype(np.float32))\n",
    "             # forward pass\n",
    "            output = self.forward(data)\n",
    "            output.data = output.data.view(data.shape[0],2)\n",
    "\n",
    "            labels = y_train_label[test]\n",
    "            labels = torch.Tensor(labels.astype(np.float32))\n",
    "            labels = torch.autograd.Variable(labels).long()\n",
    "\n",
    "            # zero the gradient buffers\n",
    "            optimizer_1.zero_grad()\n",
    "            # compute loss and gradients\n",
    "            loss_output = loss(output,labels)\n",
    "            loss_output.backward()\n",
    "            # Does the update\n",
    "            optimizer_1.step()\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "            # Early Stopping\n",
    "            if count == no_batch_minus_1 + 1:\n",
    "                count = 0\n",
    "                epoch_count = epoch_count + 1\n",
    "                probs = self.predict_proba(X_valid)\n",
    "                precision, recall, _ = precision_recall_curve(y_valid, probs)\n",
    "                auprc = auc(recall, precision)\n",
    "                if auprc > max_auprc:\n",
    "                    max_auprc = auprc\n",
    "                    ideal_epoch_count = epoch_count\n",
    "                    patience = patience + epoch_count\n",
    "                    patience_j = 0\n",
    "                else:\n",
    "                    patience_j = patience_j + 1 \n",
    "                    if patience_j == patience: break\n",
    "                \n",
    "                self = self.train()                   \n",
    "                #score = roc_auc_score(y_valid, probs)\n",
    "        return max_auprc, ideal_epoch_count\n",
    "\n",
    "        \n",
    "    #prediction probabilities array\n",
    "    def predict_proba(self, X_test):\n",
    "        self.eval()\n",
    "        #forward pass\n",
    "        test = torch.Tensor(X_test.values.astype(np.float32))\n",
    "        output = self.forward(test)\n",
    "        sf = nn.Softmax()\n",
    "        probs = sf(output.data)\n",
    "        return probs[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with model imbalance\n",
    "Weight Vector: https://towardsdatascience.com/dealing-with-imbalanced-classes-in-machine-learning-d43d6fa19d2 (look at section on \"Cost-sensitive Learning\")\n",
    "\n",
    "Implementing Early Stopping for XGBoost: https://cambridgespark.com/content/tutorials/hyperparameter-tuning-in-xgboost/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model_iterative_fixed(hyperparameters_dict,ligand_bind_features, ligand_negatives_features, ligand_name, features=[]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test different models in k-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "    \n",
    "    models_req_scaling = [\"SVM\", \"KNN\", \"Logistic\", \"NN\"]\n",
    "    classifier = classifier_method\n",
    "\n",
    "    #Create X and y with included features\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    y_df = pd.DataFrame(y)\n",
    "    y_df.index = X.index\n",
    "    y_df.columns = [\"label\"]\n",
    "    \n",
    "    #Get the fold indices\n",
    "    cv_idx = calc_CV_idx_iterative(X, splits_dict)\n",
    "    k = (int(fold)-1)\n",
    "    \n",
    "    pred_idx = k+1\n",
    "    print \"fold #: \"+str(pred_idx)\n",
    "    #test_index = cv_idx[k][\"test\"]\n",
    "    full_train_index = cv_idx[k][\"train\"]\n",
    "        \n",
    "    # phase 1: testing on validation set, hyperparameter tuning\n",
    "    \n",
    "    trial_results = np.zeros(folds_num-1)\n",
    "    epoch_counts = np.zeros(folds_num-1, dtype = \"int\")\n",
    "    for i in range(folds_num-1):\n",
    "        valid_k = (k + 1 + i) % folds_num\n",
    "        valid_index = cv_idx[valid_k][\"test\"]\n",
    "\n",
    "        train_index = [index for index in full_train_index if index not in valid_index]\n",
    "        X_train, X_valid = X.loc[train_index,:], X.loc[valid_index,:]\n",
    "        y_train, y_valid = y_df.loc[train_index,:], y_df.loc[valid_index,:]\n",
    "\n",
    "        if (classifier in models_req_scaling):\n",
    "            cols = X_train.columns\n",
    "\n",
    "            # phase 1 scaling with just training data\n",
    "            scaler_1 = StandardScaler() \n",
    "            scaler_1.fit(X_train) \n",
    "            X_train = pd.DataFrame(scaler_1.transform(X_train))\n",
    "            # apply same transformation to validation data\n",
    "            X_valid = pd.DataFrame(scaler_1.transform(X_valid))\n",
    "\n",
    "            #Restoring indices after scaling\n",
    "            X_train.index = train_index \n",
    "            X_valid.index = valid_index\n",
    "\n",
    "            #Restoring features names\n",
    "            X_train.columns = cols\n",
    "            X_valid.columns = cols\n",
    "\n",
    "        #No down-sampling\n",
    "        X_train_sampled = X_train\n",
    "        y_train_sampled = y_train\n",
    "\n",
    "        #pos and neg numbers in the training\n",
    "        #no_pos = np.count_nonzero(y_train_sampled[\"label\"] == 1)\n",
    "        #no_neg = np.count_nonzero(y_train_sampled[\"label\"] == 0)\n",
    "\n",
    "        #fit to training data\n",
    "        if (classifier == \"NN\"):\n",
    "            #weight vector\n",
    "            #neg_weight = float(no_pos) / float(no_neg + no_pos) \n",
    "            #pos_weight = 1 - neg_weight\n",
    "            neg_weight = 10\n",
    "            pos_weight = 1\n",
    "            weight = torch.Tensor([neg_weight, pos_weight])\n",
    "            auprc_score,epoch_count = model.fit(X_train_sampled, y_train_sampled[\"label\"],X_valid, y_valid[\"label\"], weight)\n",
    "        \n",
    "\n",
    "        elif (classifier == \"XGB\"):\n",
    "            num_early_stopping_rounds = 10\n",
    "            model.fit(X_train_sampled, y_train_sampled[\"label\"], eval_set = [(X_train_sampled, y_train_sampled[\"label\"]),(X_valid,y_valid[\"label\"])], eval_metric = \"map\", \n",
    "                      early_stopping_rounds = num_early_stopping_rounds)\n",
    "            probs_list = []\n",
    "            probs = model.predict_proba(X_valid, ntree_limit=model.best_ntree_limit)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "            precision, recall, _ = precision_recall_curve(y_valid, probs_list)\n",
    "            auprc_score = auc(recall, precision)\n",
    "            epoch_count = model.best_iteration + 1\n",
    "            \n",
    "\n",
    "        else:\n",
    "            model.fit(X_train_sampled, y_train_sampled[\"label\"])\n",
    "            probs_list = []\n",
    "            probs = model.predict_proba(X_valid)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "            precision, recall, _ = precision_recall_curve(y_valid, probs_list)\n",
    "            auprc_score = auc(recall, precision)\n",
    "\n",
    "        trial_results[i] = auprc_score \n",
    "        if classifier == \"NN\" or classifier == \"XGB\": epoch_counts[i] = epoch_count\n",
    "\n",
    "    mean_result = np.mean(trial_results)\n",
    "    if classifier == \"NN\" or classifier == \"XGB\":\n",
    "        mean_epoch_count = int(np.mean(epoch_counts))\n",
    "        hyperparameters_dict[\"mean_epoch_count\"] = mean_epoch_count\n",
    "\n",
    "    hyperparameters_dict[\"mean_AUPRC\"] = mean_result\n",
    "\n",
    "    # Update dictionary with all hyperparameters\n",
    "    keys = hyperparameters.keys()\n",
    "    for key in keys:\n",
    "        hyperparameters_dict[key].append(hyperparameters[key])\n",
    "    pred_idx += 1\n",
    "\n",
    "    print \"Finished \"+ligand+\" \"+classifier+\" fold: \"+fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #: 1\n",
      "[0]\tvalidation_0-map:1\tvalidation_1-map:0.007397\n",
      "Multiple eval metrics have been passed: 'validation_1-map' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.65843\tvalidation_1-map:0.007397\n",
      "[2]\tvalidation_0-map:0.363898\tvalidation_1-map:0.012856\n",
      "[3]\tvalidation_0-map:0.450897\tvalidation_1-map:0.018285\n",
      "[4]\tvalidation_0-map:0.49223\tvalidation_1-map:0.015543\n",
      "[5]\tvalidation_0-map:0.526557\tvalidation_1-map:0.018922\n",
      "[6]\tvalidation_0-map:0.577719\tvalidation_1-map:0.016723\n",
      "[7]\tvalidation_0-map:0.625582\tvalidation_1-map:0.015852\n",
      "[8]\tvalidation_0-map:0.686675\tvalidation_1-map:0.041031\n",
      "[9]\tvalidation_0-map:0.734676\tvalidation_1-map:0.043373\n",
      "[10]\tvalidation_0-map:0.770941\tvalidation_1-map:0.042223\n",
      "[11]\tvalidation_0-map:0.800372\tvalidation_1-map:0.057823\n",
      "[12]\tvalidation_0-map:0.812937\tvalidation_1-map:0.082492\n",
      "[13]\tvalidation_0-map:0.831224\tvalidation_1-map:0.078542\n",
      "[14]\tvalidation_0-map:0.842332\tvalidation_1-map:0.086635\n",
      "[15]\tvalidation_0-map:0.85703\tvalidation_1-map:0.107692\n",
      "[16]\tvalidation_0-map:0.870359\tvalidation_1-map:0.103775\n",
      "[17]\tvalidation_0-map:0.881356\tvalidation_1-map:0.109878\n",
      "[18]\tvalidation_0-map:0.895878\tvalidation_1-map:0.102602\n",
      "[19]\tvalidation_0-map:0.905643\tvalidation_1-map:0.11371\n",
      "[20]\tvalidation_0-map:0.915954\tvalidation_1-map:0.11973\n",
      "[21]\tvalidation_0-map:0.92459\tvalidation_1-map:0.129918\n",
      "[22]\tvalidation_0-map:0.936991\tvalidation_1-map:0.123775\n",
      "[23]\tvalidation_0-map:0.945251\tvalidation_1-map:0.121133\n",
      "[24]\tvalidation_0-map:0.951364\tvalidation_1-map:0.128303\n",
      "[25]\tvalidation_0-map:0.957916\tvalidation_1-map:0.137686\n",
      "[26]\tvalidation_0-map:0.960191\tvalidation_1-map:0.152654\n",
      "[27]\tvalidation_0-map:0.964564\tvalidation_1-map:0.148844\n",
      "[28]\tvalidation_0-map:0.969745\tvalidation_1-map:0.159025\n",
      "[29]\tvalidation_0-map:0.979598\tvalidation_1-map:0.156806\n",
      "[30]\tvalidation_0-map:0.985097\tvalidation_1-map:0.157476\n",
      "[31]\tvalidation_0-map:0.988648\tvalidation_1-map:0.157753\n",
      "[32]\tvalidation_0-map:0.991031\tvalidation_1-map:0.157762\n",
      "[33]\tvalidation_0-map:0.994197\tvalidation_1-map:0.145092\n",
      "[34]\tvalidation_0-map:0.995265\tvalidation_1-map:0.149283\n",
      "[35]\tvalidation_0-map:0.996031\tvalidation_1-map:0.142882\n",
      "[36]\tvalidation_0-map:0.996542\tvalidation_1-map:0.141607\n",
      "[37]\tvalidation_0-map:0.997149\tvalidation_1-map:0.148358\n",
      "[38]\tvalidation_0-map:0.997208\tvalidation_1-map:0.145243\n",
      "Stopping. Best iteration:\n",
      "[28]\tvalidation_0-map:0.969745\tvalidation_1-map:0.159025\n",
      "\n",
      "[0]\tvalidation_0-map:1\tvalidation_1-map:0.009681\n",
      "Multiple eval metrics have been passed: 'validation_1-map' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.563683\tvalidation_1-map:0.009681\n",
      "[2]\tvalidation_0-map:0.49515\tvalidation_1-map:0.009681\n",
      "[3]\tvalidation_0-map:0.420243\tvalidation_1-map:0.009681\n",
      "[4]\tvalidation_0-map:0.354593\tvalidation_1-map:0.042902\n",
      "[5]\tvalidation_0-map:0.410827\tvalidation_1-map:0.070434\n",
      "[6]\tvalidation_0-map:0.466137\tvalidation_1-map:0.065112\n",
      "[7]\tvalidation_0-map:0.511832\tvalidation_1-map:0.073411\n",
      "[8]\tvalidation_0-map:0.577416\tvalidation_1-map:0.074764\n",
      "[9]\tvalidation_0-map:0.618844\tvalidation_1-map:0.114892\n",
      "[10]\tvalidation_0-map:0.675041\tvalidation_1-map:0.110094\n",
      "[11]\tvalidation_0-map:0.708592\tvalidation_1-map:0.090833\n",
      "[12]\tvalidation_0-map:0.738933\tvalidation_1-map:0.09085\n",
      "[13]\tvalidation_0-map:0.757572\tvalidation_1-map:0.097275\n",
      "[14]\tvalidation_0-map:0.77981\tvalidation_1-map:0.092877\n",
      "[15]\tvalidation_0-map:0.805954\tvalidation_1-map:0.091807\n",
      "[16]\tvalidation_0-map:0.828388\tvalidation_1-map:0.094052\n",
      "[17]\tvalidation_0-map:0.839861\tvalidation_1-map:0.090658\n",
      "[18]\tvalidation_0-map:0.851165\tvalidation_1-map:0.086645\n",
      "[19]\tvalidation_0-map:0.859564\tvalidation_1-map:0.094472\n",
      "Stopping. Best iteration:\n",
      "[9]\tvalidation_0-map:0.618844\tvalidation_1-map:0.114892\n",
      "\n",
      "[0]\tvalidation_0-map:0.929518\tvalidation_1-map:0.007651\n",
      "Multiple eval metrics have been passed: 'validation_1-map' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.724355\tvalidation_1-map:0.007651\n",
      "[2]\tvalidation_0-map:0.577071\tvalidation_1-map:0.012246\n",
      "[3]\tvalidation_0-map:0.417494\tvalidation_1-map:0.028906\n",
      "[4]\tvalidation_0-map:0.340624\tvalidation_1-map:0.077626\n",
      "[5]\tvalidation_0-map:0.451903\tvalidation_1-map:0.0344\n",
      "[6]\tvalidation_0-map:0.521168\tvalidation_1-map:0.029801\n",
      "[7]\tvalidation_0-map:0.580252\tvalidation_1-map:0.03214\n",
      "[8]\tvalidation_0-map:0.651451\tvalidation_1-map:0.068765\n",
      "[9]\tvalidation_0-map:0.714568\tvalidation_1-map:0.082659\n",
      "[10]\tvalidation_0-map:0.745756\tvalidation_1-map:0.082263\n",
      "[11]\tvalidation_0-map:0.765116\tvalidation_1-map:0.094295\n",
      "[12]\tvalidation_0-map:0.791975\tvalidation_1-map:0.104027\n",
      "[13]\tvalidation_0-map:0.81862\tvalidation_1-map:0.140611\n",
      "[14]\tvalidation_0-map:0.837835\tvalidation_1-map:0.150548\n",
      "[15]\tvalidation_0-map:0.859121\tvalidation_1-map:0.160188\n",
      "[16]\tvalidation_0-map:0.871401\tvalidation_1-map:0.165058\n",
      "[17]\tvalidation_0-map:0.881984\tvalidation_1-map:0.167309\n",
      "[18]\tvalidation_0-map:0.894452\tvalidation_1-map:0.169602\n",
      "[19]\tvalidation_0-map:0.903365\tvalidation_1-map:0.163992\n",
      "[20]\tvalidation_0-map:0.919212\tvalidation_1-map:0.176873\n",
      "[21]\tvalidation_0-map:0.926565\tvalidation_1-map:0.19107\n",
      "[22]\tvalidation_0-map:0.933299\tvalidation_1-map:0.188895\n",
      "[23]\tvalidation_0-map:0.943094\tvalidation_1-map:0.186163\n",
      "[24]\tvalidation_0-map:0.950406\tvalidation_1-map:0.188578\n",
      "[25]\tvalidation_0-map:0.952697\tvalidation_1-map:0.19071\n",
      "[26]\tvalidation_0-map:0.95671\tvalidation_1-map:0.199108\n",
      "[27]\tvalidation_0-map:0.959194\tvalidation_1-map:0.199387\n",
      "[28]\tvalidation_0-map:0.962341\tvalidation_1-map:0.202713\n",
      "[29]\tvalidation_0-map:0.966091\tvalidation_1-map:0.212436\n",
      "[30]\tvalidation_0-map:0.968815\tvalidation_1-map:0.208715\n",
      "[31]\tvalidation_0-map:0.975619\tvalidation_1-map:0.209024\n",
      "[32]\tvalidation_0-map:0.977789\tvalidation_1-map:0.204692\n",
      "[33]\tvalidation_0-map:0.980414\tvalidation_1-map:0.206793\n",
      "[34]\tvalidation_0-map:0.982898\tvalidation_1-map:0.206517\n",
      "[35]\tvalidation_0-map:0.985105\tvalidation_1-map:0.208639\n",
      "[36]\tvalidation_0-map:0.987131\tvalidation_1-map:0.205743\n",
      "[37]\tvalidation_0-map:0.989991\tvalidation_1-map:0.201553\n",
      "[38]\tvalidation_0-map:0.991286\tvalidation_1-map:0.202528\n",
      "[39]\tvalidation_0-map:0.992326\tvalidation_1-map:0.200678\n",
      "Stopping. Best iteration:\n",
      "[29]\tvalidation_0-map:0.966091\tvalidation_1-map:0.212436\n",
      "\n",
      "[0]\tvalidation_0-map:1\tvalidation_1-map:0.007874\n",
      "Multiple eval metrics have been passed: 'validation_1-map' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-map hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-map:0.897776\tvalidation_1-map:0.007874\n",
      "[2]\tvalidation_0-map:0.595816\tvalidation_1-map:0.007874\n",
      "[3]\tvalidation_0-map:0.332831\tvalidation_1-map:0.007874\n",
      "[4]\tvalidation_0-map:0.214798\tvalidation_1-map:0.113566\n",
      "[5]\tvalidation_0-map:0.344165\tvalidation_1-map:0.127994\n",
      "[6]\tvalidation_0-map:0.509346\tvalidation_1-map:0.246501\n",
      "[7]\tvalidation_0-map:0.591512\tvalidation_1-map:0.307377\n",
      "[8]\tvalidation_0-map:0.668327\tvalidation_1-map:0.317895\n",
      "[9]\tvalidation_0-map:0.707804\tvalidation_1-map:0.29345\n",
      "[10]\tvalidation_0-map:0.739129\tvalidation_1-map:0.295555\n",
      "[11]\tvalidation_0-map:0.763856\tvalidation_1-map:0.322676\n",
      "[12]\tvalidation_0-map:0.780185\tvalidation_1-map:0.352109\n",
      "[13]\tvalidation_0-map:0.801357\tvalidation_1-map:0.397497\n",
      "[14]\tvalidation_0-map:0.821332\tvalidation_1-map:0.39916\n",
      "[15]\tvalidation_0-map:0.836751\tvalidation_1-map:0.393005\n",
      "[16]\tvalidation_0-map:0.850364\tvalidation_1-map:0.425208\n",
      "[17]\tvalidation_0-map:0.859079\tvalidation_1-map:0.433955\n",
      "[18]\tvalidation_0-map:0.870173\tvalidation_1-map:0.448538\n",
      "[19]\tvalidation_0-map:0.885034\tvalidation_1-map:0.440053\n",
      "[20]\tvalidation_0-map:0.894793\tvalidation_1-map:0.438931\n",
      "[21]\tvalidation_0-map:0.904404\tvalidation_1-map:0.437355\n",
      "[22]\tvalidation_0-map:0.912843\tvalidation_1-map:0.464306\n",
      "[23]\tvalidation_0-map:0.91969\tvalidation_1-map:0.44873\n",
      "[24]\tvalidation_0-map:0.927768\tvalidation_1-map:0.443649\n",
      "[25]\tvalidation_0-map:0.934905\tvalidation_1-map:0.443014\n",
      "[26]\tvalidation_0-map:0.939907\tvalidation_1-map:0.465121\n",
      "[27]\tvalidation_0-map:0.945036\tvalidation_1-map:0.466343\n",
      "[28]\tvalidation_0-map:0.951139\tvalidation_1-map:0.461346\n",
      "[29]\tvalidation_0-map:0.953759\tvalidation_1-map:0.464802\n",
      "[30]\tvalidation_0-map:0.959405\tvalidation_1-map:0.465144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31]\tvalidation_0-map:0.962302\tvalidation_1-map:0.47677\n",
      "[32]\tvalidation_0-map:0.967179\tvalidation_1-map:0.474169\n",
      "[33]\tvalidation_0-map:0.969855\tvalidation_1-map:0.476939\n",
      "[34]\tvalidation_0-map:0.973365\tvalidation_1-map:0.485777\n",
      "[35]\tvalidation_0-map:0.976331\tvalidation_1-map:0.487091\n",
      "[36]\tvalidation_0-map:0.980746\tvalidation_1-map:0.491812\n",
      "[37]\tvalidation_0-map:0.982192\tvalidation_1-map:0.491942\n",
      "[38]\tvalidation_0-map:0.984091\tvalidation_1-map:0.491445\n",
      "[39]\tvalidation_0-map:0.984572\tvalidation_1-map:0.496653\n",
      "[40]\tvalidation_0-map:0.986879\tvalidation_1-map:0.492137\n",
      "[41]\tvalidation_0-map:0.988519\tvalidation_1-map:0.482521\n",
      "[42]\tvalidation_0-map:0.98919\tvalidation_1-map:0.482838\n",
      "[43]\tvalidation_0-map:0.990154\tvalidation_1-map:0.49053\n",
      "[44]\tvalidation_0-map:0.991702\tvalidation_1-map:0.489602\n",
      "[45]\tvalidation_0-map:0.992218\tvalidation_1-map:0.487939\n",
      "[46]\tvalidation_0-map:0.9937\tvalidation_1-map:0.486957\n",
      "[47]\tvalidation_0-map:0.995261\tvalidation_1-map:0.472639\n",
      "[48]\tvalidation_0-map:0.996189\tvalidation_1-map:0.473338\n",
      "[49]\tvalidation_0-map:0.996884\tvalidation_1-map:0.464195\n",
      "Stopping. Best iteration:\n",
      "[39]\tvalidation_0-map:0.984572\tvalidation_1-map:0.496653\n",
      "\n",
      "Finished dna XGB fold: 1\n",
      "Finished ligand dna\n",
      "CPU times: user 3min 32s, sys: 13.7 s, total: 3min 46s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize dictionary\n",
    "hyperparameters_dict = defaultdict(list)\n",
    "\n",
    "test_model_iterative_fixed(hyperparameters_dict,ligands_positives_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "\n",
    "hyperparameters_df = pd.DataFrame.from_dict(hyperparameters_dict)\n",
    "\n",
    "#Save to file\n",
    "hyperparameters_df.to_csv(curr_dir[0]+\"/hyperparam_tuning/phase1_initial_run/\"+datafile_date+\"_\"+prec_th_str+\"/per_trial/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_trial\"+str(trial_idx)+\"_\"+str(folds_num)+\"w_hyperparameters.csv\", sep='\\t')\n",
    "\n",
    "print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

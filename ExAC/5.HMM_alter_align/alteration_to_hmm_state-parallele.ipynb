{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from os import environ\n",
    "import pickle\n",
    "import fileinput\n",
    "import sys\n",
    "import datetime\n",
    "from mapping_func import create_exon_pos_table, find_chrom_bps, protein_pos_to_hmm_state_and_aa\n",
    "from calc_exac_freq_func import create_alt_codon, exac_validation_checks, retrieve_codon_seq, codon_table\n",
    "from indels_func import is_indel, table_editing, indel_type\n",
    "from entropy_func import JSD_background, JSD, SE, JSdiv\n",
    "from af_format_calc import format_af, calculate_af_adj\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collagen\n"
     ]
    }
   ],
   "source": [
    "#Getting path\n",
    "curr_dir = !pwd\n",
    "\n",
    "#Reading the list of filtered domains\n",
    "with open(curr_dir[0]+\"/../5.domains_stats/filtered10_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list10 = pickle.load(handle)\n",
    "filtered_domains_list10.sort()\n",
    "\n",
    "#Getting the domain index as environment variable called \"idx\"\n",
    "try:\n",
    "    domain_index = int(environ['idx'])\n",
    "except:\n",
    "    domain_index = 0\n",
    "domain_name = filtered_domains_list10[domain_index]\n",
    "\n",
    "print domain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = curr_dir[0]+\"/../3.parse_HMMER/hmm_domains/pfam-v30/\"\n",
    "filename = domain_name+\".csv\"\n",
    "domain_data = pd.read_csv(in_path+filename, sep='\\t', index_col=0, dtype={\"chrom_num\": str})\n",
    "#Sort the domain data\n",
    "sorted_domain_data = domain_data.sort_values(by=[\"chrom_num\", \"gene\", \"TargetStart\"])\n",
    "sorted_domain_data = sorted_domain_data.reset_index(drop=True)\n",
    "\n",
    "#Get the canonic protein id for the domain\n",
    "with open(curr_dir[0]+\"/../4.parse_Uniprot/domains_canonic_prot/pfam-v30/\"+domain_name+\"_canonic_prot.pik\", 'rb') as handle:\n",
    "    canonic_protein = pickle.load(handle)\n",
    "\n",
    "chromosome_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"X\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving outside 756 out of 2166\n"
     ]
    }
   ],
   "source": [
    "#Counting how many domains instances are excluded because of strange chrom names.\n",
    "chrom_names_list = sorted_domain_data[\"chrom_num\"].tolist()\n",
    "strange_chrom_sum = 0\n",
    "for name in chrom_names_list:\n",
    "    if (name not in chromosome_names):\n",
    "        strange_chrom_sum += 1\n",
    "print \"Leaving outside \"+str(strange_chrom_sum)+\" out of \"+str(len(chrom_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_codon_notation(aa):\n",
    "    \"\"\"Coverting the HMMER 'x' char to '*' for stop codon notation unifirmity\"\"\"\n",
    "    if (aa == 'X'):\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_HMMER_hg19_codon(bp_ref, aa, chrom_pos_list, protein_pos, hmm_state):\n",
    "    \"\"\"Validation: checking that the returned codon sequence from hg19 match the HMMER amino-acid\"\"\"\n",
    "\n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    translated_aa = codon_table[bp_ref.upper()]\n",
    "    if (translated_aa != aa):\n",
    "        print \"chrom_pos_list = \"+str(chrom_pos_list)+\" protein_pos = \"+str(protein_pos)+\" hmm_state = \"+str(hmm_state)\n",
    "        print functionNameAsString+\" Error: hg19 codon sequence retrieved \"+bp_ref.upper()+\"=\"+translated_aa+\" doesn't match HMMER amino-acid \"+aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_exac_aa(exac_prot_data, exac_alt_aa, alt_aa, chrom_pos):\n",
    "    \"\"\"Validation: checking if the calculated aa matches the ExAC aa\"\"\"\n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    if (exac_prot_data and exac_alt_aa != alt_aa):\n",
    "        print functionNameAsString+\" \"+ str(chrom_pos)+\" Error: the ExAC alt aa \"+exac_alt_aa+\" doesn't match my alt aa calculation \"+alt_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_ref_aa(res_dict, alterations_af_dict, alterations_af_adj_dict, aa, aa_sum, aa_adj_sum, bp_af_dict, bp_af_adj_dict):\n",
    "    \"\"\"Changing the ref aa and updating all relevant dictionaries\"\"\"\n",
    "    \n",
    "    #Adding the refrence allele to the alterations dicts\n",
    "    old_ref = res_dict[\"aa_ref\"]\n",
    "    sum_of_all_alt = sum(sum(alterations_af_dict.values(), []))\n",
    "    sum_of_all_alt_adj = sum(sum(alterations_af_adj_dict.values(), []))\n",
    "    alterations_af_dict[old_ref] = [1 - sum_of_all_alt]\n",
    "    alterations_af_adj_dict[old_ref] = [1 - sum_of_all_alt_adj]\n",
    "\n",
    "    #Updating the aa to be the ref\n",
    "    res_dict[\"aa_ref\"] = aa\n",
    "\n",
    "    #Finding the codon that codes aa with highest frequency and update bp_ref\n",
    "    old_bp_ref = res_dict[\"bp_ref\"]\n",
    "    max_af = 0\n",
    "    for codon in (bp_af_adj_dict.keys()):\n",
    "        if (codon_table[codon.upper()] == aa):\n",
    "            if (bp_af_adj_dict[codon] >= max_af):\n",
    "                max_af = bp_af_adj_dict[codon]\n",
    "                res_dict[\"bp_ref\"] = codon\n",
    "                \n",
    "    #Adding the ref bp to the bp dicts\n",
    "    bp_af_dict[old_bp_ref] = res_dict[\"af\"]\n",
    "    bp_af_adj_dict[old_bp_ref] = res_dict[\"af_adj\"]\n",
    "    \n",
    "    #Updating the Frequencies of ref\n",
    "    res_dict[\"af\"] =(1 - aa_sum)\n",
    "    res_dict[\"af_adj\"] = (1 - aa_adj_sum)\n",
    "\n",
    "    #Deleting from the alterations dict\n",
    "    del alterations_af_dict[aa]\n",
    "    del alterations_af_adj_dict[aa]\n",
    "    \n",
    "    #Deleting from the bps dict\n",
    "    del bp_af_dict[res_dict[\"bp_ref\"]]\n",
    "    del bp_af_adj_dict[res_dict[\"bp_ref\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_syn_ref_bp(new_bp_ref, old_bp_ref, res_dict, bp_af_dict, bp_af_adj_dict):\n",
    "    \n",
    "    #Updating bp_ref with the high freq. codon\n",
    "    res_dict[\"bp_ref\"] = new_bp_ref\n",
    "    \n",
    "    #Add the old ref to the bp dicts with its freq.\n",
    "    bp_freq_adj_sum = sum(bp_af_adj_dict.values())\n",
    "    bp_freq_sum = sum(bp_af_dict.values())\n",
    "    bp_af_adj_dict[old_bp_ref] = (1 - bp_freq_adj_sum)\n",
    "    bp_af_dict[old_bp_ref] = (1 - bp_freq_sum)\n",
    "    \n",
    "    #Delete the new ref from the bp dicts\n",
    "    del bp_af_adj_dict[new_bp_ref]\n",
    "    del bp_af_dict[new_bp_ref]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_chrom(chrom_raw_data):\n",
    "    \n",
    "    pill_chrom = chrom_raw_data[chrom_raw_data.find(\":\")+1:]\n",
    "    chrom = pill_chrom[:pill_chrom.find(\":\")]\n",
    "    \n",
    "    return chrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A function that return a dict with the MAF info for the protein position and corresponding chromosomal location\n",
    "def calc_exac_maf_data(chrom_pos_list, chrom_gene_table, protein_pos, aa, chrom_raw_data, hmm_state):\n",
    "    \n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    #Initializing the results dictionary\n",
    "    res_dict = {}\n",
    "    chrom = get_chrom(chrom_raw_data)\n",
    "    res_dict[\"chrom\"] = chrom\n",
    "    res_dict[\"chrom_pos\"] = chrom_pos_list\n",
    "    res_dict[\"prot_pos\"] = protein_pos\n",
    "    res_dict[\"aa_ref\"] = stop_codon_notation(aa)\n",
    "    res_dict[\"bp_ref\"] = retrieve_codon_seq(chrom_pos_list, chrom_raw_data, chrom)\n",
    "    #an counters lists\n",
    "    an_dict = {k: [] for k in [\"an\", \"an_adj\", \"an_afr\", \"an_amr\", \"an_eas\", \"an_fin\", \"an_nfe\", \"an_oth\", \"an_sas\"]}\n",
    "    res_dict.update(an_dict)\n",
    "    #ac counters lists\n",
    "    ac_dict = {k: [] for k in [\"ac_adj\", \"ac_afr\", \"ac_amr\", \"ac_eas\", \"ac_fin\", \"ac_het\", \"ac_hom\", \"ac_nfe\", \"ac_oth\", \"ac_sas\"]}\n",
    "    res_dict.update(ac_dict)\n",
    "    res_dict[\"SIFT\"] = []\n",
    "    res_dict[\"PolyPhen\"] = []\n",
    "    res_dict[\"clin_sig\"] = []\n",
    "    res_dict[\"SwissProt\"] = []\n",
    "    res_dict[\"ens_prot\"] = []\n",
    "    res_dict[\"mean_coverage\"] = []\n",
    "    \n",
    "    #Initializing more variables\n",
    "    indels_cnt = 0\n",
    "    errors_cnt = 0\n",
    "    inframe_ids = []\n",
    "    alterations_af_dict = defaultdict(list)\n",
    "    alterations_af_adj_dict = defaultdict(list)\n",
    "    bp_af_dict = dict()\n",
    "    bp_af_adj_dict = dict()\n",
    "    bp_list = [] #Will not update when changing ref aa/bp, has to correspond to the population prob.\n",
    "    coverage_threshold = 20\n",
    "    \n",
    "    #Validation: checking that the returned codon sequence from hg19 match the HMMER amino-acid\n",
    "    validate_HMMER_hg19_codon(res_dict[\"bp_ref\"], aa, chrom_pos_list, protein_pos, hmm_state)\n",
    "    \n",
    "    #Going over all 3 codon positions\n",
    "    for i in range(len(chrom_pos_list)):\n",
    "        chrom_pos = chrom_pos_list[i]\n",
    "        alt_codon_pos = i\n",
    "        \n",
    "        #Retreiving relevant ExAC entry\n",
    "        chrom_alter_table = chrom_gene_table[chrom_gene_table[\"pos\"] == chrom_pos]\n",
    "                \n",
    "        if (chrom_alter_table.shape[0] == 0):\n",
    "            #No ExAC entry for this chromosome position - not adding alteration data\n",
    "            continue\n",
    "        else:\n",
    "            #In case there are several alterations for that position, iterating\n",
    "            for index, line in chrom_alter_table.iterrows():\n",
    "                chrom_alter = line\n",
    "                \n",
    "                #Extracting ref and alt\n",
    "                exac_ref_bp = chrom_alter[\"ref\"]\n",
    "                exac_alt_bp = chrom_alter[\"alt\"]\n",
    "                \n",
    "                #Extracting coverage\n",
    "                res_dict[\"mean_coverage\"].append(chrom_alter[\"coverage\"])\n",
    "                \n",
    "                #Check if indel - skip \n",
    "                if (chrom_alter[\"comments\"].find(\"ignore\") >= 0):\n",
    "                    indels_cnt += 1\n",
    "                    continue            \n",
    "        \n",
    "                #Perform validation checks (comparing ExAC and HMMER data)\n",
    "                (exac_prot_data, exac_alt_aa, exac_alt_codon, errors) = exac_validation_checks(chrom_alter, protein_pos, aa, alt_codon_pos, chrom_pos, res_dict[\"bp_ref\"])\n",
    "                if (errors):\n",
    "                    errors_cnt += 1\n",
    "\n",
    "                #Extracting ExAC allele frequency data\n",
    "                af = chrom_alter[\"AF\"]\n",
    "                an = int(chrom_alter[\"AN\"])\n",
    "                an_adj = int(chrom_alter[\"AN_Adj\"])\n",
    "                ac_adj = chrom_alter[\"AC_Adj\"]\n",
    "                \n",
    "                #Calculating the alteration relevant data\n",
    "                alt_codon = create_alt_codon (exac_ref_bp, exac_alt_bp, res_dict[\"bp_ref\"], alt_codon_pos, chrom_raw_data)   \n",
    "                if (len(alt_codon) != 3):\n",
    "                    continue \n",
    "                else:\n",
    "                    alt_aa = codon_table[alt_codon.upper()]\n",
    "    \n",
    "                #Validation: ExAC aa match the calculated alt \n",
    "                validate_exac_aa(exac_prot_data, exac_alt_aa, alt_aa, chrom_pos)\n",
    "\n",
    "                #Calculating the allele frequency adjusted\n",
    "                af_adj = calculate_af_adj(an_adj, ac_adj)\n",
    "                \n",
    "                #Saving the bp with the frequency (for both syn and nonsyn)\n",
    "                bp_af_dict[alt_codon] = af\n",
    "                bp_af_adj_dict[alt_codon] = af_adj\n",
    "                bp_list.append(alt_codon)\n",
    "                \n",
    "                res_dict[\"an\"].append(an)\n",
    "                res_dict[\"an_adj\"].append(chrom_alter[\"AN_Adj\"])\n",
    "                res_dict[\"an_afr\"].append(chrom_alter[\"AN_AFR\"])\n",
    "                res_dict[\"an_amr\"].append(chrom_alter[\"AN_AMR\"])\n",
    "                res_dict[\"an_eas\"].append(chrom_alter[\"AN_EAS\"])\n",
    "                res_dict[\"an_fin\"].append(chrom_alter[\"AN_FIN\"])\n",
    "                res_dict[\"an_nfe\"].append(chrom_alter[\"AN_NFE\"])\n",
    "                res_dict[\"an_oth\"].append(chrom_alter[\"AN_OTH\"])\n",
    "                res_dict[\"an_sas\"].append(chrom_alter[\"AN_SAS\"])\n",
    "                \n",
    "                res_dict[\"ac_adj\"].append(chrom_alter[\"AC_Adj\"])\n",
    "                res_dict[\"ac_afr\"].append(chrom_alter[\"AC_AFR\"])\n",
    "                res_dict[\"ac_amr\"].append(chrom_alter[\"AC_AMR\"])\n",
    "                res_dict[\"ac_eas\"].append(chrom_alter[\"AC_EAS\"])\n",
    "                res_dict[\"ac_fin\"].append(chrom_alter[\"AC_FIN\"])\n",
    "                res_dict[\"ac_het\"].append(chrom_alter[\"AC_Het\"])\n",
    "                res_dict[\"ac_hom\"].append(chrom_alter[\"AC_Hom\"])\n",
    "                res_dict[\"ac_nfe\"].append(chrom_alter[\"AC_NFE\"])\n",
    "                res_dict[\"ac_oth\"].append(chrom_alter[\"AC_OTH\"])\n",
    "                res_dict[\"ac_sas\"].append(chrom_alter[\"AC_SAS\"])\n",
    "                \n",
    "                #Non-synonymous(!!!) - logging the alteration in the dictionary\n",
    "                if (alt_aa != res_dict[\"aa_ref\"]):\n",
    "                    alterations_af_dict[alt_aa].append(float(af))\n",
    "                    alterations_af_adj_dict[alt_aa].append(af_adj)\n",
    "                    \n",
    "                #Saving the SIFT and PolyPhen scores (for both syn and nonsyn)\n",
    "                res_dict[\"SIFT\"].append(chrom_alter[\"SIFT\"])\n",
    "                res_dict[\"PolyPhen\"].append(chrom_alter[\"PolyPhen\"])\n",
    "                res_dict[\"clin_sig\"].append(chrom_alter[\"clin_sig\"])\n",
    "                \n",
    "                #Saving SwissProt id and Ensembl prot id\n",
    "                res_dict[\"SwissProt\"].append(chrom_alter[\"SWISSPROT\"])\n",
    "                res_dict[\"ens_prot\"].append(chrom_alter[\"ENSP\"])\n",
    "                \n",
    "\n",
    "    #Calculating the overall MAF from the alteration dicts\n",
    "    res_dict[\"af\"] = 0\n",
    "    res_dict[\"af_adj\"] = 0\n",
    "    \n",
    "    res_dict[\"aa_ref_orig\"] = res_dict[\"aa_ref\"]\n",
    "    for aa in alterations_af_dict.keys():\n",
    "        aa_sum = sum(alterations_af_dict[aa])\n",
    "        aa_adj_sum = sum(alterations_af_adj_dict[aa])\n",
    "        \n",
    "        #Checking if any alteration is above 0.5, and changing the ref accordingly\n",
    "        if (aa_sum > 0.5):\n",
    "            \n",
    "            #Update all relevent information to switching a ref aa\n",
    "            change_ref_aa(res_dict, alterations_af_dict, alterations_af_adj_dict, aa, aa_sum, aa_adj_sum, bp_af_dict, bp_af_adj_dict)\n",
    "            break\n",
    "        else:\n",
    "            res_dict[\"af\"] += aa_sum\n",
    "            res_dict[\"af_adj\"] += aa_adj_sum\n",
    "        \n",
    "        #Fix the AF format\n",
    "        res_dict[\"af\"] = format_af(res_dict[\"af\"])\n",
    "        res_dict[\"af_adj\"] = format_af(res_dict[\"af_adj\"])\n",
    "    \n",
    "    #Checking if any syn aleration bp is above 0.5 (nonsyn were already checked), and changing ref bp accordingly\n",
    "    for codon in bp_af_adj_dict.keys():\n",
    "        if ((codon_table[codon] == res_dict[\"aa_ref\"]) and (bp_af_adj_dict[codon] > 0.5)):\n",
    "            new_bp_ref = codon\n",
    "            old_bp_ref = res_dict[\"bp_ref\"]\n",
    "            change_syn_ref_bp(new_bp_ref, old_bp_ref, res_dict, bp_af_dict, bp_af_adj_dict)\n",
    "            \n",
    "        \n",
    "    res_dict[\"alterations_af_adj_dict\"] = alterations_af_adj_dict\n",
    "    res_dict[\"bp_af_dict\"] = bp_af_dict\n",
    "    res_dict[\"bp_af_adj_dict\"] = bp_af_adj_dict\n",
    "    res_dict[\"bp_list\"] = bp_list\n",
    "    \n",
    "    return (res_dict, indels_cnt, errors_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genes_on_real_chromosomes(sorted_domain_data):\n",
    "    \"\"\"\n",
    "    Get all the domains genes that are on real chromosomes (not patches)\n",
    "    \"\"\"\n",
    "    \n",
    "    genes_on_chroms = []\n",
    "    for index, line in sorted_domain_data.iterrows():\n",
    "        if (line[\"chrom_num\"] in chromosome_names):\n",
    "            genes_on_chroms.append(line[\"gene\"])\n",
    "            \n",
    "    unique_genes = pd.Series(genes_on_chroms).unique()\n",
    "    return (unique_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting....\n",
      "Finished protein ENSG00000049089.9\n",
      "Finished protein ENSG00000060718.14\n",
      "Finished protein ENSG00000084636.13\n",
      "Finished protein ENSG00000159189.7\n",
      "Finished protein ENSG00000171502.10\n",
      "Finished protein ENSG00000171812.6\n",
      "Finished protein ENSG00000173369.11\n",
      "Finished protein ENSG00000173372.12\n",
      "Finished protein ENSG00000065618.12\n",
      "Finished protein ENSG00000122852.10\n",
      "Finished protein ENSG00000133661.11\n",
      "Finished protein ENSG00000165471.6\n",
      "Finished protein ENSG00000165985.8\n",
      "Finished protein ENSG00000185303.11\n",
      "Finished protein ENSG00000197467.9\n",
      "Finished protein ENSG00000223953.3\n",
      "Finished protein ENSG00000139219.13\n",
      "Finished protein ENSG00000134871.13\n",
      "Finished protein ENSG00000187498.10\n",
      "Finished protein ENSG00000205863.5\n",
      "Finished protein ENSG00000240654.2\n",
      "Finished protein ENSG00000186417.9\n",
      "Finished protein ENSG00000108821.9\n",
      "Finished protein ENSG00000131094.3\n",
      "Finished protein ENSG00000158270.10\n",
      "Finished protein ENSG00000183287.9\n",
      "Finished protein ENSG00000080573.6\n",
      "Finished protein ENSG00000019169.9\n",
      "Finished protein ENSG00000081052.10\n",
      "Finished protein ENSG00000118004.13\n",
      "Finished protein ENSG00000136709.7\n",
      "Finished protein ENSG00000138080.9\n",
      "Finished protein ENSG00000144119.3\n",
      "Finished protein ENSG00000163359.11\n",
      "Finished protein ENSG00000168542.8\n",
      "Finished protein ENSG00000169031.14\n",
      "Finished protein ENSG00000204262.7\n",
      "Finished protein ENSG00000092758.11\n",
      "Finished protein ENSG00000101203.12\n",
      "Finished protein ENSG00000142156.10\n",
      "Finished protein ENSG00000142173.10\n",
      "Finished protein ENSG00000182871.10\n",
      "Finished protein ENSG00000186998.11\n",
      "Finished protein ENSG00000114270.11\n",
      "Finished protein ENSG00000144810.11\n",
      "Finished protein ENSG00000172752.10\n",
      "Finished protein ENSG00000181092.5\n",
      "Finished protein ENSG00000182447.4\n",
      "Finished protein ENSG00000206384.6\n",
      "Finished protein ENSG00000206561.8\n",
      "Finished protein ENSG00000163145.8\n",
      "Finished protein ENSG00000188517.10\n",
      "Finished protein ENSG00000050767.11\n",
      "Finished protein ENSG00000082196.16\n",
      "Finished protein ENSG00000145861.7\n",
      "Finished protein ENSG00000082293.8\n",
      "Finished protein ENSG00000111799.16\n",
      "Finished protein ENSG00000112280.11\n",
      "Finished protein ENSG00000123500.5\n",
      "Finished protein ENSG00000124749.12\n",
      "Finished protein ENSG00000204248.6\n",
      "Finished protein ENSG00000164692.13\n",
      "Finished protein ENSG00000215018.5\n",
      "Finished protein ENSG00000038945.10\n",
      "Finished protein ENSG00000168077.9\n",
      "Finished protein ENSG00000168079.12\n",
      "Finished protein ENSG00000169436.12\n",
      "Finished protein ENSG00000184374.2\n",
      "Finished protein ENSG00000187955.7\n",
      "Finished protein ENSG00000085265.6\n",
      "Finished protein ENSG00000130635.11\n",
      "Finished protein ENSG00000160339.11\n",
      "Finished protein ENSG00000196739.10\n",
      "Finished protein ENSG00000204291.6\n",
      "Finished protein ENSG00000158813.13\n",
      "Finished protein ENSG00000188153.8\n",
      "Finished protein ENSG00000197565.11\n",
      "Finished domain Collagen\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "\n",
    "chrom_gene_path = curr_dir[0]+\"/domain_gene_exac/pfam-v30/\"+domain_name+\"/\"\n",
    "states_dict = defaultdict(list)\n",
    "print \"Starting....\"\n",
    "\n",
    "#For error logging\n",
    "functionNameAsString = sys._getframe().f_code.co_name\n",
    "\n",
    "#A list to count indels per gene\n",
    "domain_ens_genes_indels = []\n",
    "\n",
    "#A list to count validation errors per gene\n",
    "domain_ens_genes_errors = []\n",
    "    \n",
    "#Getting a list of all the relevant ensembl gene ids for this domain\n",
    "domain_ens_genes_all = get_genes_on_real_chromosomes(sorted_domain_data)\n",
    "    \n",
    "#For each ensembl gene in the domain data - finding all the ExAC alterations\n",
    "for ens_gene in domain_ens_genes_all:\n",
    "   \n",
    "    #Getting gene-chrom (ExAC) data tables\n",
    "    chrom_gene_table = pd.read_csv(chrom_gene_path+ens_gene+\"/chrom_gene_table.csv\", sep='\\t', index_col=0,\n",
    "                                  dtype={\"AC\": int, \"AC_AFR\": int, \"AC_AMR\": int, \"AC_Adj\": int, \"AC_EAS\": int,\n",
    "                               \"AC_FIN\": int, \"AC_Het\": int, \"AC_Hom\": int, \"AC_NFE\": int, \"AC_OTH\": int, \"AC_SAS\": int, \"AF\": float, \"AN\": int, \"AN_AFR\": int,\n",
    "                               \"AN_AMR\": int, \"AN_Adj\": int, \"AN_EAS\": int, \"AN_FIN\": int, \"AN_NFE\": int, \"AN_OTH\": int, \"AN_SAS\": int, \"prot_pos\": str})\n",
    "    chrom_gene_table.fillna('', inplace=True)\n",
    "    exon_table = pd.read_csv(chrom_gene_path+ens_gene+\"/exon_table.csv\", sep='\\t', index_col=0)\n",
    "    \n",
    "    #Filtering the domain data for this gene according to the canonical protein id\n",
    "    canonic_prot = canonic_protein[ens_gene]\n",
    "    canonic_prot_t = canonic_prot[:canonic_prot.find(\".\")] #Trimming the \".#\" at the end\n",
    "    domain_gene_table = sorted_domain_data[sorted_domain_data[\"prot\"] == canonic_prot]\n",
    "    #Making sure that if two HMM-matches overlaps, the higher bit score will come first in the table\n",
    "    domain_gene_table = domain_gene_table.sort_values(by=\"BitScore\", ascending=False)\n",
    "    domain_gene_name = domain_gene_table[\"hugoSymbol\"].unique()[0]\n",
    "    if (len(domain_gene_table[\"hugoSymbol\"].unique()) > 1):\n",
    "        print functionNameAsString+\" Error: \"+ens_gene+\": more than one Hugo symbol\"  #sanity check\n",
    "\n",
    "    #Extracting neccessary information from the gene-domain data\n",
    "    chrom_raw_data = domain_gene_table[\"chromosome\"].unique()[0] #there should be only one element here\n",
    "    if (len(domain_gene_table[\"chromosome\"].unique()) > 1):\n",
    "        print functionNameAsString+\" Error: \"+ens_gene+\": more than one chromosome raw data\" #sanity check\n",
    "    targetid = domain_gene_table[\"#TargetID\"].unique()[0]\n",
    "    \n",
    "    #A counter for indels inside the gene\n",
    "    protein_indels_cnt = 0\n",
    "    #A counter for validation errors inside the gene\n",
    "    protein_errors_cnt = 0\n",
    "\n",
    "    #Iterating over the amino-acids of the protein\n",
    "    prot_len = int(domain_gene_table[\"length\"].unique()[0])\n",
    "\n",
    "    for protein_pos in range(1,prot_len+1):\n",
    "    \n",
    "        #Trying to match HMM-state, and retreive the aa from HMMER results\n",
    "        (hmm_state, aa) = protein_pos_to_hmm_state_and_aa(protein_pos, domain_gene_table) #TODO: what happens when two matches overlap? maybe sort to the best bit score?\n",
    "\n",
    "        #If there's a match to HMM-state: find the corresponding codon bps chromosome positions\n",
    "        if (hmm_state > 0):\n",
    "            chrom_pos_list =find_chrom_bps(protein_pos, exon_table, chrom_raw_data)\n",
    "\n",
    "            #Analysis of the amino-acid MAF and realted data, returned in a dictionary\n",
    "            (info_dict, indels_cnt, errors_cnt) = calc_exac_maf_data(chrom_pos_list, chrom_gene_table, protein_pos, aa, chrom_raw_data, hmm_state)\n",
    "            info_dict[\"ens_gene\"] = ens_gene\n",
    "\n",
    "            #Adding the dictionary to the HMM-state list\n",
    "            states_dict[hmm_state].append(info_dict)\n",
    "\n",
    "            #Adding the indels to the global counter\n",
    "            protein_indels_cnt += indels_cnt\n",
    "\n",
    "            #Adding the errors to the global counter\n",
    "            protein_errors_cnt += errors_cnt\n",
    "        \n",
    "    domain_ens_genes_indels.append(protein_indels_cnt)\n",
    "    domain_ens_genes_errors.append(protein_errors_cnt)\n",
    "    print \"Finished protein \"+ens_gene \n",
    "    \n",
    "!mkdir -p domains_states_dicts/pfam-v30/$domain_name\n",
    "with open(curr_dir[0]+\"/domains_states_dicts/pfam-v30/\"+domain_name+\"/\"+domain_name+\"_hmm_states_dict_\"+datetime.date.today().strftime(\"%m.%d.%y\")+\".pik\", 'wb') as handle:\n",
    "    pickle.dump(states_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print \"Finished domain \"+domain_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(domain_ens_genes_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(domain_ens_genes_indels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the percent of indels out of (mismatch + indels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "mismatch_cnt = 0\n",
    "for state in states_dict.keys():\n",
    "        for d in states_dict[state]:\n",
    "            if (d[\"af\"]  > 0):\n",
    "                mismatch_cnt += 1\n",
    "print mismatch_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of indels: 0\n"
     ]
    }
   ],
   "source": [
    "if (mismatch_cnt + sum(domain_ens_genes_indels) == 0):\n",
    "    indels_per = 0\n",
    "else:\n",
    "    indels_per = sum(domain_ens_genes_indels)/float(mismatch_cnt+sum(domain_ens_genes_indels))\n",
    "print \"% of indels: \"+str(indels_per)\n",
    "with open(curr_dir[0]+\"/domains_states_dicts/pfam-v30/indels/\"+domain_name+\"_indels_percents.txt\", \"a\") as myfile:\n",
    "    myfile.write(domain_name+\"\\t\"+str(indels_per))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from os import environ\n",
    "import pickle\n",
    "import fileinput\n",
    "import sys\n",
    "import datetime\n",
    "from mapping_func import create_exon_pos_table, find_chrom_bps, protein_pos_to_hmm_state_and_aa\n",
    "from calc_exac_freq_func import create_alt_codon, exac_validation_checks, retrieve_codon_seq, codon_table\n",
    "from indels_func import is_indel, table_editing, indel_type\n",
    "from entropy_func import JSD_background, JSD, SE, JSdiv\n",
    "from af_format_calc import format_af, calculate_af_adj\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "#Trying to fix the problem of: \"The history saving thread hit an unexpected error\" when running on the server\n",
    "#as described here: https://github.com/ipython/ipython/issues/1342\n",
    "from IPython.config.loader import Config\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "cfg = Config()\n",
    "cfg.HistoryManager.hist_file = ':memory:'\n",
    "ip = InteractiveShell.instance(config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7tm_1\n"
     ]
    }
   ],
   "source": [
    "#Getting path\n",
    "curr_dir = !pwd\n",
    "\n",
    "#Reading the list of filtered domains\n",
    "with open(curr_dir[0]+\"/../5.domains_stats/filtered10_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list10 = pickle.load(handle)\n",
    "filtered_domains_list10.sort()\n",
    "\n",
    "#Getting the domain index as environment variable called \"idx\"\n",
    "try:\n",
    "    domain_index = int(environ['idx'])\n",
    "except:\n",
    "    domain_index = 2\n",
    "\n",
    "domain_name = filtered_domains_list10[domain_index]\n",
    "print domain_name\n",
    "#domain_name = \"2OG-FeII_Oxy_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_path = curr_dir[0]+\"/../3.parse_HMMER/hmm_domains/pfam-v30/\"\n",
    "filename = domain_name+\".csv\"\n",
    "domain_data = pd.read_csv(in_path+filename, sep='\\t', index_col=0, dtype={\"chrom_num\": str})\n",
    "#Sort the domain data\n",
    "sorted_domain_data = domain_data.sort_values(by=[\"chrom_num\", \"gene\", \"TargetStart\"])\n",
    "sorted_domain_data = sorted_domain_data.reset_index(drop=True)\n",
    "\n",
    "#Get the canonic protein id for Zinc domain\n",
    "with open(curr_dir[0]+\"/../4.parse_Uniprot/domains_canonic_prot/pfam-v30/\"+domain_name+\"_canonic_prot.pik\", 'rb') as handle:\n",
    "    canonic_protein = pickle.load(handle)\n",
    "    \n",
    "#Get the filtered table of domains\n",
    "    \n",
    "chromosome_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"X\", \"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaving outside 0 out of 32\n"
     ]
    }
   ],
   "source": [
    "#Counting how many domains instances are excluded because of strange chrom names.\n",
    "chrom_names_list = sorted_domain_data[\"chrom_num\"].tolist()\n",
    "strange_chrom_sum = 0\n",
    "for name in chrom_names_list:\n",
    "    if (name not in chromosome_names):\n",
    "        strange_chrom_sum += 1\n",
    "print \"Leaving outside \"+str(strange_chrom_sum)+\" out of \"+str(len(chrom_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_codon_notation(aa):\n",
    "    \"\"\"Coverting the HMMER 'x' char to '*' for stop codon notation unifirmity\"\"\"\n",
    "    if (aa == 'X'):\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def validate_HMMER_hg19_codon(bp_ref, aa, chrom_pos_list, protein_pos, hmm_state):\n",
    "    \"\"\"Validation: checking that the returned codon sequence from hg19 match the HMMER amino-acid\"\"\"\n",
    "\n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    translated_aa = codon_table[bp_ref.upper()]\n",
    "    if (translated_aa != aa):\n",
    "        print \"chrom_pos_list = \"+str(chrom_pos_list)+\" protein_pos = \"+str(protein_pos)+\" hmm_state = \"+str(hmm_state)\n",
    "        print functionNameAsString+\" Error: hg19 codon sequence retrieved \"+bp_ref.upper()+\"=\"+translated_aa+\" doesn't match HMMER amino-acid \"+aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_exac_aa(exac_prot_data, exac_alt_aa, alt_aa, chrom_pos):\n",
    "    \"\"\"Validation: checking if the calculated aa matches the ExAC aa\"\"\"\n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    if (exac_prot_data and exac_alt_aa != alt_aa):\n",
    "        print functionNameAsString+\" \"+ str(chrom_pos)+\" Error: the ExAC alt aa \"+exac_alt_aa+\" doesn't match my alt aa calculation \"+alt_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_ref_aa(res_dict, alterations_af_dict, alterations_af_adj_dict, aa, aa_sum, aa_adj_sum, bp_af_dict, bp_af_adj_dict):\n",
    "    \"\"\"Changing the ref aa and updating all relevant dictionaries\"\"\"\n",
    "    \n",
    "    #Adding the refrence allele to the alterations dicts\n",
    "    old_ref = res_dict[\"aa_ref\"]\n",
    "    sum_of_all_alt = sum(sum(alterations_af_dict.values(), []))\n",
    "    sum_of_all_alt_adj = sum(sum(alterations_af_adj_dict.values(), []))\n",
    "    alterations_af_dict[old_ref] = [1 - sum_of_all_alt]\n",
    "    alterations_af_adj_dict[old_ref] = [1 - sum_of_all_alt_adj]\n",
    "\n",
    "    #Updating the aa to be the ref\n",
    "    res_dict[\"aa_ref\"] = aa\n",
    "\n",
    "    #Finding the codon that codes aa with highest frequency and update bp_ref\n",
    "    old_bp_ref = res_dict[\"bp_ref\"]\n",
    "    max_af = 0\n",
    "    for codon in (bp_af_adj_dict.keys()):\n",
    "        if (codon_table[codon.upper()] == aa):\n",
    "            if (bp_af_adj_dict[codon] >= max_af):\n",
    "                max_af = bp_af_adj_dict[codon]\n",
    "                res_dict[\"bp_ref\"] = codon\n",
    "                \n",
    "    #Adding the ref bp to the bp dicts\n",
    "    bp_af_dict[old_bp_ref] = res_dict[\"af\"]\n",
    "    bp_af_adj_dict[old_bp_ref] = res_dict[\"af_adj\"]\n",
    "    \n",
    "    #Updating the Frequencies of ref\n",
    "    res_dict[\"af\"] =(1 - aa_sum)\n",
    "    res_dict[\"af_adj\"] = (1 - aa_adj_sum)\n",
    "\n",
    "    #Deleting from the alterations dict\n",
    "    del alterations_af_dict[aa]\n",
    "    del alterations_af_adj_dict[aa]\n",
    "    \n",
    "    #Deleting from the bps dict\n",
    "    del bp_af_dict[res_dict[\"bp_ref\"]]\n",
    "    del bp_af_adj_dict[res_dict[\"bp_ref\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A function that return a dict with the MAF info for the protein position and corresponding chromosomal location\n",
    "def calc_exac_maf_data(chrom_pos_list, chrom_gene_table, indels_table, protein_pos, aa, chrom_raw_data, chrom, hmm_state):\n",
    "    \n",
    "    #For error logging\n",
    "    functionNameAsString = sys._getframe().f_code.co_name\n",
    "    \n",
    "    #Initializing the results dictionary\n",
    "    res_dict = {}\n",
    "    res_dict[\"chrom\"] = chrom\n",
    "    res_dict[\"chrom_pos\"] = chrom_pos_list\n",
    "    res_dict[\"prot_pos\"] = protein_pos\n",
    "    res_dict[\"aa_ref\"] = stop_codon_notation(aa)\n",
    "    res_dict[\"bp_ref\"] = retrieve_codon_seq(chrom_pos_list, chrom_raw_data, chrom)\n",
    "    #an counters lists\n",
    "    an_dict = {k: [] for k in [\"an\", \"an_adj\", \"an_afr\", \"an_amr\", \"an_eas\", \"an_fin\", \"an_nfe\", \"an_oth\", \"an_sas\"]}\n",
    "    res_dict.update(an_dict)\n",
    "    #ac counters lists\n",
    "    ac_dict = {k: [] for k in [\"ac_adj\", \"ac_afr\", \"ac_amr\", \"ac_eas\", \"ac_fin\", \"ac_het\", \"ac_hom\", \"ac_nfe\", \"ac_oth\", \"ac_sas\"]}\n",
    "    res_dict.update(ac_dict)\n",
    "    res_dict[\"SIFT\"] = []\n",
    "    res_dict[\"PolyPhen\"] = []\n",
    "    res_dict[\"clin_sig\"] = []\n",
    "    \n",
    "    #Initializing more variables\n",
    "    indels_cnt = 0\n",
    "    errors_cnt = 0\n",
    "    filter_cnt = 0\n",
    "    inframe_ids = []\n",
    "    alterations_af_dict = defaultdict(list)\n",
    "    alterations_af_adj_dict = defaultdict(list)\n",
    "    bp_af_dict = dict()\n",
    "    bp_af_adj_dict = dict()\n",
    "    bp_list = []\n",
    "    \n",
    "    #Validation: checking that the returned codon sequence from hg19 match the HMMER amino-acid\n",
    "    validate_HMMER_hg19_codon(res_dict[\"bp_ref\"], aa, chrom_pos_list, protein_pos, hmm_state)\n",
    "    \n",
    "    #Going over all 3 codon positions\n",
    "    for i in range(len(chrom_pos_list)):\n",
    "        chrom_pos = chrom_pos_list[i]\n",
    "        alt_codon_pos = i\n",
    "            \n",
    "        #Retreiving relevant ExAC entry\n",
    "        chrom_alter_table = chrom_gene_table[chrom_gene_table[\"pos\"] == chrom_pos]\n",
    "        chrom_alter_table = chrom_alter_table.reset_index(drop=True)\n",
    "                \n",
    "        if (chrom_alter_table.shape[0] == 0):\n",
    "            #No ExAC entry for this chromosome position - not adding alteration data\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            #In case there are several alterations for that position, iterating\n",
    "            for index, line in chrom_alter_table.iterrows():\n",
    "                chrom_alter = line\n",
    "                \n",
    "                #Skipping alterations that were filtered out by VQSR\n",
    "                if (chrom_alter[\"filter\"] != \"PASS\"):\n",
    "                    filter_cnt += 1\n",
    "                    continue\n",
    "                \n",
    "                #Extracting ref and alt\n",
    "                exac_ref_bp = chrom_alter[\"ref\"]\n",
    "                exac_alt_bp = chrom_alter[\"alt\"]\n",
    "                \n",
    "                #Check if indel - skip (we assume the whole protein may not function and don't add those to the MAF count)\n",
    "                if (is_indel(exac_ref_bp, exac_alt_bp, chrom_alter) != indel_type.NO_INDEL):\n",
    "                    indels_cnt += 1\n",
    "                    continue\n",
    "                \n",
    "                #Perform validation checks (comparing ExAC and HMMER data)\n",
    "                (exac_prot_data, exac_alt_aa, exac_alt_codon, errors) = exac_validation_checks(chrom_alter, protein_pos, aa, alt_codon_pos, chrom_pos, res_dict[\"bp_ref\"])\n",
    "                if (errors):\n",
    "                    errors_cnt += 1\n",
    "\n",
    "                #Extracting ExAC allele frequency data\n",
    "                af = chrom_alter[\"AF\"]\n",
    "                an = int(chrom_alter[\"AN\"])\n",
    "                an_adj = int(chrom_alter[\"AN_Adj\"])\n",
    "                ac_adj = chrom_alter[\"AC_Adj\"]\n",
    "                \n",
    "                #Calculating the alteration relevant data\n",
    "                alt_codon = create_alt_codon (exac_ref_bp, exac_alt_bp, res_dict[\"bp_ref\"], alt_codon_pos, chrom_raw_data)   \n",
    "                if (len(alt_codon) != 3):\n",
    "                    continue \n",
    "                else:\n",
    "                    alt_aa = codon_table[alt_codon.upper()]\n",
    "                \n",
    "                #Validation: ExAC aa match the calculated alt\n",
    "                validate_exac_aa(exac_prot_data, exac_alt_aa, alt_aa, chrom_pos)\n",
    "\n",
    "                #Calculating the allele frequency adjusted\n",
    "                af_adj = calculate_af_adj(an_adj, ac_adj)\n",
    "                \n",
    "                #Saving the bp with the frequency (for both syn and nonsyn)\n",
    "                bp_af_dict[alt_codon] = af\n",
    "                bp_af_adj_dict[alt_codon] = af_adj\n",
    "                bp_list.append(alt_codon)\n",
    "                \n",
    "                res_dict[\"an\"].append(an)\n",
    "                res_dict[\"an_adj\"].append(chrom_alter[\"AN_Adj\"])\n",
    "                res_dict[\"an_afr\"].append(chrom_alter[\"AN_AFR\"])\n",
    "                res_dict[\"an_amr\"].append(chrom_alter[\"AN_AMR\"])\n",
    "                res_dict[\"an_eas\"].append(chrom_alter[\"AN_EAS\"])\n",
    "                res_dict[\"an_fin\"].append(chrom_alter[\"AN_FIN\"])\n",
    "                res_dict[\"an_nfe\"].append(chrom_alter[\"AN_NFE\"])\n",
    "                res_dict[\"an_oth\"].append(chrom_alter[\"AN_OTH\"])\n",
    "                res_dict[\"an_sas\"].append(chrom_alter[\"AN_SAS\"])\n",
    "                \n",
    "                res_dict[\"ac_adj\"].append(chrom_alter[\"AC_Adj\"])\n",
    "                res_dict[\"ac_afr\"].append(chrom_alter[\"AC_AFR\"])\n",
    "                res_dict[\"ac_amr\"].append(chrom_alter[\"AC_AMR\"])\n",
    "                res_dict[\"ac_eas\"].append(chrom_alter[\"AC_EAS\"])\n",
    "                res_dict[\"ac_fin\"].append(chrom_alter[\"AC_FIN\"])\n",
    "                res_dict[\"ac_het\"].append(chrom_alter[\"AC_Het\"])\n",
    "                res_dict[\"ac_hom\"].append(chrom_alter[\"AC_Hom\"])\n",
    "                res_dict[\"ac_nfe\"].append(chrom_alter[\"AC_NFE\"])\n",
    "                res_dict[\"ac_oth\"].append(chrom_alter[\"AC_OTH\"])\n",
    "                res_dict[\"ac_sas\"].append(chrom_alter[\"AC_SAS\"])\n",
    "                \n",
    "                #Non-synonymous(!!!) - logging the alteration in the dictionary\n",
    "                if (alt_aa != res_dict[\"aa_ref\"]):\n",
    "                    alterations_af_dict[alt_aa].append(float(af))\n",
    "                    alterations_af_adj_dict[alt_aa].append(af_adj)\n",
    "                    \n",
    "                #Saving the SIFT and PolyPhen scores (for both syn and nonsyn)\n",
    "                res_dict[\"SIFT\"].append(chrom_alter[\"SIFT\"])\n",
    "                res_dict[\"PolyPhen\"].append(chrom_alter[\"PolyPhen\"])\n",
    "                res_dict[\"clin_sig\"].append(chrom_alter[\"clin_sig\"])\n",
    "                \n",
    "\n",
    "    #Calculating the overall MAF from the alteration dicts\n",
    "    res_dict[\"af\"] = 0\n",
    "    res_dict[\"af_adj\"] = 0\n",
    "    \n",
    "    for aa in alterations_af_dict.keys():\n",
    "        aa_sum = sum(alterations_af_dict[aa])\n",
    "        aa_adj_sum = sum(alterations_af_adj_dict[aa])\n",
    "        \n",
    "        #Checking if any alteration is above 0.5, and changing the ref accordingly\n",
    "        if (aa_sum > 0.5):\n",
    "            \n",
    "            #Update all relevent information to switching a ref aa\n",
    "            change_ref_aa(res_dict, alterations_af_dict, alterations_af_adj_dict, aa, aa_sum, aa_adj_sum, bp_af_dict, bp_af_adj_dict)\n",
    "            break\n",
    "        else:\n",
    "            res_dict[\"af\"] += aa_sum\n",
    "            res_dict[\"af_adj\"] += aa_adj_sum\n",
    "        \n",
    "        #Fix the AF format\n",
    "        res_dict[\"af\"] = format_af(res_dict[\"af\"])\n",
    "        res_dict[\"af_adj\"] = format_af(res_dict[\"af_adj\"])\n",
    "        \n",
    "    res_dict[\"alterations_af_adj_dict\"] = alterations_af_adj_dict\n",
    "    res_dict[\"bp_af_dict\"] = bp_af_dict\n",
    "    res_dict[\"bp_af_adj_dict\"] = bp_af_adj_dict\n",
    "    res_dict[\"bp_list\"] = bp_list\n",
    "    \n",
    "    return (res_dict, indels_cnt, errors_cnt, filter_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (45) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/home/anat/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chrom_path = curr_dir[0]+\"/../1.parse_ExAC/parsed/\"\n",
    "chrom_filename = \"parsed_chrom\"\n",
    "states_dict = defaultdict(list)\n",
    "print \"Starting....\"\n",
    "\n",
    "#For error logging\n",
    "functionNameAsString = sys._getframe().f_code.co_name\n",
    "\n",
    "#A list of all the ens genes\n",
    "domain_ens_genes_all = []\n",
    "\n",
    "#A list to count indels per gene\n",
    "domain_ens_genes_indels = []\n",
    "\n",
    "#A list to count validation errors per gene\n",
    "domain_ens_genes_errors = []\n",
    "\n",
    "#A list to count ExAC filtered-out per gene\n",
    "domain_ens_genes_filter = []\n",
    "\n",
    "for chrom in chromosome_names:\n",
    "    \n",
    "    #Filtering the domain data relevant to this chromosome\n",
    "    domain_chrom_data = sorted_domain_data[sorted_domain_data[\"chrom_num\"] == chrom]\n",
    "    \n",
    "    #Loading the ExAC parsed data of this chromosome\n",
    "    fields = [\"chrom\", \"pos\", \"ref\", \"alt\", \"filter\", \"AC\", \"AC_AFR\", \"AC_AMR\", \"AC_Adj\", \"AC_EAS\", \"AC_FIN\", \"AC_Het\", \"AC_Hom\", \"AC_NFE\", \"AC_OTH\", \"AC_SAS\", \n",
    "              \"AF\", \"AN\", \"AN_AFR\", \"AN_AMR\", \"AN_Adj\", \"AN_EAS\", \"AN_FIN\", \"AN_NFE\", \"AN_OTH\", \"AN_SAS\", \"gene\", \"feature\", \"feature_type\", \"conseq\",\n",
    "              \"prot_pos\", \"amino_acids\", \"codons\", \"strand\", \"ENSP\", \"exon\", \"intron\", \"domains\", \"SIFT\", \"PolyPhen\",\"clin_sig\"]\n",
    "    chrom_csv = pd.read_csv(chrom_path+chrom_filename+chrom+\".csv\", sep='\\t', index_col=0, usecols=fields,\n",
    "                           dtype={\"AC\": int, \"AC_AFR\": int, \"AC_AMR\": int, \"AC_Adj\": int, \"AC_EAS\": int,\n",
    "                               \"AC_FIN\": int, \"AC_Het\": int, \"AC_Hom\": int, \"AC_NFE\": int, \"AC_OTH\": int, \"AC_SAS\": int, \"AF\": float, \"AN\": int, \"AN_AFR\": int,\n",
    "                               \"AN_AMR\": int, \"AN_Adj\": int, \"AN_EAS\": int, \"AN_FIN\": int, \"AN_NFE\": int, \"AN_OTH\": int, \"AN_SAS\": int, \"prot_pos\": str})\n",
    "    chrom_csv = chrom_csv.sort_values(by=[\"pos\"])\n",
    "    chrom_csv = chrom_csv.reset_index(drop=True)\n",
    "    chrom_csv.fillna('', inplace=True)\n",
    "    chrom_csv[\"comments\"] = \"\"\n",
    "    \n",
    "    #Getting a list of all the relevant ensembl gene ids for this chromosome\n",
    "    domain_ens_genes = (domain_chrom_data[\"gene\"]).unique()\n",
    "    domain_ens_genes_all.extend(domain_ens_genes)\n",
    "    \n",
    "    #For each ensembl gene in the domain data - finding all the ExAC alterations\n",
    "    for ens_gene in domain_ens_genes:\n",
    "        \n",
    "        #Filtering the domain data for this gene according to the canonical protein id\n",
    "        canonic_prot = canonic_protein[ens_gene]\n",
    "        canonic_prot_t = canonic_prot[:canonic_prot.find(\".\")] #Trimming the \".#\" at the end\n",
    "        domain_gene_table = domain_chrom_data[domain_chrom_data[\"prot\"] == canonic_prot]\n",
    "        #Making sure that if two HMM-matches overlaps, the higher bit score will come first in the table\n",
    "        domain_gene_table = domain_gene_table.sort_values(by=\"BitScore\", ascending=False)\n",
    "        domain_gene_name = domain_gene_table[\"hugoSymbol\"].unique()[0]\n",
    "        if (len(domain_gene_table[\"hugoSymbol\"].unique()) > 1):\n",
    "            print functionNameAsString+\" Error: \"+ens_gene+\": more than one Hugo symbol\"  #sanity check\n",
    "        \n",
    "        #Creating a table of the exons for this gene, according to the canonical protein\n",
    "        chrom_raw_data = domain_gene_table[\"chromosome\"].unique()[0] #there should be only one element here\n",
    "        if (len(domain_gene_table[\"chromosome\"].unique()) > 1):\n",
    "            print functionNameAsString+\" Error: \"+ens_gene+\": more than one chromosome raw data\" #sanity check\n",
    "        targetid = domain_gene_table[\"#TargetID\"].unique()[0]\n",
    "        exon_table = create_exon_pos_table(chrom_raw_data, targetid)\n",
    "        \n",
    "        #Filtering the chromosome data to the gene exons region\n",
    "        exons_start_pos = min(exon_table[\"start_pos\"][0],exon_table[\"start_pos\"][len(exon_table)-1]) #in case of complelemt, the minimal position could be at the last row\n",
    "        exons_end_pos = max(exon_table[\"end_pos\"][0],exon_table[\"end_pos\"][len(exon_table)-1]) #in case of complelemt, the maximal position could be at the first row\n",
    "        chrom_gene_table = chrom_csv[chrom_csv[\"pos\"] >= int(exons_start_pos)][chrom_csv[\"pos\"] <= int(exons_end_pos)][chrom_csv[\"ENSP\"] == canonic_prot_t]\n",
    "        chrom_gene_table = chrom_gene_table.reset_index(drop=True)\n",
    "        \n",
    "        #Handling indels\n",
    "        indels_table = table_editing(chrom_gene_table)\n",
    "        \n",
    "        #A counter for indels inside the domain\n",
    "        protein_indels_cnt = 0\n",
    "        #A counter for validation errors inside the domain\n",
    "        protein_errors_cnt = 0\n",
    "        #A counter for ExAC filter-out inside the domain\n",
    "        protein_filter_cnt = 0\n",
    "        \n",
    "        #Iterating over the amino-acids of the protein\n",
    "        prot_len = int(domain_gene_table[\"length\"].unique()[0])\n",
    "        for protein_pos in range(1,prot_len+1):\n",
    "    \n",
    "            #Trying to match HMM-state, and retreive the aa from HMMER results\n",
    "            (hmm_state, aa) = protein_pos_to_hmm_state_and_aa(protein_pos, domain_gene_table) #TODO: what happens when two matches overlap? maybe sort to the best bit score?\n",
    "                \n",
    "            #If there's a match to HMM-state: find the corresponding codon bps chromosome positions\n",
    "            if (hmm_state > 0):\n",
    "                chrom_pos_list =find_chrom_bps(protein_pos, exon_table, chrom_raw_data)\n",
    "                \n",
    "                #Analysis of the amino-acid MAF and realted data, returned in a dictionary\n",
    "                (info_dict, indels_cnt, errors_cnt, filter_cnt) = calc_exac_maf_data(chrom_pos_list, chrom_gene_table, indels_table, protein_pos, aa, chrom_raw_data, chrom, hmm_state)\n",
    "                info_dict[\"ens_gene\"] = ens_gene\n",
    "                \n",
    "                #Adding the dictionary to the HMM-state list\n",
    "                states_dict[hmm_state].append(info_dict)\n",
    "                \n",
    "                #Adding the indels to the global counter\n",
    "                protein_indels_cnt += indels_cnt\n",
    "                \n",
    "                #Adding the errors to the global counter\n",
    "                protein_errors_cnt += errors_cnt\n",
    "                \n",
    "                #Adding the filtered to the global counter\n",
    "                protein_filter_cnt += filter_cnt\n",
    "        \n",
    "        domain_ens_genes_indels.append(protein_indels_cnt)\n",
    "        domain_ens_genes_errors.append(protein_errors_cnt)\n",
    "        domain_ens_genes_filter.append(protein_filter_cnt)\n",
    "        print \"Finished protein \"+ens_gene \n",
    "                                \n",
    "    print \"Finished chromosome \"+chrom\n",
    "\n",
    "!mkdir -p domains_states_dicts/pfam-v30/$domain_name\n",
    "with open(curr_dir[0]+\"/domains_states_dicts/pfam-v30/\"+domain_name+\"/\"+domain_name+\"_hmm_states_dict_\"+datetime.date.today().strftime(\"%m.%d.%y\")+\".pik\", 'wb') as handle:\n",
    "    pickle.dump(states_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(domain_ens_genes_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(domain_ens_genes_indels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(domain_ens_genes_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121412"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(chrom_gene_table[\"AN\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

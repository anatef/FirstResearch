{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add SPIDER chemical scores to domains positions\n",
    "\n",
    "For each protein position, update dictionaries with SPIDER2 characteristics.\n",
    "\n",
    "input: SPIDER2 info was saved at: \"ExAC/SPIDER/SPIDER2/protein_seq_results/domain_dicts/\"\n",
    "\n",
    "### Output:\n",
    "Creates a new dictionary/update existing dictionary with the mean coverage for each position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "domains_th = \"10\"\n",
    "update_same_file = True\n",
    "\n",
    "if (update_same_file):\n",
    "    input_path = curr_dir[0]+\"/ext_features_dicts/pfam-v30/\"\n",
    "else:\n",
    "    input_path = curr_dir[0]+\"/../5.HMM_alter_align/domains_states_dicts/pfam-v30/\"\n",
    "\n",
    "#Read the list of domains\n",
    "with open(curr_dir[0]+\"/../5.domains_stats/filtered\"+domains_th+\"_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list = pickle.load(handle)\n",
    "filtered_domains_list.sort()\n",
    "\n",
    "spider_path = curr_dir[0]+\"/../SPIDER/SPIDER2/protein_seq_results/domain_dicts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for domain_name in filtered_domains_list:\n",
    "\n",
    "    dirfiles = !ls -t $input_path$domain_name\n",
    "    filename = dirfiles[0]\n",
    "    with open(input_path+domain_name+\"/\"+filename, 'rb') as handle:\n",
    "        states_dict = pickle.load(handle)\n",
    "    \n",
    "    with open(curr_dir[0]+\"/../4.parse_Uniprot/domains_canonic_prot/pfam-v30/\"+domain_name+\"_canonic_prot.pik\", 'rb') as handle:\n",
    "        canonic_protein = pickle.load(handle)\n",
    "        \n",
    "    with open(spider_path+domain_name+\"_secondary_struct_dict.pik\",'rb') as handle:\n",
    "        spider_domain_dict = pickle.load(handle)\n",
    "        \n",
    "    for state in states_dict.keys():\n",
    "        \n",
    "        for d in states_dict[state]:\n",
    "            \n",
    "            if (spider_domain_dict.has_key(d[\"ens_gene\"]) == False):\n",
    "                print \"Gene is not in the Spider dictionary: \"+d[\"ens_gene\"]\n",
    "                break\n",
    "            if (spider_domain_dict[d[\"ens_gene\"]].has_key(d[\"prot_pos\"]) == False):\n",
    "                print \"protein position is not in the Spider[gene] dictionary: \"+str(d[\"prot_pos\"])\n",
    "                break\n",
    "            \n",
    "            #Getting the relevant Spider entry\n",
    "            spider_entry = spider_domain_dict[d[\"ens_gene\"]][d[\"prot_pos\"]]\n",
    "            \n",
    "            #Validation: Spider has the same AA\n",
    "            if (spider_entry[\"spd3_AA\"] != d[\"aa_ref_orig\"]):\n",
    "                print \"Spider has a different AA: \"+spider_entry[\"hsa2_AA\"]+\" dict AA: \"+d[\"aa_ref_orig\"]+\" Gene: \"+d[\"ens_gene\"]+\" prot_pos: \"+str(d[\"prot_pos\"])\n",
    "                \n",
    "            d[\"spider2-2nd_struct\"] = spider_entry[\"spd3_SS\"] #secondary structure prediction\n",
    "            d[\"spider2-helix_prob\"] = spider_entry[\"spd3_P(H)\"] #alpha-Helix prob.\n",
    "            d[\"spider2-sheet_prob\"] = spider_entry[\"spd3_P(E)\"] #beta-sheet prob.\n",
    "            d[\"spider2-turn_prob\"] = spider_entry[\"spd3_P(C)\"] #turn prob.\n",
    "            d[\"spider2-angle_Phi\"] = spider_entry[\"spd3_Phi\"] #backbone_torsion angle\n",
    "            d[\"spider2-angle_Psi\"] = spider_entry[\"spd3_Psi\"] #backbone_torsion angle\n",
    "            d[\"spider2-angle_tau\"] = spider_entry[\"spd3_Tau(i-2=>i+1)\"] #c-alpha angle (i-2=>i+1)\n",
    "            d[\"spider2-angle_theta\"] = spider_entry [\"spd3_Theta(i-1=>i+1)\"] #c-alpha angle (i-1=>i+1)\n",
    "            d[\"spider2-ASA\"] = spider_entry[\"spd3_ASA\"] #Accessible Surface Area (solvent accessibility)\n",
    "            d[\"spider2-hsa2_HSEu\"] = spider_entry[\"hsa2_HSEu\"] #half-sphere exposure Cα-Cα vectors (HSEα-up)\n",
    "            d[\"spider2-hsa2_HSEd\"] = spider_entry[\"hsa2_HSEd\"] #half-sphere exposure Cα-Cα vectors (HSEα-down)\n",
    "            d[\"spider2-hsb2_HSEu\"] = spider_entry[\"hsb2_HSEu\"] #half-sphere exposure Cα-Cβ vectors (HSEα-up)\n",
    "            d[\"spider2-hsb2_HSEd\"] = spider_entry[\"hsb2_HSEd\"] #half-sphere exposure Cα-Cβ vectors (HSEβ-down)\n",
    "            d[\"spider2-hsa2_CN\"] = spider_entry[\"hsa2_CN\"] #contanct number for Cα-Cα\n",
    "            d[\"spider2-hsb2_CN\"] = spider_entry[\"hsb2_CN\"] #contact number for Cα-Cβ\n",
    "            \n",
    "        print \"Finished state \"+str(state)\n",
    "    #Saving the updated dictionary\n",
    "    !mkdir -p ext_features_dicts/pfam-v30/$domain_name\n",
    "    \n",
    "    with open(curr_dir[0]+\"/ext_features_dicts/pfam-v30/\"+domain_name+\"/\"+domain_name+\"_hmm_states_dict_\"+datetime.date.today().strftime(\"%m.%d.%y\")+\".pik\", 'wb') as handle:\n",
    "        pickle.dump(states_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "           \n",
    "    print \"Finished \"+domain_name\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

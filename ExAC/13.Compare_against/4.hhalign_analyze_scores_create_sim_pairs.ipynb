{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, integrate\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"31\"\n",
    "domains_th = \"10\"\n",
    "\n",
    "hhalign_scores = pd.read_csv(curr_dir[0]+\"/processed_domains_hhlign_scores.csv\", sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the raw score divided by cols aligned\n",
    "from the HHsuite userguide: https://github.com/soedinglab/hh-suite/blob/master/hhsuite-userguide.pdf (page 23):\n",
    "\n",
    "How can I build a phylogenetic tree for HMMs? I would use a similarity measure like\n",
    "the raw score per alignment length. You might also add the secondary structure score to the\n",
    "raw score with some weight. Whereas probabilities, E-values, and P-values are useful for deciding\n",
    "whether a match is a reliable homolog or not, they are not suitable for measuring similarities\n",
    "because they strongly depend on the length of the alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_alignment_cols_ratio_list1 = []\n",
    "score_alignment_cols_ratio_list2 = []\n",
    "for index, row in hhalign_scores.iterrows():\n",
    "    score_norm = row[\"score1\"]/float(row[\"aligned_cols1\"])\n",
    "    score_alignment_cols_ratio_list1.append(score_norm)\n",
    "    score_norm = row[\"score2\"]/float(row[\"aligned_cols2\"])\n",
    "    score_alignment_cols_ratio_list2.append(score_norm)\n",
    "\n",
    "hhalign_scores[\"score_norm1\"] = score_alignment_cols_ratio_list1\n",
    "hhalign_scores[\"score_norm2\"] = score_alignment_cols_ratio_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain similarity filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.001 p-value is the diffault threshold for Viterbi:\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3197634/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "#Has both directions with meaningful alignments (pfal <= 0.001, precent identity >= 25)\n",
    "significantly_pvals = hhalign_scores[hhalign_scores[\"pval1\"] <= 0.001][hhalign_scores[\"pval2\"] <= 0.001]\n",
    "\n",
    "#According to HHsuite userguide, this is the % of aligned columns that match\n",
    "significantly_ident_perc = significantly_pvals[significantly_pvals[\"ident_perc1\"] >= 20][significantly_pvals[\"ident_perc2\"] >= 20]\n",
    "\n",
    "#By HHsuite userguide (page-30): A unit of column score corresponds approximately to 0.6 bits\n",
    "significantly_score = significantly_ident_perc[significantly_ident_perc[\"score_norm1\"] >= 0.6][significantly_ident_perc[\"score_norm2\"] >= 0.6]\n",
    "\n",
    "significantly_similar_pairs = significantly_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1745, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significantly_similar_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to .csv\n",
    "significantly_similar_pairs = significantly_similar_pairs.reset_index(drop=True)\n",
    "significantly_similar_pairs.to_csv(\"processed_domains_sig_pairs_pvals0.001_ident20_score0.6_2directions.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to processed domains not in the significantly similar pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the test domains that weren't used in the pipeline\n",
    "with open(curr_dir[0]+\"/processed_domains_with_labels_not_in_pipeline.pik\", 'rb') as handle:\n",
    "    processed_domains_list = pickle.load(handle)\n",
    "processed_domains_list.sort()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Domains with no significant similarity at all\n",
    "non_similar_domains = []\n",
    "for domain_name in processed_domains_list:\n",
    "    if (domain_name not in significantly_similar_pairs[\"sim_dom1\"].tolist() and domain_name not in significantly_similar_pairs[\"sim_dom2\"].tolist()):\n",
    "        non_similar_domains.append(domain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save to file\n",
    "with open(curr_dir[0]+\"/processed_domains_non_similar_at_all.pik\", 'wb') as handle:\n",
    "    pickle.dump(non_similar_domains, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the other domains - find the ones that form clusters just amongst the processed domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "might_be_similar_domains = list(set(processed_domains_list) - set(non_similar_domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_verify = []\n",
    "for domain in significantly_similar_pairs[\"sim_dom1\"]:\n",
    "    if domain not in processed_domains_list:\n",
    "        pipeline_verify.append(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_for_clusters_analysis = []\n",
    "for domain in might_be_similar_domains:\n",
    "    add = True\n",
    "    domain_table1 = significantly_similar_pairs[significantly_similar_pairs[\"sim_dom1\"] == domain]\n",
    "    domain_table2 = significantly_similar_pairs[significantly_similar_pairs[\"sim_dom2\"] == domain]\n",
    "    \n",
    "    partners1 = domain_table1[\"sim_dom2\"]\n",
    "    partners2 = domain_table2[\"sim_dom1\"]\n",
    "    \n",
    "    for partner in partners1:\n",
    "        if partner in pipeline_verify:\n",
    "            add = False\n",
    "    for partner in partners2:\n",
    "        if partner in pipeline_verify:\n",
    "            add = False\n",
    "    if (add):\n",
    "        domains_for_clusters_analysis.append(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(domains_for_clusters_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Domains similar to other processed domains\n",
    "processed_sim_clusters_idx = []\n",
    "for index, row in significantly_similar_pairs.iterrows():\n",
    "    if (row[\"sim_dom1\"] in domains_for_clusters_analysis and row[\"sim_dom2\"] in domains_for_clusters_analysis):\n",
    "        processed_sim_clusters_idx.append(index)\n",
    "\n",
    "#Save pairs of processed domains similarity clusters\n",
    "signsignificantly_similar_pairs_clusters = significantly_similar_pairs.iloc[processed_sim_clusters_idx,:]\n",
    "signsignificantly_similar_pairs_clusters = signsignificantly_similar_pairs_clusters.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to .csv\n",
    "signsignificantly_similar_pairs_clusters.to_csv(\"processed_domains_sig_pairs_clusters.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 14)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signsignificantly_similar_pairs_clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_similar_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

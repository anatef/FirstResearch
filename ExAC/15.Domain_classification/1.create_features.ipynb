{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a normalized Shannon entropy (from Miller et al, 2015)\n",
    "def entropy(a):\n",
    "    \n",
    "    if len(a) == 1:\n",
    "        return 0 #Min entropy - all the change is in one value\n",
    "    \n",
    "    a = np.asarray(a) / float(sum(a))\n",
    "    entropy = 0\n",
    "    \n",
    "    for val in a:\n",
    "        if (val == 0 or np.isnan(val)):\n",
    "            continue\n",
    "        entropy += val * math.log(val)\n",
    "    \n",
    "    entropy_adj = -entropy / math.log(len(a)) #To account for different size input\n",
    "        \n",
    "    return entropy_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ligand_features(input_path, ligand):\n",
    "    #Raw scores\n",
    "    predicted_scores = pd.read_csv(input_path+\"/\"+ligand+\"_5w.csv\",index_col=0,sep='\\t')\n",
    "    \n",
    "    #Thresholds\n",
    "    percentiles = [25, 50, 75]\n",
    "    per_thresholds = np.percentile(predicted_scores[\"prob\"], percentiles)\n",
    "    zscores_thresholds = [0.5, 1, 2, 3]\n",
    "    \n",
    "    #Initialize dataframe\n",
    "    cols = [ligand+\"_max\", ligand+\"_count\", ligand+\"_entropy\"]\n",
    "    for p in percentiles:\n",
    "        cols.append(ligand+\"_thresh_\"+str(p))\n",
    "    for z in zscores_thresholds:\n",
    "        cols.append(ligand+\"_zthresh_above_\"+str(z))\n",
    "    domain_labels = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    #Values for z-scoring\n",
    "    ligand_mean = np.mean(predicted_scores[\"prob\"])\n",
    "    ligand_std = np.std(predicted_scores[\"prob\"])\n",
    "\n",
    "    for idx,row in predicted_scores.iterrows():\n",
    "        #Extract domain name and check if already added\n",
    "        domain_name = \"_\".join(row[\"idx\"].split(\"_\")[:-1])\n",
    "        if not domain_name in domain_labels.index:\n",
    "            domain_labels.loc[domain_name] = np.zeros(len(domain_labels.columns))\n",
    "            \n",
    "        #Add helpful cols\n",
    "        predicted_scores.loc[idx,\"domain\"] = domain_name\n",
    "        predicted_scores.loc[idx,\"pos\"] = row[\"idx\"].split(\"_\")[-1]\n",
    "            \n",
    "        domain_labels.loc[domain_name,ligand+\"_count\"] += 1\n",
    "\n",
    "        #Update counts\n",
    "        for i in range(0,len(percentiles)):\n",
    "            if row[\"prob\"] > per_thresholds[i]:\n",
    "                domain_labels.loc[domain_name,ligand+\"_thresh_\"+str(percentiles[i])] += 1\n",
    "\n",
    "        #Max labels\n",
    "        domain_labels.loc[domain_name,ligand+\"_max\"] = max(domain_labels.loc[domain_name,ligand+\"_max\"], row[\"prob\"])\n",
    "        \n",
    "        #z-scores\n",
    "        for z in zscores_thresholds:\n",
    "            if (row[\"prob\"]-ligand_mean) / ligand_std > z:\n",
    "                domain_labels.loc[domain_name,ligand+\"_zthresh_above_\"+str(z)] += 1\n",
    "                \n",
    "    for idx,row in domain_labels.iterrows():\n",
    "        #Convert to fractions\n",
    "        for p in percentiles:\n",
    "            domain_labels.loc[idx,ligand+\"_thresh_\"+str(p)] = row[ligand+\"_thresh_\"+str(p)] / row[ligand+\"_count\"]\n",
    "        for z in zscores_thresholds:\n",
    "            domain_labels.loc[idx,ligand+\"_zthresh_above_\"+str(z)] = row[ligand+\"_zthresh_above_\"+str(z)] / row[ligand+\"_count\"]\n",
    "            \n",
    "        #Entropy\n",
    "        matches = predicted_scores.loc[predicted_scores[\"domain\"] == idx,:]\n",
    "        if len(matches) == 0:       #Shouldn't happen\n",
    "            print(\"Error: domain not found: \",idx)\n",
    "        probs = matches[\"prob\"].values\n",
    "        norm = probs / np.linalg.norm(probs)\n",
    "        domain_labels.loc[idx,ligand+\"_entropy\"] = entropy(norm)\n",
    "            \n",
    "    del domain_labels[ligand+\"_count\"]\n",
    "    return domain_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constant_features(input_path, filename, domain_labels):\n",
    "    #All domains are in training set, so use that features table\n",
    "    features_table = pd.read_csv(input_path+filename, index_col=0, sep='\\t')\n",
    "    \n",
    "    #Compute features\n",
    "    for idx,row in domain_labels.iterrows():\n",
    "        matches = features_table.loc[features_table[\"domain_name\"] == idx, :]\n",
    "        #Should never happen\n",
    "        if len(matches) == 0:\n",
    "            print(\"Error: Domain not found: \",idx)\n",
    "        #Length\n",
    "        domain_labels.loc[idx,\"domain_length\"] = matches[\"domain_length\"].values[0]\n",
    "        domain_labels.loc[idx,\"avg_protein_len\"] = np.mean(matches[\"prot_avg_length\"].values)\n",
    "        #Conservation\n",
    "        domain_labels.loc[idx,\"avg_phastCons\"] = matches[\"whole_domain_phastCons_avg\"].values[0]\n",
    "        domain_labels.loc[idx,\"avg_phyloP\"] = matches[\"whole_domain_phyloP_avg\"].values[0]\n",
    "        #Genomic variation\n",
    "        domain_labels.loc[idx,\"avg_maf\"] = np.mean(matches[\"avg_maf_all\"].values)\n",
    "        domain_labels.loc[idx,\"avg_blosum\"] = np.mean(matches[\"blosum_avg\"].values)\n",
    "        #Physiochemical\n",
    "        domain_labels.loc[idx,\"avg_hindex\"] = np.mean(matches[\"hindex_avg\"].values)\n",
    "        domain_labels.loc[idx,\"avg_positve_cnt\"] = np.mean(matches[\"aa_ref_charge_positive_count\"].values)\n",
    "        domain_labels.loc[idx,\"avg_solvent_acc\"] = np.mean(matches[\"solvent_acc_avg\"].values)\n",
    "        domain_labels.loc[idx,\"avg_helix_prob\"] = np.mean(matches[\"helix_prob_avg\"].values)\n",
    "        domain_labels.loc[idx,\"avg_sheet_prob\"] = np.mean(matches[\"sheet_prob_avg\"].values)\n",
    "        domain_labels.loc[idx,\"avg_turn_prob\"] = np.mean(matches[\"turn_prob_avg\"].values)\n",
    "        #Pfam\n",
    "        domain_labels.loc[idx,\"max_pfam_C\"] = np.max(matches[\"pfam_prob_C\"].values)\n",
    "        domain_labels.loc[idx,\"max_pfam_H\"] = np.max(matches[\"pfam_prob_H\"].values)\n",
    "        domain_labels.loc[idx,\"max_pfam_K\"] = np.max(matches[\"pfam_prob_K\"].values)\n",
    "        domain_labels.loc[idx,\"max_pfam_R\"] = np.max(matches[\"pfam_prob_R\"].values)\n",
    "        domain_labels.loc[idx,\"pfam_prob_max\"] = np.max(matches[\"pfam_prob_max\"].values)\n",
    "        domain_labels.loc[idx,\"cnt_pfam_conserved\"] = np.count_nonzero(matches[\"is_pfam_conserved\"].values)\n",
    "        \n",
    "    return domain_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Create features for each of the relevant ligands\n",
    "ligands = [\"dna\",\"rna\",\"ion\",\"peptide\",\"sm\"]\n",
    "ligands_chosen_models = {\"dna\": \"LIGAND\", \"rna\": \"MODEL\", \"ion\": \"MODEL\", \"peptide\": \"MODEL\", \"sm\": \"ALL\"}\n",
    "curr_dir = os.getcwd()\n",
    "input_path = curr_dir+\"/../10.Prediction/stacking/2nd_level_pred/08.06.18_dna0.5_rna0.5_ion0.75/global_auprc/\"\n",
    "domain_labels = pd.DataFrame()\n",
    "\n",
    "for ligand in ligands:\n",
    "    chosen_model = ligands_chosen_models[ligand]\n",
    "    if (chosen_model == \"LIGAND\"):\n",
    "        curr_input_path = input_path+\"ligand_features_probs/\"\n",
    "    elif (chosen_model == \"MODEL\"):\n",
    "        curr_input_path = input_path+\"model_features/\"\n",
    "    elif (chosen_model == \"ALL\"):\n",
    "        curr_input_path = input_path+\"all_features_probs/\"\n",
    "    else:\n",
    "        curr_input_path = input_path+\"just_probs/\"\n",
    "    domain_labels = pd.concat([domain_labels, create_ligand_features(curr_input_path, ligand)], axis=1)\n",
    "    \n",
    "#Add features constant across ligands\n",
    "input_path = curr_dir+\"/../10.Prediction/domains_similarity/filtered_features_table/\"\n",
    "date = \"08.06.18\"\n",
    "filename = \"windowed_positions_features_mediode_filter_\"+date+\".csv\"\n",
    "\n",
    "domain_labels = create_constant_features(input_path, filename, domain_labels)\n",
    "    \n",
    "#Save to file\n",
    "domain_labels.to_csv(\"domain_features.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

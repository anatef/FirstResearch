{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import getcwd, environ\n",
    "import sys\n",
    "\n",
    "#Import utils functions\n",
    "curr_dir = getcwd()\n",
    "sys.path.append(curr_dir+\"/../10.Prediction/utils\")\n",
    "from generate_hyperparameter_trials import generate_trials_XGB\n",
    "from tuning_helper_functions import test_model_on_validation, test_model_on_heldout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = \"08.06.18\"\n",
    "\n",
    "#Read input and sort by domain\n",
    "features_table = pd.read_csv(curr_dir+\"/domain_features.csv\", sep=\"\\t\", index_col=0)\n",
    "features_table.sort_index(inplace=True)\n",
    "labels = pd.read_csv(curr_dir+\"/train_domain_labels_\"+date+\".csv\", sep=\"\\t\", index_col=0)\n",
    "labels.sort_index(inplace=True)\n",
    "\n",
    "#Verify input\n",
    "for i in range(0,features_table.shape[0]):\n",
    "    if features_table.index[i] != labels.index[i]:\n",
    "        print(features_table.index[i])\n",
    "        print(labels.index[i])\n",
    "        print(\"Error: Domains do not match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read hyperparams input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dna\n",
      "fold = 1\n",
      "classifier_method = XGB\n",
      "trial idx = 0\n",
      "Error: goto XGB exception\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dna\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    fold = environ['fold']\n",
    "except:\n",
    "    fold = \"1\"\n",
    "print \"fold = \"+fold\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"XGB\"\n",
    "print \"classifier_method = \"+classifier_method\n",
    "\n",
    "# Reading the index to generate model\n",
    "try:\n",
    "    trial_idx = int(environ[\"trial\"])\n",
    "except:\n",
    "    trial_idx = 0\n",
    "print \"trial idx = \"+ str(trial_idx)\n",
    "\n",
    "if classifier_method == \"XGB\":\n",
    "    \n",
    "    try:\n",
    "        max_depth_ub = int(environ[\"max_depth_ub\"])\n",
    "        max_depth_lb = int(environ[\"max_depth_lb\"])\n",
    "        min_child_weight_ub = float(environ[\"min_child_weight_ub\"])\n",
    "        min_child_weight_lb = float(environ[\"min_child_weight_lb\"])\n",
    "        colsample_bytree_ub = float(environ[\"colsample_bytree_ub\"])\n",
    "        colsample_bytree_lb = float(environ[\"colsample_bytree_lb\"])\n",
    "        gamma_ub = float(environ[\"gamma_ub\"])\n",
    "        gamma_lb = float(environ[\"gamma_lb\"])\n",
    "        learning_rate_ub = float(environ[\"learning_rate_ub\"])\n",
    "        learning_rate_lb = float(environ[\"learning_rate_lb\"])\n",
    "\n",
    "        try:\n",
    "            sec_max_depth_ub = int(environ[\"sec_max_depth_ub\"])\n",
    "            sec_max_depth_lb = int(environ[\"sec_max_depth_lb\"])\n",
    "            max_depth_weight_1 = float(environ[\"max_depth_weight_1\"])\n",
    "            max_depth_weight_2 = float(environ[\"max_depth_weight_2\"])\n",
    "        except:\n",
    "            sec_max_depth_ub = max_depth_ub\n",
    "            sec_max_depth_lb = max_depth_lb\n",
    "            max_depth_weight_1 = 1\n",
    "            max_depth_weight_2 = 1\n",
    "        try:\n",
    "            sec_min_child_weight_ub = float(environ['sec_min_child_weight_ub'])\n",
    "            sec_min_child_weight_lb = float(environ['sec_min_child_weight_lb'])\n",
    "            min_child_weight_weight_1 = float(environ[\"min_child_weight_weight_1\"])\n",
    "            min_child_weight_weight_2 = float(environ[\"min_child_weight_weight_2\"])\n",
    "            \n",
    "        except:\n",
    "            sec_min_child_weight_ub = min_child_weight_ub\n",
    "            sec_min_child_weight_lb = min_child_weight_lb\n",
    "            min_child_weight_weight_1 = 1\n",
    "            min_child_weight_weight_2 = 1\n",
    "        try:\n",
    "            sec_colsample_bytree_ub = float(environ['sec_colsample_bytree_ub'])\n",
    "            sec_colsample_bytree_lb = float(environ['sec_colsample_bytree_lb'])\n",
    "            colsample_bytree_weight_1 = float(environ['colsample_bytree_weight_1'])\n",
    "            colsample_bytree_weight_2 = float(environ['colsample_bytree_weight_2'])\n",
    "        except:\n",
    "            sec_colsample_bytree_ub = colsample_bytree_ub\n",
    "            sec_colsample_bytree_lb = colsample_bytree_lb\n",
    "            colsample_bytree_weight_1 = 1\n",
    "            colsample_bytree_weight_2 = 1\n",
    "            \n",
    "        try:\n",
    "            sec_gamma_ub = float(environ['sec_gamma_ub'])\n",
    "            sec_gamma_lb = float(environ['sec_gamma_lb'])\n",
    "            gamma_weight_1 = float(environ['gamma_weight_1'])\n",
    "            gamma_weight_2 = float(environ['gamma_weight_2'])\n",
    "        except:\n",
    "            sec_gamma_ub = gamma_ub\n",
    "            sec_gamma_lb = gamma_lb\n",
    "            gamma_weight_1 = 1\n",
    "            gamma_weight_2 = 1\n",
    "        try:\n",
    "            sec_learning_rate_ub = float(environ['sec_learning_rate_ub'])\n",
    "            sec_learning_rate_lb = float(environ['sec_learning_rate_lb'])\n",
    "            lr_weight_1 = float(environ['lr_weight_1'])\n",
    "            lr_weight_2 = float(environ['lr_weight_2'])\n",
    "        except:\n",
    "            sec_learning_rate_ub = learning_rate_ub\n",
    "            sec_learning_rate_lb = learning_rate_lb\n",
    "            lr_weight_1 = 1\n",
    "            lr_weight_2 = 1\n",
    "\n",
    "    except:    \n",
    "        print \"Error: goto XGB exception\"\n",
    "        max_depth_ub = 10\n",
    "        max_depth_lb = 1\n",
    "        min_child_weight_ub = 5\n",
    "        min_child_weight_lb = 0\n",
    "        colsample_bytree_ub = 1\n",
    "        colsample_bytree_lb = 0.5\n",
    "        gamma_ub = -1\n",
    "        gamma_lb = -3\n",
    "        learning_rate_ub = -0.3\n",
    "        learning_rate_lb = -1\n",
    "        \n",
    "        sec_max_depth_ub = 10\n",
    "        sec_max_depth_lb = 1\n",
    "        sec_min_child_weight_ub = 5\n",
    "        sec_min_child_weight_lb = 0\n",
    "        sec_colsample_bytree_ub = 1\n",
    "        sec_colsample_bytree_lb = 0.5\n",
    "        sec_gamma_ub = -1\n",
    "        sec_gamma_lb = -3\n",
    "        sec_learning_rate_ub = -0.3\n",
    "        sec_learning_rate_lb = -1\n",
    "        \n",
    "        max_depth_weight_1 = 0.5\n",
    "        max_depth_weight_2 = 0.5\n",
    "        min_child_weight_weight_1 = 0.5\n",
    "        min_child_weight_weight_2 = 0.5\n",
    "        colsample_bytree_weight_1 = 0.5\n",
    "        colsample_bytree_weight_2 = 0.5\n",
    "        gamma_weight_1 = 0.5\n",
    "        gamma_weight_2 = 0.5\n",
    "        lr_weight_1 = 0.5\n",
    "        lr_weight_2 = 0.5\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_trials = 100\n",
    "\n",
    "if classifier_method == \"XGB\":\n",
    "    max_depth_list = [[max_depth_lb, max_depth_ub], [sec_max_depth_lb, sec_max_depth_ub]]\n",
    "    \n",
    "    max_depth_list_weights = [max_depth_weight_1, max_depth_weight_2]\n",
    "    \n",
    "    min_child_weight_list = [[min_child_weight_lb, min_child_weight_ub],[sec_min_child_weight_lb, sec_min_child_weight_ub]]\n",
    "    \n",
    "    min_child_weight_list_weights = [min_child_weight_weight_1, min_child_weight_weight_2]\n",
    "    \n",
    "    colsample_bytree_list = [[colsample_bytree_lb, colsample_bytree_ub], [sec_colsample_bytree_lb, sec_colsample_bytree_ub]]\n",
    "    \n",
    "    colsample_bytree_list_weights = [colsample_bytree_weight_1, colsample_bytree_weight_2]\n",
    "    \n",
    "    gamma_list = [[gamma_lb, gamma_ub],[sec_gamma_lb, sec_gamma_ub]] \n",
    "    \n",
    "    gamma_list_weights = [gamma_weight_1, gamma_weight_2]\n",
    "    \n",
    "    lr_list = [[learning_rate_lb, learning_rate_ub],[sec_learning_rate_lb, sec_learning_rate_ub]]\n",
    "    \n",
    "    lr_list_weights = [lr_weight_1, lr_weight_2]\n",
    "\n",
    "    hyperparameter_trials = generate_trials_XGB(no_trials, max_depth_list, max_depth_list_weights, min_child_weight_list, \n",
    "                                                min_child_weight_list_weights, colsample_bytree_list, colsample_bytree_list_weights, \n",
    "                                                gamma_list, gamma_list_weights, lr_list, lr_list_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.9289728088113784, 'scale_pos_weight': 1, 'learning_rate': 0.273208739594035, 'min_child_weight': 4.2213287429050865, 'max_depth': 6, 'gamma': 0.04948840736375751}\n"
     ]
    }
   ],
   "source": [
    "#print hyperparameter_trials\n",
    "hyperparameters = hyperparameter_trials[trial_idx]\n",
    "if (hyperparameters[\"scale_pos_weight\"] == 0.1):\n",
    "    hyperparameters[\"scale_pos_weight\"] = 1 #dataset is not highly imbalance anymore, 0.1 is not useful here.\n",
    "print hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange ligand data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ligand_str = ligand+\"_label\"\n",
    "domains_positives = labels[labels[ligand_str] == 1].index\n",
    "domains_negatvies = labels[labels[ligand_str] == 0].index\n",
    "ligand_features_positives = features_table.loc[domains_positives,:]\n",
    "ligand_features_negatives = features_table.loc[domains_negatvies,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict and save trial performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #: 1\n",
      "model.best_iteration = 8\n",
      "AUPRC = 0.7844453165881737\n",
      "AUC = 0.9311224489795918\n",
      "model.best_iteration = 2\n",
      "AUPRC = 0.6431216931216931\n",
      "AUC = 0.8742424242424243\n",
      "model.best_iteration = 19\n",
      "AUPRC = 0.5492329196255641\n",
      "AUC = 0.7264150943396227\n",
      "model.best_iteration = 2\n",
      "AUPRC = 0.3816643882433356\n",
      "AUC = 0.7577639751552796\n",
      "Finished dna XGB fold: 1 trial: 0\n",
      "fold #: 1\n",
      "test AUC = 0.9371584699453551\n",
      "test AUPRC = 0.7677179058758006\n",
      "Finished dna XGB fold: 1\n"
     ]
    }
   ],
   "source": [
    "#Run the trial and predict\n",
    "hyperparameters_output_dict = defaultdict(list)\n",
    "\n",
    "#Get validation params\n",
    "test_model_on_validation(hyperparameters, hyperparameters_output_dict, ligand_features_positives, ligand_features_negatives, ligand, classifier_method, fold, trial_idx, features=[],\n",
    "                        xgb_early_stopping_rounds=50, xgb_increase_rounds_limit=0, final_model=False, whole_domain=True)\n",
    "\n",
    "#Get test fold performance\n",
    "if (classifier_method == \"NN\" or classifier_method == \"XGB\"):\n",
    "    hyperparameters[\"mean_epoch_count\"] = hyperparameters_output_dict[\"mean_epoch_count\"]\n",
    "    \n",
    "    \n",
    "test_model_on_heldout(hyperparameters_output_dict, hyperparameters, ligand_features_positives, ligand_features_negatives, ligand, \n",
    "                          classifier_method, fold, features=[], final_model=False, test_positives=None, test_negatives=None, rseed=0, whole_domain=True)\n",
    "hyperparameters_df = pd.DataFrame.from_dict(hyperparameters_output_dict)\n",
    "\n",
    "#Save to file\n",
    "hyperparameters_df.to_csv(curr_dir+\"/hyperparam_tuning/per_trial/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_trial\"+str(trial_idx)+\"_5w_hyperparameters.csv\", sep='\\t')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group domain families by GO terms\n",
    "\n",
    "### Requirements:\n",
    "1. List of domains\n",
    "2. Mapping of pfam domains to GO terms\n",
    "\n",
    "### Instructions:\n",
    "Run the cells and R function in order.\n",
    "\n",
    "### Output:\n",
    "1. freq_counts: A csv mapping GO terms to domains before traversing the GO tree\n",
    "2. freq_counts_broad: A csv mapping GO terms to domains after traversing the GO tree\n",
    "3. freq_counts_expanded: A csv mapping GO terms to domains after traversing the GO tree and giving domains without GO terms the same terms as a domain in the same family\n",
    "4. freq_counts_uniprot: The same as before, but also using Uniprot annotations to add to groups when possible\n",
    "\n",
    "### Other utility:\n",
    "Functions that combine, remove, and compute the overlap of GO terms facilitate the manual formation of groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cPickle as pickle\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "\n",
    "curr_dir = !pwd\n",
    "instance_cutoff = \"10\"\n",
    "pfam_version = \"31\"\n",
    "TEST_PROCCESSED_DOMAINS = False\n",
    "DUFS = True\n",
    "\n",
    "# Reading the list of filtered domains\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    with open(curr_dir[0]+\"/../../13.Compare_against/processed_domains_not_in_pipeline_final_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "elif (DUFS):\n",
    "    with open(curr_dir[0]+\"/../../9.Features_exploration/DUFs_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "else:\n",
    "    with open(curr_dir[0] + \"/../../5.domains_stats/pfam-v\"+pfam_version+\"/filtered\"+instance_cutoff+\"_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "filtered_domains_list.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map GO terms to domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_dict = defaultdict(defaultdict)\n",
    "# Read GO terms line by line\n",
    "with open(curr_dir[0] + '/../../pfam2GO/pfam2go.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        # Skip heading\n",
    "        if line[0] != 'P':\n",
    "            continue\n",
    "        # Skip domains that are not included in the analysis\n",
    "        domain = line[13:line.find('>')-1]\n",
    "        if not domain in filtered_domains_list:\n",
    "            continue\n",
    "        # Map domain to descriptions and GO numbers\n",
    "        tokens = line.split('GO:')\n",
    "        name = tokens[1][0:len(tokens[1])-3]\n",
    "        number = int(tokens[2])\n",
    "        # If domain not already present, create a new dictionary and add it\n",
    "        if not domain in domains_dict:\n",
    "            temp = defaultdict(list)\n",
    "            temp['names'].append(name)\n",
    "            temp['numbers'].append(number)\n",
    "            domains_dict[domain] = temp\n",
    "        # Otherwise, append to the existing dictionary\n",
    "        else:\n",
    "            domains_dict[domain]['names'].append(name)\n",
    "            domains_dict[domain]['numbers'].append(number)\n",
    "            \n",
    "# Compute frequency counts\n",
    "counts = {}\n",
    "numbers_to_names = {}\n",
    "numbers_to_domains = {}\n",
    "for k in domains_dict.keys():\n",
    "    for i in range(0,len(domains_dict[k]['numbers'])):\n",
    "        num = domains_dict[k]['numbers'][i]\n",
    "        if num in counts:\n",
    "            counts[num] += 1\n",
    "        else:\n",
    "            counts[num] = 1\n",
    "        if not num in numbers_to_names.keys():\n",
    "            numbers_to_names[num] = domains_dict[k]['names'][i]\n",
    "            numbers_to_domains[num] = k\n",
    "        else:\n",
    "            numbers_to_domains[num] += \".\" + k\n",
    "sorted_counts = sorted(counts.items(),key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "# Add to dataframe\n",
    "all_counts = pd.DataFrame(columns=['number','count','name','domains'])\n",
    "i = 1\n",
    "for c in sorted_counts:\n",
    "    all_counts.loc[i,'number'] = c[0]\n",
    "    all_counts.loc[i,'count'] = c[1]\n",
    "    all_counts.loc[i,'name'] = numbers_to_names[c[0]]\n",
    "    all_counts.loc[i,'domains'] = numbers_to_domains[c[0]]\n",
    "    i += 1\n",
    "    \n",
    "# Save to csv\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    all_counts.to_csv(\"pfam-v\"+pfam_version+\"_less_than_10/freq_counts\"+instance_cutoff+\".csv\")\n",
    "elif (DUFS):\n",
    "    all_counts.to_csv(\"pfam-v\"+pfam_version+\"_less_than_10/DUFs_freq_counts\"+instance_cutoff+\".csv\")\n",
    "else:\n",
    "    all_counts.to_csv(\"pfam-v\"+pfam_version+\"/freq_counts\"+instance_cutoff+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swim up GO tree\n",
    "\n",
    "Before continuing, run domain_go.R to move domains associated with narrow GO terms to broader ones to facilitate grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reorganize by domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read file\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    freq_counts_broad = pd.read_csv(curr_dir[0]+\"/pfam-v\"+pfam_version+\"_less_than_10/freq_counts_broad\"+instance_cutoff+\".csv\",index_col=0)\n",
    "elif (DUFS):\n",
    "    freq_counts_broad = pd.read_csv(curr_dir[0]+\"/pfam-v\"+pfam_version+\"_less_than_10/DUFs_freq_counts_broad\"+instance_cutoff+\".csv\",index_col=0)\n",
    "else:    \n",
    "    freq_counts_broad = pd.read_csv(curr_dir[0]+\"/pfam-v\"+pfam_version+\"/freq_counts_broad\"+instance_cutoff+\".csv\",index_col=0)\n",
    "\n",
    "domain_counts = pd.DataFrame(columns=[\"count\",\"groups\"])\n",
    "for row in freq_counts_broad.iterrows():\n",
    "    for d in freq_counts_broad.loc[row[0],\"domains\"].split(\".\"):\n",
    "        if d in domain_counts.index:\n",
    "            domain_counts.loc[d,\"count\"] += 1\n",
    "            domain_counts.loc[d,\"groups\"] += \".\" + freq_counts_broad.loc[row[0],\"name\"]\n",
    "        else:\n",
    "            domain_counts.loc[d,\"count\"] = 1\n",
    "            domain_counts.loc[d,\"groups\"] = freq_counts_broad.loc[row[0],\"name\"]\n",
    "\n",
    "domain_counts = domain_counts.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For domains without GO terms, find domain with a GO term from the same family if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any match is fine, so overwriting on repeats is allowable\n",
    "fam_map = {}\n",
    "for row in domain_counts.iterrows():\n",
    "    fam = row[0].replace('-','_').split('_')[0].lower()\n",
    "    fam_map[fam] = row[0]\n",
    "    \n",
    "# Find matches\n",
    "for domain in filtered_domains_list:\n",
    "    if not domain in domain_counts.index:\n",
    "        fam = domain.replace('-','_').split('_')[0].lower()\n",
    "        if not fam in fam_map:\n",
    "            continue\n",
    "        close_domain = fam_map[fam]\n",
    "        # Copy row\n",
    "        domain_counts.loc[domain,\"count\"] = domain_counts.loc[close_domain,\"count\"]\n",
    "        domain_counts.loc[domain,\"groups\"] = domain_counts.loc[close_domain,\"groups\"]\n",
    "        # Update freq_counts\n",
    "        terms = domain_counts.loc[domain,\"groups\"].split(\".\")\n",
    "        for t in terms:\n",
    "            freq_counts_broad.loc[freq_counts_broad.loc[:,\"name\"] == t,\"domains\"] += \".\" + domain\n",
    "            freq_counts_broad.loc[freq_counts_broad.loc[:,\"name\"] == t,\"count\"] += 1\n",
    "            \n",
    "# Save to csv\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    freq_counts_broad.to_csv(\"pfam-v\"+pfam_version+\"_less_than_10/freq_counts_expanded\"+instance_cutoff+\".csv\")\n",
    "elif (DUFS):\n",
    "    freq_counts_broad.to_csv(\"pfam-v\"+pfam_version+\"_less_than_10/DUFs_freq_counts_expanded\"+instance_cutoff+\".csv\")\n",
    "else:\n",
    "    freq_counts_broad.to_csv(\"pfam-v\"+pfam_version+\"/freq_counts_expanded\"+instance_cutoff+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Uniprot annotations also if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/anat/Research/ExAC/8.Whole_domain_analysis/families_go/../uniprot_annotations/uniprot_annotations_dict.pik'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1d01a17cd48a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Load annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/../uniprot_annotations/uniprot_annotations_dict.pik\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0muniprot_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/anat/Research/ExAC/8.Whole_domain_analysis/families_go/../uniprot_annotations/uniprot_annotations_dict.pik'"
     ]
    }
   ],
   "source": [
    "# Fraction of genes that must have annotations to consider in group\n",
    "thresh = 0.25\n",
    "\n",
    "def add_domain(condition,number,domain_name):\n",
    "    if condition and not domain_name in freq_counts_broad.loc[freq_counts_broad.loc[:,'number'] == number,'domains'].values[0].split('.'):\n",
    "        freq_counts_broad.loc[freq_counts_broad.loc[:,'number'] == number,'count'] += 1\n",
    "        freq_counts_broad.loc[freq_counts_broad.loc[:,'number'] == number,'domains'] += '.'+domain_name\n",
    "\n",
    "# Load annotations\n",
    "with open(curr_dir[0] + \"/../uniprot_annotations/uniprot_annotations_dict.pik\", 'rb') as handle:\n",
    "    uniprot_dict = pickle.load(handle)\n",
    "\n",
    "for domain_name in filtered_domains_list:\n",
    "    if len(uniprot_dict[domain_name]) == 0:\n",
    "        continue\n",
    "    # Check each for relevant annotations and keep track of genes\n",
    "    metal_gene = np.zeros(len(uniprot_dict[domain_name]))\n",
    "    nucleic_gene = np.zeros(len(uniprot_dict[domain_name]))\n",
    "    nucleotide_gene = np.zeros(len(uniprot_dict[domain_name]))\n",
    "    index = 0\n",
    "    for gene in uniprot_dict[domain_name]:\n",
    "        for pos in uniprot_dict[domain_name][gene]:\n",
    "            ent = uniprot_dict[domain_name][gene][pos]\n",
    "            if 'calcium' in ent:\n",
    "                metal_gene[index] = 1\n",
    "            if 'metal' in ent:\n",
    "                metal_gene[index] = 1\n",
    "            if 'dna' in ent:\n",
    "                nucleic_gene[index] = 1\n",
    "            if 'nucleotide' in ent:\n",
    "                nucleotide_gene[index] = 1\n",
    "        index += 1\n",
    "    \n",
    "    # If annotations found, add to groups\n",
    "    add_domain(sum(metal_gene)/float(len(metal_gene)) > thresh,46872,domain_name)\n",
    "    add_domain(sum(nucleic_gene)/float(len(nucleic_gene)) > thresh,3676,domain_name)\n",
    "    add_domain(sum(nucleotide_gene)/float(len(nucleotide_gene)) > thresh,166,domain_name)\n",
    "\n",
    "# Save to csv\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "     freq_counts_broad.to_csv(\"pfam-v\"+pfam_version+\"_less_than_10/freq_counts_uniprot\"+instance_cutoff+\".csv\")\n",
    "else:\n",
    "    freq_counts_broad.to_csv(\"pfam-v\"+pfam_version+\"/freq_counts_uniprot\"+instance_cutoff+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to help manual group formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify freq_counts_broad for logical operations\n",
    "for row in freq_counts_broad.iterrows():\n",
    "    domains = freq_counts_broad.loc[row[0],\"domains\"]\n",
    "    if domains[0] != '.':\n",
    "        freq_counts_broad.loc[row[0],\"domains\"] = \".\" + freq_counts_broad.loc[row[0],\"domains\"] + \".\"\n",
    "        \n",
    "# The union of domains in two or more groups\n",
    "def combine(groups):\n",
    "    domains_combined = \".\"\n",
    "    for g in groups:\n",
    "        # A list of terms can also be a string separated by periods\n",
    "        terms = g.split(\".\")\n",
    "        for t in terms:\n",
    "            domains = freq_counts_broad.loc[freq_counts_broad.loc[:,\"name\"] == t,\"domains\"].values[0].split(\".\")\n",
    "            for d in domains:\n",
    "                if len(d) > 0 and not \".\" + d + \".\" in domains_combined:\n",
    "                    domains_combined += d + \".\"\n",
    "    return(domains_combined)\n",
    "\n",
    "# Remove one or more groups and all domains associated from freq_counts_broad\n",
    "def remove(groups):\n",
    "    freq_counts_removed = freq_counts_broad.copy()\n",
    "    for g in groups:\n",
    "        for d in freq_counts_removed.loc[freq_counts_removed.loc[:,\"name\"] == g,\"domains\"].values[0].split(\".\"):\n",
    "            for row in freq_counts_removed.iterrows():\n",
    "                if \".\" + d + \".\" in freq_counts_removed.loc[row[0],\"domains\"]:\n",
    "                    freq_counts_removed.loc[row[0],\"count\"] -= 1\n",
    "                    freq_counts_removed.loc[row[0],\"domains\"] = freq_counts_removed.loc[row[0],\"domains\"].replace(d + \".\",\"\")\n",
    "    # Remove rows with no entries left\n",
    "    freq_counts_removed = freq_counts_removed.drop(freq_counts_removed.loc[freq_counts_removed.loc[:,\"count\"] == 0,:].index)\n",
    "    return(freq_counts_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domains</th>\n",
       "      <th>total overlap</th>\n",
       "      <th>nucleic acid binding.nucleotide binding overlap</th>\n",
       "      <th>protein binding overlap</th>\n",
       "      <th>metal ion binding overlap</th>\n",
       "      <th>membrane overlap</th>\n",
       "      <th>intracellular overlap</th>\n",
       "      <th>signal transduction overlap</th>\n",
       "      <th>nucleic acid binding overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nucleic acid binding</th>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protein binding</th>\n",
       "      <td>122</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metal ion binding</th>\n",
       "      <td>66</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>membrane</th>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intracellular</th>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>signal transduction</th>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     domains total overlap  \\\n",
       "nucleic acid binding      77            22   \n",
       "protein binding          122            13   \n",
       "metal ion binding         66            20   \n",
       "membrane                  65            17   \n",
       "intracellular             40            20   \n",
       "signal transduction       35            15   \n",
       "\n",
       "                     nucleic acid binding.nucleotide binding overlap  \\\n",
       "nucleic acid binding                                             NaN   \n",
       "protein binding                                                  NaN   \n",
       "metal ion binding                                                NaN   \n",
       "membrane                                                         NaN   \n",
       "intracellular                                                    NaN   \n",
       "signal transduction                                              NaN   \n",
       "\n",
       "                      protein binding overlap  metal ion binding overlap  \\\n",
       "nucleic acid binding                        3                          7   \n",
       "protein binding                           NaN                          3   \n",
       "metal ion binding                           3                        NaN   \n",
       "membrane                                    0                          6   \n",
       "intracellular                               3                          5   \n",
       "signal transduction                         5                          0   \n",
       "\n",
       "                      membrane overlap  intracellular overlap  \\\n",
       "nucleic acid binding                 1                     10   \n",
       "protein binding                      0                      3   \n",
       "metal ion binding                    6                      5   \n",
       "membrane                           NaN                      3   \n",
       "intracellular                        3                    NaN   \n",
       "signal transduction                  8                      1   \n",
       "\n",
       "                      signal transduction overlap  \\\n",
       "nucleic acid binding                            3   \n",
       "protein binding                                 5   \n",
       "metal ion binding                               0   \n",
       "membrane                                        8   \n",
       "intracellular                                   1   \n",
       "signal transduction                           NaN   \n",
       "\n",
       "                      nucleic acid binding overlap  \n",
       "nucleic acid binding                           NaN  \n",
       "protein binding                                  3  \n",
       "metal ion binding                                7  \n",
       "membrane                                         1  \n",
       "intracellular                                   10  \n",
       "signal transduction                              3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organize categories into a table\n",
    "\n",
    "# List of groups — a '.' indicates a group is a combination of GO terms\n",
    "groups = [\"nucleic acid binding.nucleotide binding\",\"protein binding\",\"metal ion binding\",\"membrane\",\"intracellular\",\"signal transduction\"]\n",
    "copy = [\"nucleic acid binding.nucleotide binding\",\"protein binding\",\"metal ion binding\",\"membrane\",\"intracellular\",\"signal transduction\"]\n",
    "\n",
    "comb = combine(groups).split(\".\")\n",
    "\n",
    "# Initialize and populate dataframe\n",
    "categories = pd.DataFrame(columns=[\"domains\",\"total overlap\",groups[0]+\" overlap\"])\n",
    "for g in groups:\n",
    "    # Find number of domains in group\n",
    "    terms = g.split(\".\")\n",
    "    categories.loc[terms[0],\"domains\"] = 0\n",
    "    for t in terms:\n",
    "        categories.loc[terms[0],\"domains\"] += freq_counts_broad.loc[freq_counts_broad.loc[:,\"name\"] == t,\"count\"].values[0]\n",
    "    term = combine(terms).split(\".\")\n",
    "    \n",
    "    # Compute overlap — total and with other groups\n",
    "    copy.remove(g)\n",
    "    others = combine(copy).split(\".\")\n",
    "    categories.loc[terms[0],\"total overlap\"] = len(term) + len(others) - len(comb) - 2\n",
    "    for other_group in copy:\n",
    "        other_terms = other_group.split(\".\")\n",
    "        other = combine(other_terms).split(\".\")\n",
    "        both = combine(terms+other_terms).split(\".\")\n",
    "        categories.loc[terms[0],other_terms[0]+\" overlap\"] = len(term) + len(other) - len(both) - 2\n",
    "    copy.append(g)\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

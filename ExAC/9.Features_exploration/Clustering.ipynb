{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute clustering of non-synonomous mutations\n",
    "\n",
    "### Requirements:\n",
    "1. List of domains\n",
    "2. Domain dictionaries\n",
    "\n",
    "### Instructions:\n",
    "Run cells in order\n",
    "\n",
    "### Output:\n",
    "A csv file containing a clustering score for each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "curr_dir = !pwd\n",
    "sys.path.append(curr_dir[0] + \"/../5.HMM_alter_align\") \n",
    "from calc_exac_freq_func import codon_table\n",
    "from dnds_func import calculate_ns, seq_ns\n",
    "from collections import defaultdict\n",
    "\n",
    "#Getting path\n",
    "curr_dir = !pwd\n",
    "intance_cutoff = \"10\"\n",
    "\n",
    "#Reading the list of filtered domains\n",
    "with open(curr_dir[0]+\"/../5.domains_stats/filtered\"+intance_cutoff+\"_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list = pickle.load(handle)\n",
    "filtered_domains_list.sort()\n",
    "\n",
    "#Reading the table of all domains stats\n",
    "filtered_domains_df = pd.read_csv(curr_dir[0]+\"/../5.domains_stats/filtered\"+intance_cutoff+\"_domains_df.csv\",\n",
    "                                  sep='\\t', index_col=0)\n",
    "input_path = curr_dir[0]+\"/../5.HMM_alter_align/domains_states_dicts/pfam-v30/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute P<sub>u</sub> from Wagner, 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes the variance of the distance array\n",
    "def calc_stat(sample):\n",
    "    # Compute x\n",
    "    x = [0]\n",
    "    for i in range(0,len(sample)):\n",
    "        if sample[i] == 1:\n",
    "            x.append(i)\n",
    "    x.append(len(sample)-1)\n",
    "\n",
    "    # Compute d\n",
    "    d = np.zeros(len(x)-1)\n",
    "    for i in range(0,len(x)-1):\n",
    "        d[i] = x[i+1]-x[i]\n",
    "\n",
    "    return(np.std(d)*np.std(d))\n",
    "\n",
    "# Sample 10,000 times from a uniform distribution and compare\n",
    "def gen_random(sample):\n",
    "    stats = []\n",
    "    for i in range(0,10000):\n",
    "        np.random.shuffle(sample)\n",
    "        stats.append(calc_stat(sample))\n",
    "    return(stats)\n",
    "\n",
    "# Performs the permutation test to calculate Pu\n",
    "def p_val(sample):\n",
    "    stat = calc_stat(sample)\n",
    "    rands = gen_random(sample)\n",
    "    counter = 0\n",
    "    for rand in rands:\n",
    "        # Less than or equals fixes the case if there are 0 mutations\n",
    "        if stat <= rand:\n",
    "            counter += 1\n",
    "    return(counter/10000.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most recent file for a given domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recent_file(path,domain):\n",
    "    # Reading the domain states dictionary\n",
    "    domain_dirfiles = !ls -t $path$domain\n",
    "    # Find the most recent file\n",
    "    recent_priority = -1\n",
    "    recent_filename = \"\"\n",
    "    for f in domain_dirfiles:\n",
    "        tokens = f.split(\"_\")\n",
    "        date = tokens[len(tokens)-1].split(\".\")\n",
    "        month = int(date[0])\n",
    "        day = int(date[1])\n",
    "        # Not all files have years, but those that do are the most recent\n",
    "        if date[2] != \"pik\":\n",
    "            year = int(date[2])\n",
    "        else:\n",
    "            year = 0\n",
    "        priority = year*1000 + month*50 + day\n",
    "        if priority > recent_priority:\n",
    "            recent_priority = priority\n",
    "            recent_filename = f\n",
    "    return(recent_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average non-synonomous mutation rates across instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nonsyn mutation rates averaged across instances for every position in every domain\n",
    "nonsyn_rates = []\n",
    "\n",
    "for domain_name in filtered_domains_list:\n",
    "    # Load file\n",
    "    with open(input_path+domain_name+\"/\"+recent_file(input_path,domain_name), 'rb') as handle:\n",
    "        states_dict = pickle.load(handle)\n",
    "    \n",
    "    # Average non-synonomous mutation rates across instances\n",
    "    for state in states_dict:\n",
    "        nonsyns = 0\n",
    "        for d in states_dict[state]:\n",
    "            for val in d['alterations_af_adj_dict'].values():\n",
    "                nonsyns += val[0]\n",
    "        if nonsyns == 0:\n",
    "            nonsyn_rates.append(0)\n",
    "        else:\n",
    "            nonsyn_rates.append(nonsyns / len(states_dict[state]))\n",
    "\n",
    "# Get percentiles\n",
    "rates = np.asarray(nonsyn_rates)\n",
    "percentiles = np.percentile(rates,[95,90,85,80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute clustering from data binned with fixed thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clustering_fixed_cutoff(thresh,labels):\n",
    "    scores = pd.DataFrame()\n",
    "    for domain_name in filtered_domains_list:\n",
    "        # Open recent file\n",
    "        with open(input_path+domain_name+\"/\"+recent_file(input_path,domain_name), 'rb') as handle:\n",
    "            states_dict = pickle.load(handle)\n",
    "        \n",
    "        # Get rate of nonsynonomous mutations for each position\n",
    "        nonsyn_rates = []\n",
    "        for state in states_dict:\n",
    "            nonsyns = 0\n",
    "            for d in states_dict[state]:\n",
    "                for val in d['alterations_af_adj_dict'].values():\n",
    "                    nonsyns += val[0]\n",
    "            if nonsyns == 0:\n",
    "                nonsyn_rates.append(0)\n",
    "            else:\n",
    "                nonsyn_rates.append(nonsyns / len(states_dict[state]))\n",
    "        \n",
    "        # Bin the rates for each threshold and calculate clustering\n",
    "        for i in range(0,len(thresh)):\n",
    "            t = thresh[i]\n",
    "            bin_rates = []\n",
    "            for j in range(0,len(nonsyn_rates)):\n",
    "                if nonsyn_rates[j] >= t:\n",
    "                    bin_rates.append(1)\n",
    "                else:\n",
    "                    bin_rates.append(0)\n",
    "            scores.loc[domain_name,str(labels[i])] = p_val(bin_rates)\n",
    "            scores.loc[domain_name,str(labels[i])+\" ratio\"] = float(sum(bin_rates)) / len(bin_rates)\n",
    "    return(scores)\n",
    "\n",
    "# Use percentiles as a threshold, for instance\n",
    "scores = clustering_fixed_cutoff(percentiles,[\"95\",\"90\",\"85\",\"80\"])\n",
    "scores.to_csv(\"clustering_percentile.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute clustering with data binned with a binomial test from Tamborero et al, 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "thresh = np.mean(nonsyn_rates)\n",
    "scores = pd.DataFrame()\n",
    "for domain_name in filtered_domains_list:\n",
    "    # Open recent file\n",
    "    with open(input_path+domain_name+\"/\"+recent_file(input_path,domain_name), 'rb') as handle:\n",
    "        states_dict = pickle.load(handle)\n",
    "    \n",
    "    # Get total number of mutations and total number of people sampled per position\n",
    "    mutations = []\n",
    "    people = []\n",
    "    for state in states_dict:\n",
    "        mut = 0\n",
    "        total = 0\n",
    "        for d in states_dict[state]:\n",
    "            for val in d['alterations_af_adj_dict'].values():\n",
    "                mut += val[0]*max(d['an_adj'])\n",
    "            if len(d['alterations_af_adj_dict']) > 0:\n",
    "                total += max(d['an_adj'])\n",
    "        mutations.append(mut)\n",
    "        people.append(total)\n",
    "    \n",
    "    # Bin data\n",
    "    bin_rates = []\n",
    "    for i in range(0,len(mutations)):\n",
    "        if binom.cdf(np.round(mutations[i]),people[i],thresh) >= 0.99:\n",
    "            bin_rates.append(1)\n",
    "        else:\n",
    "            bin_rates.append(0)\n",
    "\n",
    "    # Compute clustering\n",
    "    scores.loc[domain_name,\"0.99\"] = p_val(bin_rates)\n",
    "    scores.loc[domain_name,\"0.99 ratio\"] = float(sum(bin_rates)) / len(bin_rates)\n",
    "    \n",
    "# Save to csv\n",
    "scores.to_csv(\"clustering_binom.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

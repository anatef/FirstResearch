{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "#My modules\n",
    "from dnds_func import calculate_ns, seq_ns\n",
    "from aa_chemical_properties import aa_charge, aa_charge_dict, aa_functional_group, aa_functional_group_dict, hindex_Kyte_Doolitle, aa_propensity,\\\n",
    "                                    propensity_chou_fasman, aa_volume_group, aa_volume, aa_volume_group_dict, aa_h_bond_donor, aa_h_bond_acceptor\n",
    "from ext_predictors_codes import sift_codes, polyphen_codes, clinvar_codes\n",
    "\n",
    "curr_dir = !pwd\n",
    "sys.path.append(curr_dir[0]+'/../5.HMM_alter_align') \n",
    "from calc_exac_freq_func import codon_table\n",
    "from entropy_func import SE_hist, JSD_background, JSD_hist\n",
    "sys.path.append(curr_dir[0]+'/../8.Whole_domain_analysis')\n",
    "from go_groups import go_term_group\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"32\"\n",
    "domains_th = \"10\"\n",
    "SIFT_THRESHOLD = 0.05\n",
    "TEST_PROCCESSED_DOMAINS = False\n",
    "\n",
    "#Rare SNP thresholds\n",
    "MAFT_5 =  0.005\n",
    "MAFT_05 = 0.0005\n",
    "MAFT_005 = 0.00005\n",
    "        \n",
    "hmm_filename = curr_dir[0]+\"/../2.parse_Pfam/v\"+pfam_version+\"/domains_hmm_prob_dict.pik\"\n",
    "pfam_aa_order = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "amino_acids_sym = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', \"*\"]\n",
    "ligands = [\"dna\", \"dnabase\", \"dnabackbone\", \"rna\", \"rnabase\", \"rnabackbone\", \"peptide\", \"ion\", \"metabolite\", \"sm\", \"druglike\", \"all\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of domains = 1503\n"
     ]
    }
   ],
   "source": [
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    input_path = curr_dir[0]+\"/../6.Ext_features_to_dicts/ext_features_dicts/pfam-v\"+pfam_version+\"_less_than_10/\"\n",
    "else:\n",
    "    input_path = curr_dir[0]+\"/../6.Ext_features_to_dicts/ext_features_dicts/pfam-v\"+pfam_version+\"/\"\n",
    "\n",
    "#Reading the BLOSUM62 dict\n",
    "with open(curr_dir[0]+\"/../BLOSUM62/BLOSUM62_dict.pik\", 'rb') as handle:\n",
    "    blosum62_dict = pickle.load(handle)\n",
    "\n",
    "#Reading the PAM40 dict\n",
    "with open(curr_dir[0]+\"/../PAM40/PAM40_dict.pik\", 'rb') as handle:\n",
    "    pam40_dict = pickle.load(handle)\n",
    "\n",
    "#Backward compatibilty for pfam-v30 (and older) old binding scores\n",
    "if (int(pfam_version) <= 30):\n",
    "    #Read binding scores\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/domains_binding_dict.pik\", 'rb') as handle:\n",
    "        binding_scores_dict = pickle.load(handle) #TODO: is this needed?\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/domains_all_binding_dict.pik\", 'rb') as handle:\n",
    "        binding_all_scores_dict = pickle.load(handle)\n",
    "\n",
    "    #Read binding scores per ligand dictionaries\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/dna_binding_dict.pik\", 'rb') as handle:\n",
    "        dna_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/rna_binding_dict.pik\", 'rb') as handle:\n",
    "        rna_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/dnabase_binding_dict.pik\", 'rb') as handle:\n",
    "        dnabase_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/rnabase_binding_dict.pik\", 'rb') as handle:\n",
    "        rnabase_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/dnabackbone_binding_dict.pik\", 'rb') as handle:\n",
    "        dnabackbone_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/rnabackbone_binding_dict.pik\", 'rb') as handle:\n",
    "        rnabackbone_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/ion_binding_dict.pik\", 'rb') as handle:\n",
    "        ion_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/peptide_binding_dict.pik\", 'rb') as handle:\n",
    "        peptide_binding_scores_dict = pickle.load(handle)\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/pfam-v30_old_scores/binding_dicts/metabolite_binding_dict.pik\", 'rb') as handle:\n",
    "        metabolite_binding_scores_dict = pickle.load(handle)\n",
    "\n",
    "#Newer InteracDome propensities        \n",
    "else:\n",
    "    with open(curr_dir[0]+\"/../7.InteracDome_targetVariable/domains_ligands_propensity_dict.pik\", 'rb') as handle:\n",
    "        binding_props_dict = pickle.load(handle)\n",
    "    \n",
    "#Read the list of domains\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    with open(curr_dir[0]+\"/../13.Compare_against/processed_domains_not_in_pipeline_final_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "elif (pfam_version==\"32\"):\n",
    "    with open(curr_dir[0]+\"/../5.domains_stats/pfam-v\"+pfam_version+\"/regular_human_domains_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "else:\n",
    "    with open(curr_dir[0]+\"/../5.domains_stats/pfam-v\"+pfam_version+\"/filtered\"+domains_th+\"_list.pik\", 'rb') as handle:\n",
    "        filtered_domains_list = pickle.load(handle)\n",
    "filtered_domains_list.sort()\n",
    "\n",
    "\n",
    "#Read the substitutions table (for the dN/dS calculation)\n",
    "with open(curr_dir[0]+\"/codon_ns_table.pik\", 'rb') as handle:\n",
    "    codon_ns_table = pickle.load(handle)\n",
    "    \n",
    "#Read the whole-domain conservation dict\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    with open(curr_dir[0]+\"/../8.Whole_domain_analysis/pfam-v\"+pfam_version+\"_less_than_10/domain_conservation_dict.pik\", 'rb') as handle:\n",
    "        whole_domain_con_dict = pickle.load(handle)\n",
    "else:\n",
    "    with open(curr_dir[0]+\"/../8.Whole_domain_analysis/pfam-v\"+pfam_version+\"/domain_conservation_dict.pik\", 'rb') as handle:\n",
    "        whole_domain_con_dict = pickle.load(handle)\n",
    "    \n",
    "#Read the whole_domain GO classification dict\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    with open(curr_dir[0]+\"/../8.Whole_domain_analysis/pfam-v\"+pfam_version+\"_less_than_10/domain_go_dict.pik\", 'rb') as handle:\n",
    "        whole_domain_GO_dict = pickle.load(handle)\n",
    "else:\n",
    "    with open(curr_dir[0]+\"/../8.Whole_domain_analysis/pfam-v\"+pfam_version+\"/domain_go_dict.pik\", 'rb') as handle:\n",
    "        whole_domain_GO_dict = pickle.load(handle)\n",
    "\n",
    "#Open the HMM dict - takes some time\n",
    "with open(hmm_filename, 'rb') as handle:\n",
    "    hmm_prob_dict = pickle.load(handle)    \n",
    "    \n",
    "#Creating a list of the intersection of domains with binding scores and domains with states dicts\n",
    "domains = []\n",
    "for domain in filtered_domains_list:\n",
    "    if (domain in binding_props_dict.keys()):\n",
    "        domains.append(domain)\n",
    "print \"number of domains = \"+str(len(domains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#domains = filtered_domains_list\n",
    "#spider_problems_domains_list = [\"Ank_2\", \"Ank_4\", \"Ank_5\", \"Asp\", \"CD45\", \"Cys_knot\", \"DENN\", \"DUF1908\", \"DUF4187\", \"EF-hand_1\", \"EF-hand_5\", \"EF-hand_6\", \"EF-hand_7\", \"EF-hand_8\", \"EF-hand_9\", \"EFhand_Ca_insen\", \"ELM2\", \"Exo_endo_phos\", \"FYVE\", \"G-patch\", \"G-patch_2\", \"GRAM\", \"GSHPx\", \"IQ_SEC7_PH\", \"LRR_1\", \"LRR_12\", \"LRR_6\", \"LRR_8\", \"MFS_1\", \"Myb_DNA-binding\", \"Myotub-related\", \"PDZ\", \"PDZ_6\", \"PH\", \"PNMA\", \"PTP_N\", \"Pkinase\", \"Pkinase_Tyr\", \"RNase_T\", \"RUN\", \"Rdx\", \"SBF2\", \"SKICH\", \"Sec7\", \"SelP_C\", \"SelP_N\", \"SelR\", \"Sep15_SelM\", \"T4_deiodinase\", \"TAXi_N\", \"TIR\", \"Trefoil\", \"V-set\", \"WAP\", \"Y_phosphatase\", \"dDENN\", \"fn3\", \"uDENN\", \"zf-C2H2\", \"zf-C2H2_4\", \"zf-CCCH\", \"zf-H2C2_5\"]\n",
    "#domains = spider_problems_domains_list\n",
    "#len(domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for calculating features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExAC alterations functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExAC_MAF_features(features_dict, state_id, table_columns, first_pass, sites_aa_num, sites_aa_alter_num, maf_list):\n",
    "    \n",
    "    #Feature: avg MAF\n",
    "    if (sites_aa_num == 0):\n",
    "        avg_maf_overall = 0\n",
    "    else:\n",
    "        avg_maf_overall = np.sum(maf_list)/float(sites_aa_num)\n",
    "    features_dict[state_id].append(avg_maf_overall)\n",
    "    if (first_pass): table_columns.append(\"avg_maf_all\")\n",
    "\n",
    "    #Feature: avg MAF of all the altered sites\n",
    "    if (sites_aa_alter_num == 0):\n",
    "        avg_maf_only_altered = 0\n",
    "    else:\n",
    "        avg_maf_only_altered = np.sum(maf_list)/float(sites_aa_alter_num)\n",
    "    features_dict[state_id].append(avg_maf_only_altered)\n",
    "    if (first_pass): table_columns.append(\"avg_maf_altered\")\n",
    "    \n",
    "    bins = [0, 0.001, 0.005, 0.01, 0.02, 0.04, 0.06, 0.08, 0.1, 0.2, 0.5]\n",
    "    non_zero_maf_lst = np.array(maf_list)[np.nonzero(maf_list)[0].tolist()]\n",
    "    \n",
    "    maf_hist = np.histogram(non_zero_maf_lst, bins)[0]\n",
    "    \n",
    "    features_dict[state_id].extend(maf_hist)\n",
    "    if (first_pass): \n",
    "        for i in range(len(bins)-1):\n",
    "            hist_col_title = \"maf_hist_\"+str(bins[i])+\"-\"+str(bins[i+1])\n",
    "            table_columns.append(hist_col_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExAC_population_features(features_dict, state_id, table_columns, first_pass, ac_sum, ac_sum_syn, ac_sum_nonsyn,\n",
    "                             an_list, pop_maf_list, pop_maf_syn_list, pop_maf_nonsyn_list):\n",
    "    \n",
    "#     #Feature: populations ac sum\n",
    "#     for i in range(len(ac_str)):\n",
    "#         features_dict[state_id].append(ac_sum[i])\n",
    "#         if (first_pass): table_columns.append(\"ac_\"+ac_str[i][3:])\n",
    "\n",
    "#     #Feature: populations ac syn sum\n",
    "#     for i in range(len(ac_str)):\n",
    "#         features_dict[state_id].append(ac_sum_syn[i])\n",
    "#         if (first_pass): table_columns.append(\"ac_syn_\"+ac_str[i][3:])\n",
    "\n",
    "#     #Feature: populations ac nonsyn sum\n",
    "#     for i in range(len(ac_str)):\n",
    "#         features_dict[state_id].append(ac_sum_nonsyn[i])\n",
    "#         if (first_pass): table_columns.append(\"ac_nonsyn_\"+ac_str[i][3:])\n",
    "\n",
    "    #Feature: populations an avg        \n",
    "#     for i in range(len(an_str)):\n",
    "#         if (len(an_list[i]) == 0):\n",
    "#             an_avg = 0\n",
    "#         else:\n",
    "#             an_avg = np.average(an_list[i])\n",
    "#         features_dict[state_id].append(an_avg)\n",
    "#         if (first_pass): table_columns.append(\"an_\"+an_str[i][3:])\n",
    "\n",
    "    #Feature: populations total maf avg\n",
    "    for i in range(len(an_str)):\n",
    "        if (len(pop_maf_list[i]) == 0):\n",
    "            avg_pop_maf = 0\n",
    "        else:\n",
    "            avg_pop_maf = np.average(pop_maf_list[i])\n",
    "        features_dict[state_id].append(avg_pop_maf)\n",
    "        if (first_pass): table_columns.append(\"maf_\"+an_str[i][3:])\n",
    "\n",
    "    #Feature: populations syn maf avg\n",
    "    for i in range(len(an_str)):\n",
    "        if (len(pop_maf_syn_list[i]) == 0):\n",
    "            avg_pop_maf_syn = 0\n",
    "        else:\n",
    "            avg_pop_maf_syn = np.average(pop_maf_syn_list[i])\n",
    "        features_dict[state_id].append(avg_pop_maf_syn)\n",
    "        if (first_pass): table_columns.append(\"maf_syn_\"+an_str[i][3:])\n",
    "\n",
    "    #Feature: populations non-syn maf avg\n",
    "    for i in range(len(an_str)):\n",
    "        if (len(pop_maf_nonsyn_list[i]) == 0):\n",
    "            avg_pop_maf_nonsyn = 0\n",
    "        else:\n",
    "            avg_pop_maf_nonsyn = np.average(pop_maf_nonsyn_list[i])\n",
    "        features_dict[state_id].append(avg_pop_maf_nonsyn)\n",
    "        if (first_pass): table_columns.append(\"maf_nonsyn_\"+an_str[i][3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExAC_count_features(features_dict, state_id, table_columns, first_pass, sites_aa_num, sites_aa_alter_num, sites_snp_num, sites_snp_alter_num):\n",
    "    \n",
    "    #Feature: number of alterations - aa level (raw and normalized by total number of matched positions)\n",
    "    if (sites_aa_num == 0):\n",
    "        norm_aa_alter_num = 0\n",
    "    else:\n",
    "        norm_aa_alter_num = sites_aa_alter_num/float(sites_aa_num)\n",
    "    features_dict[state_id].append(sites_aa_alter_num)\n",
    "    if (first_pass): table_columns.append(\"alter_num_aa\")\n",
    "    features_dict[state_id].append(norm_aa_alter_num)\n",
    "    if (first_pass): table_columns.append(\"alter_num_aa_norm\")\n",
    "\n",
    "    #Feature: number of alterations - DNA level (raw and normalized by total number of matched positions)\n",
    "    if (sites_snp_num == 0):\n",
    "        norm_snp_alter_num = 0\n",
    "    else:\n",
    "        norm_snp_alter_num = sites_snp_alter_num/float(sites_snp_num)\n",
    "    features_dict[state_id].append(sites_snp_alter_num)\n",
    "    if (first_pass): table_columns.append(\"alter_num_snp\")\n",
    "    features_dict[state_id].append(norm_snp_alter_num)\n",
    "    if (first_pass): table_columns.append(\"alter_num_snp_norm\")\n",
    "\n",
    "    #Feature: average number of poymorphisms at one site\n",
    "    if (sites_aa_alter_num == 0):\n",
    "        avg_poly_aa = 0\n",
    "    else:\n",
    "        avg_poly_aa = sites_poly_aa_num/float(sites_aa_alter_num)\n",
    "    features_dict[state_id].append(avg_poly_aa)\n",
    "    if (first_pass): table_columns.append(\"avg_aa_polymorphisms\")\n",
    "\n",
    "    #Feature: fraction of altered sites with more than 1 polymorphism\n",
    "    if (sites_aa_alter_num == 0):\n",
    "        frac_poly_several = 1\n",
    "    else:\n",
    "        frac_poly_several = sites_poly_aa_several/float(sites_aa_alter_num)\n",
    "    features_dict[state_id].append(frac_poly_several)\n",
    "    if (first_pass): table_columns.append(\"frac_poly_aa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExAC_rareSNP_features(features_dict, state_id, table_columns, first_pass, sites_snp_alter_num, rare_5_num, rare_05_num, rare_005_num):\n",
    "    \n",
    "    #Feature: fraction of rare SNPs (0.5%, 0.05%, 0.005%)\n",
    "    if (sites_snp_alter_num == 0):\n",
    "        frac_rare_5 = 0\n",
    "        frac_rare_05 = 0\n",
    "        frac_rare_005 = 0\n",
    "    else:\n",
    "        frac_rare_5 = rare_5_num/float(sites_snp_alter_num)\n",
    "        frac_rare_05 = rare_05_num/float(sites_snp_alter_num)\n",
    "        frac_rare_005 = rare_005_num/float(sites_snp_alter_num)\n",
    "        \n",
    "    features_dict[state_id].append(frac_rare_5)\n",
    "    if (first_pass): table_columns.append(\"rare_poly_0.5\")\n",
    "    features_dict[state_id].append(frac_rare_05)\n",
    "    if (first_pass): table_columns.append(\"rare_poly_0.05\")\n",
    "    features_dict[state_id].append(frac_rare_005)\n",
    "    if (first_pass): table_columns.append(\"rare_poly_0.005\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conservation function (phastCons, PhyloP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conservation_features(features_dict, state_id, table_columns, first_pass, phastCons_dict, phyloP_dict):\n",
    "    \n",
    "    #Features: conservation scores avg for each codon position - phastCons\n",
    "    features_dict[state_id].append(np.nanmean(phastCons_dict[1]))\n",
    "    if (first_pass): table_columns.append(\"phastCons1_avg\")\n",
    "    features_dict[state_id].append(np.nanmean(phastCons_dict[2]))\n",
    "    if (first_pass): table_columns.append(\"phastCons2_avg\")\n",
    "    features_dict[state_id].append(np.nanmean(phastCons_dict[3]))\n",
    "    if (first_pass): table_columns.append(\"phastCons3_avg\")\n",
    "    \n",
    "    #Features: conservation scores avg for each codon position - phyloP\n",
    "    features_dict[state_id].append(np.nanmean(phyloP_dict[1]))\n",
    "    if (first_pass): table_columns.append(\"phyloP1_avg\")\n",
    "    features_dict[state_id].append(np.nanmean(phyloP_dict[2]))\n",
    "    if (first_pass): table_columns.append(\"phyloP2_avg\")\n",
    "    features_dict[state_id].append(np.nanmean(phyloP_dict[3]))\n",
    "    if (first_pass): table_columns.append(\"phyloP3_avg\")\n",
    "        \n",
    "    #Features: conservation scores histograms for each codon position - phastCons\n",
    "    phastCons_bins = np.concatenate((np.linspace(0,0.75, 4), np.linspace(0.8,1.0, 5)), axis=0)\n",
    "    phastCons1_hist = np.histogram(np.array(phastCons_dict[1])[~np.isnan(phastCons_dict[1])], phastCons_bins)[0]\n",
    "    phastCons2_hist = np.histogram(np.array(phastCons_dict[2])[~np.isnan(phastCons_dict[2])], phastCons_bins)[0]\n",
    "    phastCons3_hist = np.histogram(np.array(phastCons_dict[3])[~np.isnan(phastCons_dict[3])], phastCons_bins)[0]\n",
    "    \n",
    "    features_dict[state_id].extend(phastCons1_hist)\n",
    "    features_dict[state_id].extend(phastCons2_hist)\n",
    "    features_dict[state_id].extend(phastCons3_hist)\n",
    "    if (first_pass): \n",
    "        for i in range(len(phastCons_bins)-1):\n",
    "            hist_col_title = \"phastCons1_hist_\"+str(phastCons_bins[i])+\"-\"+str(phastCons_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "        for i in range(len(phastCons_bins)-1):\n",
    "            hist_col_title = \"phastCons2_hist_\"+str(phastCons_bins[i])+\"-\"+str(phastCons_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "        for i in range(len(phastCons_bins)-1):\n",
    "            hist_col_title = \"phastCons3_hist_\"+str(phastCons_bins[i])+\"-\"+str(phastCons_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "    \n",
    "    #Features: conservation scores histograms for each codon position - phyloP\n",
    "    phyloP_bins = np.concatenate((np.array([-14, -1]), np.linspace(0, 3, 4), np.linspace(3.5, 6, 6)), axis=0)\n",
    "    phyloP_hist1 = np.histogram(np.array(phyloP_dict[1])[~np.isnan(phyloP_dict[1])], phyloP_bins)[0]\n",
    "    phyloP_hist2 = np.histogram(np.array(phyloP_dict[2])[~np.isnan(phyloP_dict[2])], phyloP_bins)[0]\n",
    "    phyloP_hist3 = np.histogram(np.array(phyloP_dict[3])[~np.isnan(phyloP_dict[3])], phyloP_bins)[0]\n",
    "    \n",
    "    features_dict[state_id].extend(phyloP_hist1)\n",
    "    features_dict[state_id].extend(phyloP_hist2)\n",
    "    features_dict[state_id].extend(phyloP_hist3)\n",
    "    if (first_pass): \n",
    "        for i in range(len(phyloP_bins)-1):\n",
    "            hist_col_title = \"phyloP1_hist_\"+str(phyloP_bins[i])+\"-\"+str(phyloP_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "        for i in range(len(phyloP_bins)-1):\n",
    "            hist_col_title = \"phyloP2_hist_\"+str(phyloP_bins[i])+\"-\"+str(phyloP_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "        for i in range(len(phyloP_bins)-1):\n",
    "            hist_col_title = \"phyloP3_hist_\"+str(phyloP_bins[i])+\"-\"+str(phyloP_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "            \n",
    "    #Features: histogram of avg in each codon\n",
    "    phastCons_codons_avg = []\n",
    "    phyloP_codons_avg = []\n",
    "    for i in range(len(phastCons_dict[1])):\n",
    "        phastCons_score_avg = np.nanmean([phastCons_dict[1][i], phastCons_dict[2][i], phastCons_dict[3][i]])\n",
    "        phastCons_codons_avg.append(phastCons_score_avg)\n",
    "        phyloP_score_avg = np.nanmean([phyloP_dict[1][i], phyloP_dict[2][i], phyloP_dict[3][i]])\n",
    "        phyloP_codons_avg.append(phyloP_score_avg)\n",
    "        \n",
    "    phastCons_codons_hist = np.histogram(phastCons_codons_avg, phastCons_bins)[0]\n",
    "    phyloP_codons_hist = np.histogram(phyloP_codons_avg, phyloP_bins)[0]\n",
    "    \n",
    "    features_dict[state_id].extend(phastCons_codons_hist)\n",
    "    features_dict[state_id].extend(phyloP_codons_hist)\n",
    "    if (first_pass): \n",
    "        for i in range(len(phastCons_bins)-1):\n",
    "            hist_col_title = \"phastCons_codons_hist_\"+str(phastCons_bins[i])+\"-\"+str(phastCons_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "        for i in range(len(phyloP_bins)-1):\n",
    "            hist_col_title = \"phyloP_codons_hist_\"+str(phyloP_bins[i])+\"-\"+str(phyloP_bins[i+1])\n",
    "            table_columns.append(hist_col_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLOSUM/PAM functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_matrix_features(features_dict, state_id, table_columns, first_pass, sub_list, weigted_sub_list, sub_name):\n",
    "    \n",
    "    if (len(sub_list) == 0):\n",
    "        sub_avg = 0\n",
    "        weigted_sub_avg = 0\n",
    "        sub_postivies = 0\n",
    "        sub_negatives = 0\n",
    "        sub_ratio = 1\n",
    "    else:\n",
    "        #Feature: BLOSUM62 average and frequency weighted-average\n",
    "        sub_avg = sum(sub_list)/float(len(sub_list))\n",
    "        weigted_sub_avg = sum(weigted_sub_list)/float(len(weigted_sub_list))\n",
    "\n",
    "        #Feature: BLOSUM62 count of positives and negatives\n",
    "        sub_postivies = sum(1 for x in sub_list if x > 0)\n",
    "        sub_negatives = sum(1 for x in sub_list if x < 0)\n",
    "\n",
    "        #Feature: BLOSUM62 positives/negatives ratio\n",
    "        if (sub_postivies == 0 or sub_negatives == 0):\n",
    "            sub_ratio = 0\n",
    "        else:\n",
    "            sub_ratio = sub_postivies/float(sub_negatives)\n",
    "\n",
    "    features_dict[state_id].append(sub_avg)\n",
    "    if (first_pass): table_columns.append(sub_name+\"_avg\")\n",
    "    features_dict[state_id].append(weigted_sub_avg)\n",
    "    if (first_pass): table_columns.append(sub_name+\"_avg_weighted\")\n",
    "    features_dict[state_id].append(sub_postivies)\n",
    "    if (first_pass): table_columns.append(sub_name+\"_positive_num\")\n",
    "    features_dict[state_id].append(sub_negatives)\n",
    "    if (first_pass): table_columns.append(sub_name+\"_negative_num\")\n",
    "    features_dict[state_id].append(sub_ratio)\n",
    "    if (first_pass): table_columns.append(sub_name+\"_ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SIFT, PolyPhen, ClinVar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT_features(features_dict, state_id, table_columns, first_pass, sift_scores_list, weighted_sift_scores_list):\n",
    "    \n",
    "    if (len(sift_scores_list) > 0):\n",
    "        #Feature: SIFT average\n",
    "        sift_avg = np.mean(sift_scores_list)\n",
    "        \n",
    "        #Feature: weighted (by frequency) SIFT average\n",
    "        sift_w_avg = np.mean(weighted_sift_scores_list)\n",
    "\n",
    "        #Feature: SIFT number of deleterious (score <=0.05)\n",
    "        sift_deleterious_num = sum(1 for x in sift_scores_list if x <= SIFT_THRESHOLD)\n",
    "\n",
    "        #Feature: SIFT number of tolerated (score > 0.05)\n",
    "        sift_tolerated_num = sum(1 for x in sift_scores_list if x > SIFT_THRESHOLD)\n",
    "\n",
    "        #Feature: deleterious/tolerated ratio\n",
    "        if (sift_tolerated_num == 0 or sift_deleterious_num == 0):\n",
    "            sift_ratio = 0\n",
    "        else:\n",
    "            sift_ratio = sift_deleterious_num/float(sift_tolerated_num)\n",
    "\n",
    "        #Feature: SIFT \"majority-decision\" (deleterious/tolerated)\n",
    "        if (sift_deleterious_num > sift_tolerated_num):\n",
    "            sift_majority = sift_codes.SIFT_DELETERIOUS.value\n",
    "        elif (sift_tolerated_num > sift_deleterious_num):\n",
    "            sift_majority = sift_codes.SIFT_TOLERATED.value\n",
    "        else:\n",
    "            sift_majority = sift_codes.SIFT_TIE.value\n",
    "\n",
    "    else:\n",
    "        sift_avg = sift_w_avg = -1\n",
    "        sift_deleterious_num = 0\n",
    "        sift_tolerated_num = 0\n",
    "        sift_ratio = 1\n",
    "        sift_majority = sift_codes.SIFT_TIE.value\n",
    "\n",
    "    features_dict[state_id].append(sift_avg)\n",
    "    if (first_pass): table_columns.append(\"sift_avg\")\n",
    "    features_dict[state_id].append(sift_w_avg)\n",
    "    if (first_pass): table_columns.append(\"sift_avg_weighted\")\n",
    "    features_dict[state_id].append(sift_deleterious_num)\n",
    "    if (first_pass): table_columns.append(\"sift_deleterious_num\")\n",
    "    features_dict[state_id].append(sift_tolerated_num)\n",
    "    if (first_pass): table_columns.append(\"sift_tolerated_num\")\n",
    "    features_dict[state_id].append(sift_ratio)\n",
    "    if (first_pass): table_columns.append(\"sift_ratio\")\n",
    "    features_dict[state_id].append(sift_majority)\n",
    "    if (first_pass): table_columns.append(\"sift_majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PolyPhen_features(features_dict, state_id, table_columns, first_pass, polyphen_scores_list, polyphen_pred_list, weighted_polyphen_scores_list):\n",
    "    \n",
    "    if (len(polyphen_scores_list) > 0):\n",
    "        #Feature: PolyPhen average\n",
    "        polyphen_avg = np.mean(polyphen_scores_list)\n",
    "        \n",
    "        #Feature: weighted (by frequency) PolyPhen average\n",
    "        polyphen_w_avg = np.mean(weighted_polyphen_scores_list)\n",
    "\n",
    "        #Feature: polyPhen number of benign\n",
    "        polyphen_benign_num = polyphen_pred_list.count(\"benign\")\n",
    "\n",
    "        #Feature: polyPhen number of possibly_damaging\n",
    "        polyphen_possibly_num = polyphen_pred_list.count(\"possibly_damaging\")\n",
    "\n",
    "        #Feature: polyPhen number of probably_damaging\n",
    "        polyphen_probably_num = polyphen_pred_list.count(\"probably_damaging\")\n",
    "\n",
    "        #Feature: polyPhen \"majority-decision\" (benign/possibly_damaging/probably_damaging/unknown)\n",
    "        if ((polyphen_benign_num > polyphen_probably_num and polyphen_benign_num > polyphen_possibly_num) or \n",
    "            (polyphen_benign_num > polyphen_probably_num and polyphen_benign_num == polyphen_possibly_num)):\n",
    "            polyphen_majority = polyphen_codes.POLYPHEN_BENIGN.value\n",
    "\n",
    "        elif ((polyphen_probably_num > polyphen_benign_num and polyphen_probably_num > polyphen_possibly_num) or \n",
    "              (polyphen_probably_num > polyphen_benign_num and polyphen_probably_num == polyphen_possibly_num)):\n",
    "            polyphen_majority = polyphen_codes.POLYPHEN_PROBABLY.value\n",
    "\n",
    "        elif (polyphen_possibly_num > polyphen_benign_num and polyphen_possibly_num > polyphen_probably_num):\n",
    "            polyphen_majority = polyphen_codes.POLYPHEN_POSSIBLY.value\n",
    "\n",
    "        elif (polyphen_benign_num == polyphen_probably_num == polyphen_possibly_num):\n",
    "            polyphen_majority = polyphen_codes.PLOYPHEN_EQUAL.value\n",
    "\n",
    "        else:\n",
    "            polyphen_majority = polyphen_codes.POLYPHEN_UNKNOWN.value\n",
    "\n",
    "    else:\n",
    "        polyphen_avg = polyphen_w_avg = -1\n",
    "        polyphen_benign_num = 0\n",
    "        polyphen_possibly_num = 0\n",
    "        polyphen_probably_num = 0\n",
    "        polyphen_majority = polyphen_codes.POLYPHEN_UNKNOWN.value\n",
    "\n",
    "    features_dict[state_id].append(polyphen_avg)\n",
    "    if (first_pass): table_columns.append(\"polyphen_avg\")\n",
    "    features_dict[state_id].append(polyphen_w_avg)\n",
    "    if (first_pass): table_columns.append(\"polyphen_avg_weighted\")\n",
    "    features_dict[state_id].append(polyphen_benign_num)\n",
    "    if (first_pass): table_columns.append(\"polyphen_benign_num\")\n",
    "    features_dict[state_id].append(polyphen_possibly_num)\n",
    "    if (first_pass): table_columns.append(\"polyphen_possibly_num\")\n",
    "    features_dict[state_id].append(polyphen_probably_num)\n",
    "    if (first_pass): table_columns.append(\"polyphen_probably_num\")\n",
    "    features_dict[state_id].append(polyphen_majority)\n",
    "    if (first_pass): table_columns.append(\"polyphen_majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClinVar_scores(features_dict, state_id, table_columns, first_pass, clinsig_list, clinsig_af):\n",
    "    \n",
    "    valid_scores = []\n",
    "    valid_scores_weighted = []\n",
    "    \n",
    "    for i in range(len(clinsig_list)):\n",
    "        sig = clinsig_list[i]\n",
    "        sig_list = pd.Series(sig.split(\"&\")).unique().tolist()\n",
    "        #Skipping \n",
    "        if (\"not\" in sig_list or \"\" in sig_list):\n",
    "                continue\n",
    "        \n",
    "        #Determine the alteration clinvar score\n",
    "        if (len(sig_list) == 1 and sig_list[0] == \"pathogenic\"):\n",
    "            score = clinvar_codes.CLINVAR_PATHOGENIC.value\n",
    "        elif (len(sig_list) == 1 and sig_list[0] == \"benign\"):\n",
    "            score = clinvar_codes.CLINVAR_BENIGN.value\n",
    "        elif (len(sig_list) == 2 and \"benign\" in sig_list and \"likely\" in sig_list):\n",
    "            score = clinvar_codes.CLINVAR_LIKELY_BENIGN.value\n",
    "        elif (len(sig_list) == 2 and \"pathogenic\" in sig_list and \"uncertain\" in sig_list):\n",
    "            score = clinvar_codes.CLINVAR_LIKELY_PATHOGENIC.value\n",
    "        elif (len(sig_list) == 2 and \"pathogenic\" in sig_list and \"other\" in sig_list):\n",
    "            score = clinvar_codes.CLINVAR_PATHOGENIC_OTHER.value\n",
    "        else:\n",
    "            score = clinvar_codes.CLINVAR_UNCERTAIN.value #value of 0\n",
    "            \n",
    "        valid_scores.append(score)\n",
    "        score_af = clinsig_af[i]\n",
    "        valid_scores_weighted.append(score*score_af)\n",
    "        \n",
    "    #===Feature: Avg. and weighted avg. ClinVar score===#\n",
    "    if (len(valid_scores) == 0):\n",
    "        avg_clinvar_score = 0\n",
    "        avg_w_clinvar_score = 0\n",
    "    else:\n",
    "        avg_clinvar_score = np.mean(valid_scores)\n",
    "        avg_w_clinvar_score = np.mean(valid_scores_weighted)\n",
    "        \n",
    "    features_dict[state_id].append(avg_clinvar_score)\n",
    "    if (first_pass): table_columns.append(\"avg_clinvar_score\")\n",
    "    features_dict[state_id].append(avg_w_clinvar_score)\n",
    "    if (first_pass): table_columns.append(\"avg_clinvar_weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExAC SNPs entropy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a normalized Shannon entropy (from Miller et al, 2015)\n",
    "def entropy(a):\n",
    "    \n",
    "    if (len(a) == 1):\n",
    "        return 0 #Min entropy - all the change is in one value\n",
    "    \n",
    "    a = np.asarray(a) / float(sum(a))\n",
    "    entropy = 0\n",
    "    \n",
    "    for val in a:\n",
    "        if (val == 0 or np.isnan(val)):\n",
    "            continue\n",
    "        if (val < 0):\n",
    "            print a\n",
    "        entropy += val * math.log(val)\n",
    "    \n",
    "    entropy_adj = -entropy / math.log(len(a)) #To account for different size input\n",
    "        \n",
    "    return entropy_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_features(features_dict, state_id, table_columns, first_pass, maf_list):\n",
    "    \n",
    "    #Feature: entropy of nonsyn SNPs distributed across instances\n",
    "    if (np.sum(maf_list) == 0):\n",
    "        instances_entropy = math.log(len(maf_list)) #if no SNPs- each instance has the prob. = max. entropy ln(n)\n",
    "    else:\n",
    "        instances_entropy = entropy(maf_list)\n",
    "        if (len(maf_list) == 0):\n",
    "            print \"maf_list empty\"\n",
    "        if (np.isnan(instances_entropy)):\n",
    "            print \"entropy nan\"\n",
    "            print maf_list\n",
    "        \n",
    "    features_dict[state_id].append(instances_entropy)\n",
    "    if (first_pass): table_columns.append(\"snp_nonsyn_entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modified dN/dS functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudo_dNdS_features(features_dict, state_id, table_columns, first_pass, ref_seq, Nd, Sd):\n",
    "    \n",
    "    (N,S) = seq_ns(ref_seq) #Reference expected syn/nonsyn per site\n",
    "    if (N == 0): \n",
    "        PN = 0\n",
    "    else:\n",
    "        PN = Nd/float(N) #Proportion of nonsyn\n",
    "    if (S == 0):\n",
    "        PS = 0\n",
    "    else:\n",
    "        PS = Sd/float(S) #Proportion of syn\n",
    "\n",
    "    #num of nonsyn substitutions per nonsyn site\n",
    "    dN = -0.75 * (np.log(1-4*PN/float(3)))\n",
    "    features_dict[state_id].append(dN)\n",
    "    if (first_pass): table_columns.append(\"pseudo_nonsyn\")\n",
    "\n",
    "    #num of syn substitutions per syn site\n",
    "    if (4*PS/float(3) >= 1):\n",
    "        dS = 1\n",
    "    else:\n",
    "        dS = -0.75 * (np.log(1-4*PS/float(3)))\n",
    "    features_dict[state_id].append(dS)\n",
    "    if (first_pass): table_columns.append(\"pseudo_syn\")\n",
    "\n",
    "    if (dN ==0 or dS == 0):\n",
    "        dN_dS = 1 #There isn't enough information to calculate dN/dS (1 is a neutral value)\n",
    "    else:\n",
    "        dN_dS = dN/dS\n",
    "        if (dN_dS == np.nan):\n",
    "            print \"dN = \"+str(dN)\n",
    "            print \"dS = \"+str(dS)\n",
    "            dN_dS = 1 #There isn't enough information to calculate dN/dS (1 is a neutral value)\n",
    "        \n",
    "    features_dict[state_id].append(dN_dS)\n",
    "    if (first_pass): table_columns.append(\"pseudo_dNdS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pfam emission prob. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfam_emission_prob_features(features_dict, state_id, table_columns, first_pass, domain_name, state):\n",
    "    \n",
    "    #Feature: Max. emission probability\n",
    "    state_max_emiss_prob = max(hmm_prob_dict[domain_name][state])\n",
    "    features_dict[state_id].append(state_max_emiss_prob)\n",
    "    if (first_pass): table_columns.append(\"pfam_prob_max\"); orto_para_cols.append(\"pfam_prob_max\")\n",
    "\n",
    "    #Features: emission prob. for each amino acid\n",
    "    for i in range(len(hmm_prob_dict[domain_name][state])):\n",
    "        features_dict[state_id].append(hmm_prob_dict[domain_name][state][i])\n",
    "        if (first_pass):\n",
    "            prob_aa_title = \"pfam_prob_\"+str(pfam_aa_order[i])\n",
    "            table_columns.append(prob_aa_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pfam_conserved_state_feature(features_dict, state_id, table_columns, first_pass, state, con_states_dict):\n",
    "    \n",
    "    #Feature: is state is conserved according to Pfam?\n",
    "    con_state = False\n",
    "    if (state in con_states_dict.keys()):\n",
    "        con_state = True\n",
    "        \n",
    "    features_dict[state_id].append(con_state)\n",
    "    if (first_pass): table_columns.append(\"is_pfam_conserved\");  orto_para_cols.append(\"is_pfam_conserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ortho-para notion functions (convervation of orthologues vs. paralogoues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instance_individuals_100way_change_features(features_dict, state_id, table_columns, first_pass, maf_list, aa_ref_hist, jsd100way_list):\n",
    "    #Computing Orthologus conservation in different ways (from 100way-ucsc alignment)\n",
    "    #Computing Paralogus conservartion in different ways (from different instances)\n",
    "    #Combining both to measurments that maximize ortho. con. and minimize para. con.\n",
    "    \n",
    "    ##Paralogus##\n",
    "    #===Feature: fraction of change across instances===#\n",
    "    \n",
    "    #determine majority aa (index of one of the majority)\n",
    "    minor_counts = 0\n",
    "    max_pos = aa_ref_hist.index(max(aa_ref_hist))\n",
    "    for i in range(len(aa_ref_hist)):\n",
    "        if (i == max_pos):\n",
    "            continue\n",
    "        minor_counts += aa_ref_hist[i]\n",
    "    \n",
    "    instances_change_frac = minor_counts/float(np.sum(aa_ref_hist))\n",
    "    features_dict[state_id].append(instances_change_frac)\n",
    "    if (first_pass): table_columns.append(\"instances_change_frac\"); orto_para_cols.append(\"instances_change_frac\")\n",
    "        \n",
    "    #===Feature: number of different amino acids that appear more than once===#\n",
    "#     aa_num = 0\n",
    "#     for cnt in aa_ref_hist:\n",
    "#         if (cnt > 1):\n",
    "#             aa_num += 1\n",
    "#     features_dict[state_id].append(aa_num)\n",
    "#     if (first_pass): table_columns.append(\"aa_ref_overlap\"); orto_para_cols.append(\"aa_ref_overlap\")\n",
    "    \n",
    "    #===Feature: entropy of ref AA===#\n",
    "    aa_ref_entropy = SE_hist(aa_ref_hist)\n",
    "    features_dict[state_id].append(aa_ref_entropy)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_SE\"); orto_para_cols.append(\"aa_ref_SE\")\n",
    "        \n",
    "    #===Feature: JSD of ref AA===#\n",
    "    aa_ref_jsd = JSD_hist(aa_ref_hist, background=JSD_background.BLOSUM62)\n",
    "    features_dict[state_id].append(aa_ref_jsd)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_jsd\"); orto_para_cols.append(\"aa_ref_jsd\")\n",
    "    \n",
    "    \n",
    "    ##Orthologus##\n",
    "    \n",
    "    #first remove -1 illegal scores of JSD mismatch (positions where JSD alignment didn't match, I added -1):\n",
    "    jsd100way_list_no_mismatch = [i for i in jsd100way_list if i != -1]\n",
    "    \n",
    "    #===Feature: median JSD score across 100way vertbrates===#\n",
    "    if (len(jsd100way_list_no_mismatch) == 0):\n",
    "        med_jsd = 0\n",
    "    else:\n",
    "        med_jsd = np.median(jsd100way_list_no_mismatch)\n",
    "    features_dict[state_id].append(med_jsd)\n",
    "    if (first_pass): table_columns.append(\"med_jsd_100way_blosum\"); orto_para_cols.append(\"med_jsd_100way_blosum\")\n",
    "        \n",
    "    #===Feature: Histogram of JSD score across 100way vertebrates===#\n",
    "    jsd_median_bins = [0,0.5,0.6,0.7,0.8,1]\n",
    "    jsd_median_hist = np.histogram(jsd100way_list_no_mismatch, bins=jsd_median_bins)[0]\n",
    "    \n",
    "    features_dict[state_id].extend(jsd_median_hist)\n",
    "    if (first_pass): \n",
    "        for i in range(len(jsd_median_bins)-1):\n",
    "            hist_col_title = \"jsd_median_hist_\"+str(jsd_median_bins[i])+\"-\"+str(jsd_median_bins[i+1])\n",
    "            table_columns.append(hist_col_title)\n",
    "    \n",
    "    ##Functional measurments of both##\n",
    "    #===Feature: ratio: change across instances / change across individuals(MAF)===#\n",
    "    #idea: low MAF (orthologues), high instances change (paralogous) = SDPs\n",
    "    if (np.sum(maf_list) == 0):\n",
    "        avg_maf_overall = 0.0000001 #set the minimal non-zero in our data\n",
    "    else:\n",
    "        avg_maf_overall = np.sum(maf_list)/float(len(maf_list))\n",
    "    \n",
    "    instances_individuals_ratio = instances_change_frac/float(avg_maf_overall)\n",
    "    features_dict[state_id].append(instances_individuals_ratio)\n",
    "    if (first_pass): table_columns.append(\"instances_individuals_change_ratio\"); orto_para_cols.append(\"instances_individuals_change_ratio\")\n",
    "    \n",
    "#     #===Feature: aa num / change across individuals(MAF)\n",
    "#     #idea: low aa num (orthologues), high instances change (paralogous) = SDPs\n",
    "#     aa_num_maf_individuals_ratio = aa_num/float(avg_maf_overall)\n",
    "#     features_dict[state_id].append(aa_num_maf_individuals_ratio)\n",
    "#     if (first_pass): table_columns.append(\"aa_ref_overlap_individuals_change_ratio\"); orto_para_cols.append(\"aa_ref_overlap_individuals_change_ratio\")\n",
    "        \n",
    "    #===Feature: ratio: med JSD across 100way vertebrates / instances major allele freq.===#\n",
    "    #idea: high JSD (orthologues), high instances change (paralogous) = SDPs\n",
    "    instances_major_frac = 1-instances_change_frac #We want high MAF -> small 1-MAF\n",
    "    jsd_instances_major_ratio = med_jsd/float(instances_major_frac) #We want high JSD\n",
    "    features_dict[state_id].append(jsd_instances_major_ratio)\n",
    "    if (first_pass): table_columns.append(\"jsd_100way_instances_major_ratio\"); orto_para_cols.append(\"jsd_100way_instances_major_ratio\")\n",
    "        \n",
    "#     #===Feature: ratio: med JSD / aa ref count===#\n",
    "#     #idea: high JSD (orthologues), high usage of aa (low not used aa) (paralogous) = SDPs\n",
    "#     not_used_aa_cnt = len(amino_acids_sym)-aa_num\n",
    "#     jsd_aa_cnt_ratio = med_jsd/float(not_used_aa_cnt) #We want high aa_num -> small not used aa\n",
    "#     features_dict[state_id].append(jsd_aa_cnt_ratio)\n",
    "#     if (first_pass): table_columns.append(\"jsd_100way_aa_not_used_ratio\"); orto_para_cols.append(\"jsd_100way_aa_not_used_ratio\")\n",
    "        \n",
    "    #===Feature: multiplication: med JSD * shannon entropy of ref aa===#\n",
    "    #idea: high JSD (orthologues), high shannon entropy (paralogous) = SDPs\n",
    "    jsd_mul_se = (med_jsd * aa_ref_entropy)\n",
    "    features_dict[state_id].append(jsd_mul_se)\n",
    "    if (first_pass): table_columns.append(\"jsd_mul_aa_ref_SE\"); orto_para_cols.append(\"jsd_mul_aa_ref_SE\")\n",
    "        \n",
    "    #===Feature: ratio: med JSD / (max. entropy - shannon entropy of ref aa)===#\n",
    "    #idea: high JSD (orthologues), low diff. of max SE to shannon entropy (paralogous) = SDPs\n",
    "    max_entropy = SE_hist([0]*len(amino_acids_sym))\n",
    "    entropy_diff= max_entropy - aa_ref_entropy\n",
    "    jsd_SE_diff_ratio = med_jsd/float(entropy_diff)\n",
    "    features_dict[state_id].append(jsd_SE_diff_ratio)\n",
    "    if (first_pass): table_columns.append(\"jsd_SE_diff_ratio\"); orto_para_cols.append(\"jsd_SE_diff_ratio\")\n",
    "    \n",
    "    #===Feature: sum: med JSD + normalized shannon entropy of ref aa ===#\n",
    "     #idea: high JSD (orthologues), high shannon entropy (paralogous) = SDPs\n",
    "    norm_SE = aa_ref_entropy/float(max_entropy)\n",
    "    jsd_SE_sum = med_jsd + norm_SE\n",
    "    features_dict[state_id].append(jsd_SE_sum)\n",
    "    if (first_pass): table_columns.append(\"jsd_SE_sum\"); orto_para_cols.append(\"jsd_SE_sum\")\n",
    "    \n",
    "    #===Feature: ratio:shannon entropy of ref aa / (max. JSD - med JSD)===#\n",
    "    #idea: high shannon entropy (paralogous), low diff. of max JSD to avg JSD (orthologues) = SDPs\n",
    "    max_jsd = 1\n",
    "    jsd_diff = (max_jsd - med_jsd)\n",
    "    SE_jsd_diff_ratio = aa_ref_entropy/float(jsd_diff)\n",
    "    features_dict[state_id].append(SE_jsd_diff_ratio)\n",
    "    if (first_pass): table_columns.append(\"SE_jsd_diff_ratio\"); orto_para_cols.append(\"SE_jsd_diff_ratio\")\n",
    "        \n",
    "    #===Feature: ratio: med 100way-JSD / (aa ref JSD)===#\n",
    "    #idea: high JSD (orthologues), low JSD (paralogoues) = SDPs\n",
    "    jsds_ratio = med_jsd /float(aa_ref_jsd)\n",
    "    features_dict[state_id].append(jsds_ratio)\n",
    "    if (first_pass): table_columns.append(\"jsds_ratio\"); orto_para_cols.append(\"jsds_ratio\")\n",
    "    \n",
    "    #===Feature: subtraction: (avg 100way-JSD) - (aa ref JSD)===#\n",
    "    #idea: high difference between orthoulogus (more conserved) and paralogous (less conserved)\n",
    "    jsds_subtraction = med_jsd - aa_ref_jsd\n",
    "    features_dict[state_id].append(jsds_subtraction)\n",
    "    if (first_pass): table_columns.append(\"jsds_subtraction\"); orto_para_cols.append(\"jsds_subtraction\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physio-chemical properties functions (major and sub.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_identity_features(features_dict, state_id, table_columns, first_pass, aa_ref_hist, type_str):\n",
    "    \n",
    "    #===Features: aa identity histogram===#\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        features_dict[state_id].append(aa_ref_hist[i])\n",
    "        if (first_pass): table_columns.append(type_str+\"_hist_\"+str(amino_acids_sym[i]))\n",
    "\n",
    "    #===Features: aa identity prob. vector===#\n",
    "    if (np.sum(aa_ref_hist) == 0):\n",
    "        aa_ref_prob = aa_ref_hist \n",
    "    else:\n",
    "        aa_ref_prob = np.asarray(aa_ref_hist)/float(np.sum(aa_ref_hist))\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        features_dict[state_id].append(aa_ref_prob[i])\n",
    "        if (first_pass): table_columns.append(type_str+\"_prob_\"+str(amino_acids_sym[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_charge(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    #===Feature: major allele aa charge counts===#\n",
    "    charge_positive_count = 0\n",
    "    charge_negative_count = 0\n",
    "    charge_neutral_count = 0\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            charge = aa_charge_dict[amino_acids_sym[i]]\n",
    "            if (charge.value == 0):\n",
    "                charge_neutral_count += aa_count\n",
    "            elif (charge.value == 1):\n",
    "                charge_positive_count += aa_count\n",
    "            else:\n",
    "                charge_negative_count += aa_count\n",
    "    \n",
    "    features_dict[state_id].append(charge_positive_count)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_charge_positive_count\")\n",
    "    features_dict[state_id].append(charge_negative_count)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_charge_negative_count\")\n",
    "    features_dict[state_id].append(charge_neutral_count)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_charge_neutral_count\")\n",
    "        \n",
    "    #===Feature: major allele majority charge===#\n",
    "    charge_majority = aa_charge.NEUTRAL.value\n",
    "    if (charge_positive_count > charge_neutral_count and charge_positive_count > charge_negative_count):\n",
    "        charge_majority = aa_charge.POSITIVE.value\n",
    "    elif (charge_negative_count > charge_neutral_count and charge_negative_count > charge_positive_count):\n",
    "        charge_majority = aa_charge.NEGATIVE.value\n",
    "        \n",
    "    features_dict[state_id].append(charge_majority)\n",
    "    if (first_pass): table_columns.append(\"aa_ref_charge_majority\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_functional_group(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    #===Feature: major allele aa functional group counts===#\n",
    "    func_counters = [0] * (len(aa_functional_group)-1) #Major allele is never a stop codon\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            func_group_num = aa_functional_group_dict[amino_acids_sym[i]].value #getting numeric functional group value\n",
    "            if (func_group_num == aa_functional_group.STOP.value): #Major allele is never a stop codon\n",
    "                continue\n",
    "            func_counters[func_group_num] += aa_count\n",
    "    \n",
    "    features_dict[state_id].extend(func_counters)\n",
    "    if (first_pass): \n",
    "        for group in aa_functional_group:\n",
    "            if (group == aa_functional_group.STOP): #Major allele is never a stop codon\n",
    "                continue\n",
    "            func_str = \"aa_ref_\"+str(group)+\"_count\"\n",
    "            table_columns.append(func_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_diff_functional_group(features_dict, state_id, table_columns, first_pass, ref_alt_pairs):\n",
    "    \n",
    "    #===Features: count and frequency staying in functional group Vs. moving to other group===#\n",
    "    stay_cnt = 0\n",
    "    stay_cnt_freq = 0\n",
    "    move_cnt = 0\n",
    "    move_cnt_freq = 0\n",
    "    \n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_func_group = aa_functional_group_dict[ref].value\n",
    "        alt_func_group = aa_functional_group_dict[alt].value\n",
    "        if (ref_func_group == alt_func_group):\n",
    "            stay_cnt += 1\n",
    "            stay_cnt_freq += af\n",
    "        else:\n",
    "            move_cnt += 1\n",
    "            move_cnt_freq += af\n",
    "            \n",
    "    features_dict[state_id].append(stay_cnt)\n",
    "    if (first_pass): table_columns.append(\"sub_func_group_stay_cnt\")\n",
    "    features_dict[state_id].append(stay_cnt_freq)\n",
    "    if (first_pass): table_columns.append(\"sub_func_group_stay_freq\")\n",
    "    features_dict[state_id].append(move_cnt)\n",
    "    if (first_pass): table_columns.append(\"sub_func_group_move_cnt\")\n",
    "    features_dict[state_id].append(move_cnt_freq)\n",
    "    if (first_pass): table_columns.append(\"sub_func_group_move_freq\")\n",
    "     \n",
    "    #===Features: functional groups transitions counts===#\n",
    "    transitions_vec_size = (len(aa_functional_group) - 1) * len(aa_functional_group) #excluding transitions from STOP codons\n",
    "    transitions_vec = [0] * transitions_vec_size\n",
    "    \n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_func_group = aa_functional_group_dict[ref].value\n",
    "        alt_func_group = aa_functional_group_dict[alt].value\n",
    "        #Calculate counter position on the vector (ref_func_group is never STOP = 5)\n",
    "        trans_vec_i = ref_func_group * (len(aa_functional_group) - 1)\n",
    "        trans_vec_i += alt_func_group\n",
    "        transitions_vec[trans_vec_i] += 1\n",
    "   \n",
    "    features_dict[state_id].extend(transitions_vec)\n",
    "    if (first_pass): \n",
    "        for i in range(len(aa_functional_group)-1): #-1 for excluding transitions from STOP\n",
    "            for j in range(len(aa_functional_group)):\n",
    "                trans_col_title = \"sub_func_group_trans_\"+str(i)+\"-\"+str(j)\n",
    "                table_columns.append(trans_col_title)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_hydrophobicity(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    #===Feature: major allele hydrophicity average, hydrophobic and polar counts===#\n",
    "    h_sum = 0\n",
    "    h_cnt = 0\n",
    "    hydrophobic_cnt = 0\n",
    "    polar_charge_cnt = 0\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            hindex = hindex_Kyte_Doolitle[amino_acids_sym[i]]\n",
    "            h_sum += hindex * aa_count\n",
    "            h_cnt += aa_count\n",
    "            \n",
    "            if (hindex > 0):\n",
    "                hydrophobic_cnt += aa_count\n",
    "            else:\n",
    "                polar_charge_cnt += aa_count\n",
    "    \n",
    "    if (h_cnt == 0):\n",
    "        h_avg = 0\n",
    "    else:\n",
    "        h_avg = h_sum/float(h_cnt)\n",
    "    \n",
    "    features_dict[state_id].append(h_avg)\n",
    "    if (first_pass): table_columns.append(\"hindex_avg\")\n",
    "    features_dict[state_id].append(hydrophobic_cnt)\n",
    "    if (first_pass): table_columns.append(\"hindex_pos_cnt\")\n",
    "    features_dict[state_id].append(polar_charge_cnt)\n",
    "    if (first_pass): table_columns.append(\"hindex_neg_cnt\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_diff_hydrophobicity(features_dict, state_id, table_columns, first_pass, ref_alt_pairs):\n",
    "    \n",
    "    #===Feature: hydrophicity difference average and weighted average===#\n",
    "    hindex_diff_sum = 0\n",
    "    hindex_diff_sum_weighted = 0\n",
    "    hindex_diff_cnt = 0\n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_hindex = hindex_Kyte_Doolitle[ref]\n",
    "        alt_hindex = hindex_Kyte_Doolitle[alt]\n",
    "        hindex_diff = (alt_hindex - ref_hindex)\n",
    "        hindex_diff_sum += hindex_diff\n",
    "        hindex_diff_sum_weighted += hindex_diff*af\n",
    "        hindex_diff_cnt += 1\n",
    "    \n",
    "    if (hindex_diff_cnt == 0):\n",
    "        hindex_diff_avg = hindex_diff_avg_weighted = 0\n",
    "    else:\n",
    "        hindex_diff_avg = hindex_diff_sum/float(hindex_diff_cnt)\n",
    "        hindex_diff_avg_weighted = hindex_diff_sum_weighted/float(hindex_diff_cnt)\n",
    "        \n",
    "    features_dict[state_id].append(hindex_diff_avg)\n",
    "    if (first_pass): table_columns.append(\"sub_diff_hindex_avg\")\n",
    "    features_dict[state_id].append(hindex_diff_avg_weighted)\n",
    "    if (first_pass): table_columns.append(\"sub_diff_hindex_avg_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_volume(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    #===Feature: major allele volume average, tiny, small and big counts===#\n",
    "    vol_sum = 0\n",
    "    vol_cnt = 0\n",
    "    tiny_cnt = 0\n",
    "    small_cnt = 0\n",
    "    big_cnt = 0\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            volume = aa_volume[amino_acids_sym[i]]\n",
    "            vol_sum += volume * aa_count\n",
    "            vol_cnt += aa_count\n",
    "            \n",
    "            vol_group = aa_volume_group_dict[amino_acids_sym[i]]\n",
    "            if (vol_group == aa_volume_group.TINY):\n",
    "                tiny_cnt += aa_count\n",
    "            elif (vol_group == aa_volume_group.SMALL):\n",
    "                small_cnt += aa_count\n",
    "            elif (vol_group == aa_volume_group.BIG):\n",
    "                big_cnt += aa_count\n",
    "    \n",
    "    if (vol_cnt == 0):\n",
    "        vol_avg = 0\n",
    "    else:\n",
    "        vol_avg = (vol_sum/float(vol_cnt))\n",
    "        \n",
    "    features_dict[state_id].append(vol_avg)\n",
    "    if (first_pass): table_columns.append(\"vol_avg\")\n",
    "    features_dict[state_id].append(tiny_cnt)\n",
    "    if (first_pass): table_columns.append(\"vol_tiny_cnt\")\n",
    "    features_dict[state_id].append(small_cnt)\n",
    "    if (first_pass): table_columns.append(\"vol_small_cnt\") \n",
    "    features_dict[state_id].append(big_cnt)\n",
    "    if (first_pass): table_columns.append(\"vol_big_cnt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_diff_volume(features_dict, state_id, table_columns, first_pass, ref_alt_pairs):\n",
    "    \n",
    "    #===Feature: volume difference average and weighted average===#\n",
    "    volume_diff_sum = 0\n",
    "    volume_diff_sum_weighted = 0\n",
    "    volume_diff_cnt = 0\n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_vol = aa_volume[ref]\n",
    "        alt_vol = aa_volume[alt]\n",
    "        vol_diff = (ref_vol - alt_vol)\n",
    "        volume_diff_sum += vol_diff\n",
    "        volume_diff_sum_weighted += vol_diff*af\n",
    "        volume_diff_cnt += 1\n",
    "        \n",
    "    if (volume_diff_cnt == 0):\n",
    "        volume_diff_avg = volume_diff_avg_weighted = 0\n",
    "    else:\n",
    "        volume_diff_avg = volume_diff_sum/float(volume_diff_cnt)\n",
    "        volume_diff_avg_weighted = volume_diff_sum_weighted/float(volume_diff_cnt)\n",
    "        \n",
    "    features_dict[state_id].append(volume_diff_avg)\n",
    "    if (first_pass): table_columns.append(\"sub_diff_vol_avg\")\n",
    "    features_dict[state_id].append(volume_diff_avg_weighted)\n",
    "    if (first_pass): table_columns.append(\"sub_diff_vol_avg_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_propensity(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    prop_sum = [0, 0, 0]\n",
    "    prop_cnt = 0\n",
    "    prop_majority_counts = [0, 0, 0]\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            curr_prop = propensity_chou_fasman[amino_acids_sym[i]]\n",
    "            mul_curr_prop = [x*aa_count for x in curr_prop]\n",
    "            prop_sum = [sum(x) for x in zip(prop_sum, mul_curr_prop)]\n",
    "            prop_cnt += aa_count\n",
    "            \n",
    "            if (curr_prop[aa_propensity.ALPHA_HELIX.value] == max(curr_prop)):\n",
    "                prop_majority_counts[aa_propensity.ALPHA_HELIX.value] += 1\n",
    "            if (curr_prop[aa_propensity.BETA_SHEET.value] == max(curr_prop)):\n",
    "                prop_majority_counts[aa_propensity.BETA_SHEET.value] += 1\n",
    "            if (curr_prop[aa_propensity.TURN.value] == max(curr_prop)):\n",
    "                prop_majority_counts[aa_propensity.TURN.value] += 1\n",
    "            \n",
    "    #===Feature: major allele propensity avgs===#\n",
    "    if (prop_cnt == 0):\n",
    "        prop_avg = [0, 0, 0]\n",
    "    else:\n",
    "        prop_avg = [x/float(prop_cnt) for x in prop_sum]\n",
    "    \n",
    "    features_dict[state_id].extend(prop_avg)\n",
    "    if (first_pass): table_columns.extend([\"aa_ref_alpha_prop_avg\", \"aa_ref_beta_prop_avg\", \"aa_ref_turn_prop_avg\"])\n",
    "        \n",
    "    #===Feature: major allele majority propensity===#\n",
    "    max_idx = np.where(np.array(prop_majority_counts) == max(prop_majority_counts))[0]\n",
    "    majority_vec = [0, 0, 0]\n",
    "    for i in max_idx:\n",
    "        majority_vec[i] = 1 #put 1 in the propensities that has max. count\n",
    "    \n",
    "    features_dict[state_id].extend(majority_vec)\n",
    "    if (first_pass): table_columns.extend([\"aa_ref_alpha_is_majority\", \"aa_ref_beta_is_majority\", \"aa_ref_turn_is_majority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_diff_propensity(features_dict, state_id, table_columns, first_pass, ref_alt_pairs):\n",
    "    \n",
    "    #===Feature: propensity difference average===#\n",
    "    prop_vec_sum = [0,0,0]\n",
    "    prop_vec_sum_weighted = [0,0,0]\n",
    "    prop_cnt = 0\n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_struct = propensity_chou_fasman[ref]\n",
    "        alt_struct = propensity_chou_fasman[alt]\n",
    "        prop_diff = [(x-y) for (x,y) in zip(ref_struct,alt_struct)]\n",
    "        prop_diff_weighted = [(x-y)*af for (x,y) in zip(ref_struct,alt_struct)]\n",
    "        prop_vec_sum = [(x+y) for (x,y) in zip(prop_vec_sum,prop_diff)]\n",
    "        prop_vec_sum_weighted = [(x+y) for (x,y) in zip(prop_vec_sum_weighted,prop_diff_weighted)]\n",
    "\n",
    "        prop_cnt += 1\n",
    "    \n",
    "    if (prop_cnt == 0):\n",
    "        prop_vec_avg = prop_vec_avg_weighted = [0,0,0]\n",
    "    else:\n",
    "        prop_vec_avg = [(x/float(prop_cnt)) for x in prop_vec_sum]\n",
    "        prop_vec_avg_weighted = [(x/float(prop_cnt)) for x in prop_vec_sum_weighted]\n",
    "    \n",
    "    features_dict[state_id].extend(prop_vec_avg)\n",
    "    if (first_pass): \n",
    "        table_columns.append(\"sub_diff_prop_avg_alpha\")\n",
    "        table_columns.append(\"sub_diff_prop_avg_beta\")\n",
    "        table_columns.append(\"sub_diff_prop_avg_turn\")\n",
    "    features_dict[state_id].extend(prop_vec_avg_weighted)\n",
    "    if (first_pass): \n",
    "        table_columns.append(\"sub_diff_prop_avg_alpha_weighed\")\n",
    "        table_columns.append(\"sub_diff_prop_avg_beta_weighed\")\n",
    "        table_columns.append(\"sub_diff_prop_avg_turn_weighed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def major_allele_h_bonds(features_dict, state_id, table_columns, first_pass, aa_ref_hist):\n",
    "    \n",
    "    #===Feature: avg donor and acceptor H-bond potential===#\n",
    "    donor_sum = 0\n",
    "    acceptor_sum = 0\n",
    "    bonds_cnt = 0\n",
    "    for i in range(len(amino_acids_sym)):\n",
    "        aa_count = aa_ref_hist[i]\n",
    "        if (aa_count > 0):\n",
    "            donor_sum += (aa_h_bond_donor[amino_acids_sym[i]] * aa_count)\n",
    "            acceptor_sum += (aa_h_bond_acceptor[amino_acids_sym[i]] * aa_count)\n",
    "            bonds_cnt += aa_count\n",
    "    \n",
    "    if (bonds_cnt == 0):\n",
    "        donor_avg = 0\n",
    "        acceptor_avg = 0\n",
    "    else:\n",
    "        donor_avg = donor_sum/float(bonds_cnt)\n",
    "        acceptor_avg = acceptor_sum/float(bonds_cnt)\n",
    "    \n",
    "    features_dict[state_id].append(donor_avg)\n",
    "    if (first_pass): table_columns.append(\"H_bond_donor_avg\")\n",
    "    features_dict[state_id].append(acceptor_avg)\n",
    "    if (first_pass): table_columns.append(\"H_bond_acceptor_avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_diff_h_bonds(features_dict, state_id, table_columns, first_pass, ref_alt_pairs):\n",
    "    \n",
    "    #===Feature: acceptor and donor diff average and weighted average===#\n",
    "    donor_diff_sum = 0\n",
    "    donor_diff_sum_weighted = 0\n",
    "    acceptor_diff_sum = 0\n",
    "    acceptor_diff_sum_weighted = 0\n",
    "    diff_cnt = 0\n",
    "    for (ref,alt,af) in ref_alt_pairs:\n",
    "        ref_donor = aa_h_bond_donor[ref]\n",
    "        alt_donor = aa_h_bond_donor[alt]\n",
    "        donor_diff = (ref_donor - alt_donor)\n",
    "        donor_diff_sum += donor_diff\n",
    "        donor_diff_sum_weighted += donor_diff*af\n",
    "        \n",
    "        ref_acceptor = aa_h_bond_acceptor[ref]\n",
    "        alt_acceptor = aa_h_bond_acceptor[alt]\n",
    "        acceptor_diff = (ref_acceptor - alt_acceptor)\n",
    "        acceptor_diff_sum += acceptor_diff\n",
    "        acceptor_diff_sum += acceptor_diff*af\n",
    "        \n",
    "        diff_cnt += 1\n",
    "        \n",
    "    if (diff_cnt == 0):\n",
    "        donor_diff_avg = donor_diff_avg_weighted = 0\n",
    "        acceptor_diff_avg = acceptor_diff_avg_weighted = 0\n",
    "    else:\n",
    "        donor_diff_avg = donor_diff_sum/float(diff_cnt)\n",
    "        donor_diff_avg_weighted = donor_diff_sum_weighted/float(diff_cnt)\n",
    "        acceptor_diff_avg = acceptor_diff_sum/float(diff_cnt)\n",
    "        acceptor_diff_avg_weighted = acceptor_diff_sum_weighted/float(diff_cnt)\n",
    "        \n",
    "    features_dict[state_id].append(donor_diff_avg)\n",
    "    if (first_pass): table_columns.append(\"donor_diff_avg\")\n",
    "    features_dict[state_id].append(donor_diff_avg_weighted)\n",
    "    if (first_pass): table_columns.append(\"donor_diff_avg_weighted\")\n",
    "    features_dict[state_id].append(acceptor_diff_avg)\n",
    "    if (first_pass): table_columns.append(\"acceptor_diff_avg\")\n",
    "    features_dict[state_id].append(acceptor_diff_avg_weighted)\n",
    "    if (first_pass): table_columns.append(\"acceptor_diff_avg_weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPIDER predictions (solvent accessibility and secondary structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_solvent_acc_pred(features_dict, state_id, table_columns, first_pass, spider_dict):\n",
    "    \n",
    "    #===Feature: Accessible Surface Area (solvent accessibility) average===#\n",
    "    asa_avg = np.nanmean(spider_dict[\"spider2-ASA\"])\n",
    "    features_dict[state_id].append(asa_avg)\n",
    "    if (first_pass): table_columns.append(\"solvent_acc_avg\")\n",
    "        \n",
    "    #===Feature: Accessible Surface Area (solvent accessibility) std===#\n",
    "    asa_std = np.nanstd(spider_dict[\"spider2-ASA\"])\n",
    "    features_dict[state_id].append(asa_std)\n",
    "    if (first_pass): table_columns.append(\"solvent_acc_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_contact_number_pred(features_dict, state_id, table_columns, first_pass, spider_dict):\n",
    "    \n",
    "    #===Feature: contanct number for C-C average===#\n",
    "    hsa2_cn_avg = np.nanmean(spider_dict[\"spider2-hsa2_CN\"])\n",
    "    features_dict[state_id].append(hsa2_cn_avg)\n",
    "    if (first_pass): table_columns.append(\"hsa2_cn_avg\")\n",
    "        \n",
    "    #===Feature: contanct number for C-C std===#\n",
    "    hsa2_cn_std = np.nanstd(spider_dict[\"spider2-hsa2_CN\"])\n",
    "    features_dict[state_id].append(hsa2_cn_std)\n",
    "    if (first_pass): table_columns.append(\"hsa2_cn_std\")\n",
    "    \n",
    "    #===Feature: contanct number for C-C average===#\n",
    "    hsb2_cn_avg = np.nanmean(spider_dict[\"spider2-hsb2_CN\"])\n",
    "    features_dict[state_id].append(hsb2_cn_avg)\n",
    "    if (first_pass): table_columns.append(\"hsb2_cn_avg\")\n",
    "        \n",
    "    #===Feature: contanct number for C-C std===#\n",
    "    hsb2_cn_std = np.nanstd(spider_dict[\"spider2-hsb2_CN\"])\n",
    "    features_dict[state_id].append(hsb2_cn_std)\n",
    "    if (first_pass): table_columns.append(\"hsb2_cn_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_angles_pred(features_dict, state_id, table_columns, first_pass, spider_dict):\n",
    "    \n",
    "    #===Feature: backbone Phi angle average===#\n",
    "    Phi_angle_avg = np.nanmean(spider_dict[\"spider2-angle_Phi\"])\n",
    "    features_dict[state_id].append(Phi_angle_avg)\n",
    "    if (first_pass): table_columns.append(\"backbone_Phi_angle_avg\")\n",
    "        \n",
    "    #===Feature: backbone Phi angle std===#\n",
    "    Phi_angle_std = np.nanstd(spider_dict[\"spider2-angle_Phi\"])\n",
    "    features_dict[state_id].append(Phi_angle_std)\n",
    "    if (first_pass): table_columns.append(\"backbone_Phi_angle_std\")\n",
    "        \n",
    "    #===Feature: backbone Psi angle average===#\n",
    "    Psi_angle_avg = np.nanmean(spider_dict[\"spider2-angle_Psi\"])\n",
    "    features_dict[state_id].append(Psi_angle_avg)\n",
    "    if (first_pass): table_columns.append(\"backbone_Psi_angle_avg\")\n",
    "        \n",
    "    #===Feature: backbone Psi angle std===#\n",
    "    Psi_angle_std = np.nanstd(spider_dict[\"spider2-angle_Psi\"])\n",
    "    features_dict[state_id].append(Psi_angle_std)\n",
    "    if (first_pass): table_columns.append(\"backbone_Psi_angle_std\")\n",
    "        \n",
    "    #===Feature: c-alpha angle (i-2=>i+1) average===#\n",
    "    tau_angle_avg = np.nanmean(spider_dict[\"spider2-angle_tau\"])\n",
    "    features_dict[state_id].append(tau_angle_avg)\n",
    "    if (first_pass): table_columns.append(\"c-alpha_tau_angle_avg\")\n",
    "        \n",
    "    #===Feature: c-alpha angle (i-2=>i+1) std===#\n",
    "    tau_angle_std = np.nanstd(spider_dict[\"spider2-angle_tau\"])\n",
    "    features_dict[state_id].append(tau_angle_std)\n",
    "    if (first_pass): table_columns.append(\"c-alph_tau_angle_std\")\n",
    "    \n",
    "    #===Feature: c-alpha angle (i-1=>i+1) average===#\n",
    "    theta_angle_avg = np.nanmean(spider_dict[\"spider2-angle_theta\"])\n",
    "    features_dict[state_id].append(theta_angle_avg)\n",
    "    if (first_pass): table_columns.append(\"c-alpha_theta_angle_avg\")\n",
    "        \n",
    "    #===Feature: c-alpha angle (i-1=>i+1) std===#\n",
    "    theta_angle_std = np.nanstd(spider_dict[\"spider2-angle_theta\"])\n",
    "    features_dict[state_id].append(theta_angle_std)\n",
    "    if (first_pass): table_columns.append(\"c-alph_theta_angle_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_struct_pred(features_dict, state_id, table_columns, first_pass, spider_dict):\n",
    "            \n",
    "    #===Feature: helix prob. avg===#\n",
    "    helix_prob_avg = np.nanmean(spider_dict[\"spider2-helix_prob\"])\n",
    "    features_dict[state_id].append(helix_prob_avg)\n",
    "    if (first_pass): table_columns.append(\"helix_prob_avg\")\n",
    "        \n",
    "    #===Feature: helix prob. std===#\n",
    "    helix_prob_std = np.nanstd(spider_dict[\"spider2-helix_prob\"])\n",
    "    features_dict[state_id].append(helix_prob_std)\n",
    "    if (first_pass): table_columns.append(\"helix_prob_std\")\n",
    "    \n",
    "    #===Feature: sheet prob. avg===#\n",
    "    sheet_prob_avg = np.nanmean(spider_dict[\"spider2-sheet_prob\"])\n",
    "    features_dict[state_id].append(sheet_prob_avg)\n",
    "    if (first_pass): table_columns.append(\"sheet_prob_avg\")\n",
    "        \n",
    "    #===Feature: sheet prob. std===#\n",
    "    sheet_prob_std = np.nanstd(spider_dict[\"spider2-sheet_prob\"])\n",
    "    features_dict[state_id].append(sheet_prob_std)\n",
    "    if (first_pass): table_columns.append(\"sheet_prob_std\")\n",
    "        \n",
    "    #===Feature: turn prob. avg===#\n",
    "    turn_prob_avg = np.nanmean(spider_dict[\"spider2-turn_prob\"])\n",
    "    features_dict[state_id].append(turn_prob_avg)\n",
    "    if (first_pass): table_columns.append(\"turn_prob_avg\")\n",
    "        \n",
    "    #===Feature: turn prob. std===#\n",
    "    turn_prob_std = np.nanstd(spider_dict[\"spider2-turn_prob\"])\n",
    "    features_dict[state_id].append(turn_prob_std)\n",
    "    if (first_pass): table_columns.append(\"turn_prob_std\")\n",
    "        \n",
    "    #===Feature: major allele majority propensity===#\n",
    "    struct_majority_counts = []\n",
    "    struct_majority_counts.append(spider_dict[\"spider2-2nd_struct\"].count('H'))\n",
    "    struct_majority_counts.append(spider_dict[\"spider2-2nd_struct\"].count('E'))\n",
    "    struct_majority_counts.append(spider_dict[\"spider2-2nd_struct\"].count('C'))\n",
    "    \n",
    "    max_idx = np.where(np.array(struct_majority_counts) == max(struct_majority_counts))[0]\n",
    "    majority_vec = [0, 0, 0]\n",
    "    for i in max_idx:\n",
    "        majority_vec[i] = 1 #put 1 in the struct that has max. count\n",
    "    \n",
    "    features_dict[state_id].extend(majority_vec)\n",
    "    if (first_pass): table_columns.extend([\"spd_helix_is_majority\", \"spd_sheet_is_majority\", \"spd_turn_is_majority\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_half_sphere_exposure_pred(features_dict, state_id, table_columns, first_pass, spider_dict):\n",
    "    \n",
    "    #===Feature: half-sphere exposure C-C vectors (HSE-up) average===#\n",
    "    hsa2_HSEu_avg = np.mean(spider_dict[\"spider2-hsa2_HSEu\"])\n",
    "    features_dict[state_id].append(hsa2_HSEu_avg)\n",
    "    if (first_pass): table_columns.append(\"hsa2_HSE-up_avg\")\n",
    "        \n",
    "    #===Feature:half-sphere exposure C-C vectors (HSE-up) std===#\n",
    "    hsa2_HSEu_std = np.std(spider_dict[\"spider2-hsa2_HSEu\"])\n",
    "    features_dict[state_id].append(hsa2_HSEu_std)\n",
    "    if (first_pass): table_columns.append(\"hsa2_HSE-up_std\")\n",
    "        \n",
    "    #===Feature: half-sphere exposure C-C vectors (HSE-down) average===#\n",
    "    hsa2_HSEd_avg = np.mean(spider_dict[\"spider2-hsa2_HSEu\"])\n",
    "    features_dict[state_id].append(hsa2_HSEd_avg)\n",
    "    if (first_pass): table_columns.append(\"hsa2_HSE-down_avg\")\n",
    "        \n",
    "    #===Feature:half-sphere exposure C-C vectors (HSE-down) std===#\n",
    "    hsa2_HSEd_std = np.std(spider_dict[\"spider2-hsa2_HSEd\"])\n",
    "    features_dict[state_id].append(hsa2_HSEd_std)\n",
    "    if (first_pass): table_columns.append(\"hsa2_HSE-down_std\")\n",
    "    \n",
    "    #===Feature: half-sphere exposure C-C vectors (HSE-up) average===#\n",
    "    hsb2_HSEu_avg = np.mean(spider_dict[\"spider2-hsb2_HSEu\"])\n",
    "    features_dict[state_id].append(hsb2_HSEu_avg)\n",
    "    if (first_pass): table_columns.append(\"hsb2_HSE-up_avg\")\n",
    "        \n",
    "    #===Feature:half-sphere exposure C-C vectors (HSE-up) std===#\n",
    "    hsb2_HSEu_std = np.std(spider_dict[\"spider2-hsb2_HSEu\"])\n",
    "    features_dict[state_id].append(hsb2_HSEu_std)\n",
    "    if (first_pass): table_columns.append(\"hsb2_HSE-up_std\")\n",
    "    \n",
    "    #===Feature: half-sphere exposure C-C vectors (HSE-down) average===#\n",
    "    hsb2_HSEd_avg = np.mean(spider_dict[\"spider2-hsb2_HSEd\"])\n",
    "    features_dict[state_id].append(hsb2_HSEd_avg)\n",
    "    if (first_pass): table_columns.append(\"hsb2_HSE-down_avg\")\n",
    "        \n",
    "    #===Feature:half-sphere exposure C-C vectors (HSE-down) std===#\n",
    "    hsb2_HSEd_std = np.std(spider_dict[\"spider2-hsb2_HSEd\"])\n",
    "    features_dict[state_id].append(hsb2_HSEd_std)\n",
    "    if (first_pass): table_columns.append(\"hsb2_HSE-down_std\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Whole-domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_domain_conservation(features_dict, state_id, table_columns, first_pass, domain_name):\n",
    "    \n",
    "    #===Features: phastCons and PhyloP whole-domain average and std===#\n",
    "    features_dict[state_id].append(whole_domain_con_dict[domain_name][\"phastCons_mean\"])\n",
    "    if (first_pass): table_columns.append(\"whole_domain_phastCons_avg\")\n",
    "    features_dict[state_id].append(whole_domain_con_dict[domain_name][\"phastCons_std\"])\n",
    "    if (first_pass): table_columns.append(\"whole_domain_phastCons_std\")\n",
    "    features_dict[state_id].append(whole_domain_con_dict[domain_name][\"phyloP_mean\"])\n",
    "    if (first_pass): table_columns.append(\"whole_domain_phyloP_avg\")\n",
    "    features_dict[state_id].append(whole_domain_con_dict[domain_name][\"phyloP_std\"])\n",
    "    if (first_pass): table_columns.append(\"whole_domain_phyloP_std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_domain_GO_group(features_dict, state_id, table_columns, first_pass, domain_name):\n",
    "    \n",
    "    #===Feature: domain groups (based on GO analysis)===#\n",
    "    GO_groups_vec = [0] *len(go_term_group)\n",
    "    \n",
    "    if (whole_domain_GO_dict.has_key(domain_name)):\n",
    "        domain_GO_groups = whole_domain_GO_dict[domain_name]\n",
    "        for group in domain_GO_groups:\n",
    "            group_val = group.value\n",
    "            GO_groups_vec[group_val] = 1\n",
    "    #If the domain doesn't have any of the GO terms we defined, adding +1 to NO_TERM\n",
    "    else:\n",
    "        GO_groups_vec[go_term_group.NO_TERM.value] = 1\n",
    "     \n",
    "    features_dict[state_id].extend(GO_groups_vec)\n",
    "    if (first_pass): \n",
    "        for term in go_term_group:\n",
    "            table_columns.append(\"GO:\"+term.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Position and location features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_location_features(features_dict, state_id, table_columns, first_pass, state, max_state):\n",
    "    \n",
    "    #===Feature: the position in the domain===#\n",
    "    features_dict[state_id].append(state)\n",
    "    if (first_pass): table_columns.append(\"domain_pos\"); orto_para_cols.append(\"domain_pos\")\n",
    "        \n",
    "    #===Feature: the domain total length===#\n",
    "    features_dict[state_id].append(max_state)\n",
    "    if (first_pass): table_columns.append(\"domain_length\"); orto_para_cols.append(\"domain_length\")\n",
    "        \n",
    "    #===Feature: the location in the domain: beginning/middle/end===#\n",
    "    location_list = [0,0,0]\n",
    "    BEGIN_POS = 0\n",
    "    MIDDLE_POS = 1\n",
    "    END_POS = 2\n",
    "    domain_location_bins = np.histogram(np.arange(1,max_state),bins=3)[1]\n",
    "    if (state < domain_location_bins[1]):\n",
    "        location_list[BEGIN_POS] = 1\n",
    "    elif (state > domain_location_bins[2]):\n",
    "        location_list[END_POS] = 1\n",
    "    else:\n",
    "        location_list[MIDDLE_POS] = 1\n",
    "        \n",
    "    features_dict[state_id].extend(location_list)\n",
    "    if (first_pass): \n",
    "        col_names = [\"domain_pos_location_begin\", \"domain_pos_location_middle\", \"domain_pos_location_end\"]\n",
    "        table_columns.extend(col_names); orto_para_cols.append(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_location_features(features_dict, state_id, table_columns, first_pass, protein_pos_list, protein_len_list):\n",
    "    \n",
    "    #===Feature: the protein total length (average)===#\n",
    "    protein_len_avg = np.mean(protein_len_list)\n",
    "    features_dict[state_id].append(protein_len_avg)\n",
    "    if (first_pass): table_columns.append(\"prot_avg_length\"); orto_para_cols.append(\"prot_avg_length\")\n",
    "        \n",
    "    #===Feature: counts of he location in the protein: beginning/middle/end===#\n",
    "    location_list = [0,0,0]\n",
    "    BEGIN_POS = 0\n",
    "    MIDDLE_POS = 1\n",
    "    END_POS = 2\n",
    "    for i in range(len(protein_pos_list)):\n",
    "        prot_location_bins = np.histogram(np.arange(1,protein_len_list[i]),bins=3)[1]\n",
    "        if (protein_pos_list[i] < prot_location_bins[1]):\n",
    "            location_list[BEGIN_POS] += 1\n",
    "        elif (protein_pos_list[i] > prot_location_bins[2]):\n",
    "            location_list[END_POS] += 1\n",
    "        else:\n",
    "            location_list[MIDDLE_POS] += 1\n",
    "    \n",
    "    #Normalize to ratios\n",
    "    location_list_norm = np.array(location_list)/sum(location_list)\n",
    "    \n",
    "    features_dict[state_id].extend(location_list_norm)\n",
    "    if (first_pass): \n",
    "        col_names = [\"prot_pos_location_begin\", \"prot_pos_location_middle\", \"prot_pos_location_end\"]\n",
    "        table_columns.extend(col_names); orto_para_cols.append(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binding scores function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binding_propensities(features_dict, state_id, table_columns, first_pass, domain_name, state):\n",
    "    \n",
    "    curr_domain_props_dict = binding_props_dict[domain_name]\n",
    "    \n",
    "    for ligand in ligands:\n",
    "        \n",
    "        #Getting information form the propensity dict\n",
    "        if (ligand in curr_domain_props_dict.keys()):\n",
    "            prop = curr_domain_props_dict[ligand][\"states_props\"][state]\n",
    "            th_10 = curr_domain_props_dict[ligand][\"prop_th_0.1\"]\n",
    "            th_25 = curr_domain_props_dict[ligand][\"prop_th_0.25\"]\n",
    "            th_50 = curr_domain_props_dict[ligand][\"prop_th_0.5\"]\n",
    "            th_75 = curr_domain_props_dict[ligand][\"prop_th_0.75\"]\n",
    "\n",
    "        else:\n",
    "            prop = -1\n",
    "            th_10 = -1\n",
    "            th_25 = -1\n",
    "            th_50 = -1\n",
    "            th_75 = -1\n",
    "        \n",
    "        #Saving information to the features table\n",
    "        features_dict[state_id].append(prop)\n",
    "        ligand_prop_str = ligand+\"_propensity\"\n",
    "        if (first_pass): table_columns.append(ligand_prop_str); orto_para_cols.append(ligand_prop_str)\n",
    "            \n",
    "        features_dict[state_id].append(th_10)\n",
    "        ligand_th10_str = ligand+\"_prop_th_0.1\"\n",
    "        if (first_pass): table_columns.append(ligand_th10_str); orto_para_cols.append(ligand_th10_str)\n",
    "            \n",
    "        features_dict[state_id].append(th_25)\n",
    "        ligand_th25_str = ligand+\"_prop_th_0.25\"\n",
    "        if (first_pass): table_columns.append(ligand_th25_str); orto_para_cols.append(ligand_th25_str)\n",
    "        \n",
    "        features_dict[state_id].append(th_50)\n",
    "        ligand_th50_str = ligand+\"_prop_th_0.5\"\n",
    "        if (first_pass): table_columns.append(ligand_th50_str); orto_para_cols.append(ligand_th50_str)\n",
    "            \n",
    "        features_dict[state_id].append(th_75)\n",
    "        ligand_th75_str = ligand+\"_prop_th_0.75\"\n",
    "        if (first_pass): table_columns.append(ligand_th75_str); orto_para_cols.append(ligand_th75_str)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binding_scores_features_old_pfam(features_dict, state_id, table_columns, first_pass, domain_name, state):\n",
    "    \n",
    "    #Feature: DNA Binding-score\n",
    "    if (state in dna_binding_scores_dict[domain_name].keys()):\n",
    "        dna_binding_score = dna_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        dna_binding_score = 0\n",
    "    features_dict[state_id].append(dna_binding_score)\n",
    "    if (first_pass): table_columns.append(\"dna_binding_score\"); orto_para_cols.append(\"dna_binding_score\")\n",
    "        \n",
    "    #Feature: RNA Binding-score\n",
    "    if (state in rna_binding_scores_dict[domain_name].keys()):\n",
    "        rna_binding_score = rna_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        rna_binding_score = 0\n",
    "    features_dict[state_id].append(rna_binding_score)\n",
    "    if (first_pass): table_columns.append(\"rna_binding_score\"); orto_para_cols.append(\"rna_binding_score\")\n",
    "        \n",
    "    #Feature: DNABASE Binding-score\n",
    "    if (state in dnabase_binding_scores_dict[domain_name].keys()):\n",
    "        dnabase_binding_score = dnabase_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        dnabase_binding_score = 0\n",
    "    features_dict[state_id].append(dnabase_binding_score)\n",
    "    if (first_pass): table_columns.append(\"dnabase_binding_score\"); orto_para_cols.append(\"dnabase_binding_score\")\n",
    "    \n",
    "    #Feature: RNABASE Binding-score\n",
    "    if (state in rnabase_binding_scores_dict[domain_name].keys()):\n",
    "        rnabase_binding_score = rnabase_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        rnabase_binding_score = 0\n",
    "    features_dict[state_id].append(rnabase_binding_score)\n",
    "    if (first_pass): table_columns.append(\"rnabase_binding_score\"); orto_para_cols.append(\"rnabase_binding_score\")\n",
    "        \n",
    "    #Feature: DNABACKBONE Binding-score\n",
    "    if (state in dnabackbone_binding_scores_dict[domain_name].keys()):\n",
    "        dnabackbone_binding_score = dnabackbone_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        dnabackbone_binding_score = 0\n",
    "    features_dict[state_id].append(dnabackbone_binding_score)\n",
    "    if (first_pass): table_columns.append(\"dnabackbone_binding_score\"); orto_para_cols.append(\"dnabackbone_binding_score\")\n",
    "    \n",
    "    #Feature: RNABACKBONE Binding-score\n",
    "    if (state in rnabackbone_binding_scores_dict[domain_name].keys()):\n",
    "        rnabackbone_binding_score = rnabackbone_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        rnabackbone_binding_score = 0\n",
    "    features_dict[state_id].append(rnabackbone_binding_score)\n",
    "    if (first_pass): table_columns.append(\"rnabackbone_binding_score\"); orto_para_cols.append(\"rnabackbone_binding_score\")\n",
    "        \n",
    "    #Feature: peptide Binding-score\n",
    "    if (state in peptide_binding_scores_dict[domain_name].keys()):\n",
    "        peptide_binding_score = peptide_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        peptide_binding_score = 0\n",
    "    features_dict[state_id].append(peptide_binding_score)\n",
    "    if (first_pass): table_columns.append(\"peptide_binding_score\"); orto_para_cols.append(\"peptide_binding_score\")\n",
    "        \n",
    "    #Feature: ion Binding-score\n",
    "    if (state in ion_binding_scores_dict[domain_name].keys()):\n",
    "        ion_binding_score = ion_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        ion_binding_score = 0\n",
    "    features_dict[state_id].append(ion_binding_score)\n",
    "    if (first_pass): table_columns.append(\"ion_binding_score\"); orto_para_cols.append(\"ion_binding_score\")\n",
    "        \n",
    "    #Feature: metabolite Binding-score\n",
    "    if (state in metabolite_binding_scores_dict[domain_name].keys()):\n",
    "        metabolite_binding_score = metabolite_binding_scores_dict[domain_name][state]\n",
    "    else:\n",
    "        metabolite_binding_score = 0\n",
    "    features_dict[state_id].append(metabolite_binding_score)\n",
    "    if (first_pass): table_columns.append(\"metabolite_binding_score\"); orto_para_cols.append(\"metabolite_binding_score\")\n",
    "        \n",
    "    #Feature: Max. Binding-score\n",
    "    max_binding_score = max(dna_binding_score, rna_binding_score, dnabase_binding_score, rnabase_binding_score, dnabackbone_binding_score, rnabackbone_binding_score, \n",
    "                            peptide_binding_score, ion_binding_score, metabolite_binding_score)\n",
    "    features_dict[state_id].append(max_binding_score)\n",
    "    if (first_pass): table_columns.append(\"max_binding_score\"); orto_para_cols.append(\"max_binding_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Ank_2\n",
      "Finished Ank_4\n",
      "Finished Ank_5\n",
      "Finished Asp\n",
      "Finished CD45\n",
      "Finished Cys_knot\n",
      "Finished DENN\n",
      "Finished DUF1908\n",
      "Finished DUF4187\n",
      "Finished EF-hand_1\n",
      "Finished EF-hand_5\n",
      "Finished EF-hand_6\n",
      "Finished EF-hand_7\n",
      "Finished EF-hand_8\n",
      "Finished EF-hand_9\n",
      "Finished EFhand_Ca_insen\n",
      "Finished ELM2\n",
      "Finished Exo_endo_phos\n",
      "Finished FYVE\n",
      "Finished G-patch\n",
      "Finished G-patch_2\n",
      "Finished GRAM\n",
      "Finished GSHPx\n",
      "Finished IQ_SEC7_PH\n",
      "Finished LRR_1\n",
      "Finished LRR_12\n",
      "Finished LRR_6\n",
      "Finished LRR_8\n",
      "Finished MFS_1\n",
      "Finished Myb_DNA-binding\n",
      "Finished Myotub-related\n",
      "Finished PDZ\n",
      "Finished PDZ_6\n",
      "Finished PH\n",
      "Finished PNMA\n",
      "Finished PTP_N\n",
      "Finished Pkinase\n",
      "Finished Pkinase_Tyr\n",
      "Finished RNase_T\n",
      "Finished RUN\n",
      "Finished Rdx\n",
      "Finished SBF2\n",
      "Finished SKICH\n",
      "Finished Sec7\n",
      "Finished SelP_C\n",
      "Finished SelP_N\n",
      "Finished SelR\n",
      "Finished Sep15_SelM\n",
      "Finished T4_deiodinase\n",
      "Finished TAXi_N\n",
      "Finished TIR\n",
      "Finished Trefoil\n",
      "Finished V-set\n",
      "Finished WAP\n",
      "Finished Y_phosphatase\n",
      "Finished dDENN\n",
      "Finished fn3\n",
      "Finished uDENN\n",
      "Finished zf-C2H2\n",
      "Finished zf-C2H2_4\n",
      "Finished zf-CCCH\n",
      "Finished zf-H2C2_5\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "features_dict = defaultdict(list)\n",
    "an_str = [\"an_afr\", \"an_amr\", \"an_eas\", \"an_fin\", \"an_nfe\", \"an_oth\", \"an_sas\"]\n",
    "ac_str = [\"ac_afr\", \"ac_amr\", \"ac_eas\", \"ac_fin\", \"ac_nfe\", \"ac_oth\", \"ac_sas\"]\n",
    "table_columns = []\n",
    "orto_para_cols = []\n",
    "first_pass = True\n",
    "\n",
    "#Randomize numbers to create id feature\n",
    "np.random.seed(0)\n",
    "random_ids = np.random.permutation(len(domains))\n",
    "\n",
    "#for domain_name in domains:\n",
    "for i in range(len(domains)):\n",
    "    domain_name = domains[i]\n",
    "   \n",
    "    dirfiles = !ls -t $input_path$domain_name\n",
    "    filename = dirfiles[0]\n",
    "    with open(input_path+domain_name+\"/\"+filename, 'rb') as handle:\n",
    "        states_dict = pickle.load(handle)\n",
    "    \n",
    "    #Create af_adj flat dict\n",
    "    states_af_adj_dict = defaultdict(list)\n",
    "    for state in states_dict.keys():\n",
    "        for d in states_dict[state]:\n",
    "            states_af_adj_dict[state].append(d[\"af_adj\"])\n",
    "        \n",
    "    #scale the af_dict\n",
    "    states_MAF_adj_dict_scaled = defaultdict(list)\n",
    "    for state in states_dict.keys():\n",
    "        state_len = len(states_dict[state])\n",
    "        for d in states_dict[state]:\n",
    "            states_MAF_adj_dict_scaled[state].append(float(d[\"af_adj\"]/state_len))\n",
    "    \n",
    "    #Create a dict of conserved states\n",
    "    con_states_dict = {}\n",
    "    con_threshold = 0.5\n",
    "    for state in hmm_prob_dict[domain_name].keys():\n",
    "        prob_list = hmm_prob_dict[domain_name][state]\n",
    "        for i in range(len(prob_list)):\n",
    "            p = prob_list[i]\n",
    "            if (p > con_threshold):\n",
    "                major_allele = pfam_aa_order[i]\n",
    "                con_states_dict[state] = major_allele\n",
    "    \n",
    "    #Adding states features\n",
    "    for state in states_dict.keys():\n",
    "        \n",
    "        state_id = domain_name+\"_\"+str(state)\n",
    "        \n",
    "        #Init counters & paramters\n",
    "        maf_list = []\n",
    "        sites_aa_alter_num = 0\n",
    "        sites_snp_alter_num = 0\n",
    "        sites_aa_num = len(states_dict[state])\n",
    "        sites_snp_num = 3*sites_aa_num\n",
    "        sites_poly_aa_num = 0 #The number of different aa in all the altered sites (most are 1)\n",
    "        sites_poly_aa_several = 0\n",
    "        \n",
    "        #Rare-poly-counters\n",
    "        rare_5_num = 0\n",
    "        rare_05_num = 0\n",
    "        rare_005_num = 0\n",
    "        \n",
    "        #Conservation params\n",
    "        phastCons_dict = defaultdict(list)\n",
    "        phyloP_dict = defaultdict(list)\n",
    "        jsd100way_list = []\n",
    "        \n",
    "        #SPIDER params\n",
    "        spider_dict = defaultdict(list)\n",
    "        \n",
    "        #BLOSUM62_params\n",
    "        blosum62_list = []\n",
    "        weigted_blosum62_list = []\n",
    "        \n",
    "        #PAM40_params\n",
    "        pam40_list = []\n",
    "        weigted_pam40_list = []\n",
    "        \n",
    "        #dn/ds counters and variables\n",
    "        ref_seq = \"\"\n",
    "        Nd = 0\n",
    "        Sd = 0\n",
    "        \n",
    "        #SIFT params\n",
    "        sift_scores_list = []\n",
    "        weighted_sift_scores_list = []\n",
    "        \n",
    "        #PolyPhen params\n",
    "        polyphen_scores_list = []\n",
    "        weighted_polyphen_scores_list = []\n",
    "        polyphen_pred_list = []\n",
    "        \n",
    "        #clinVar params\n",
    "        clinsig_list = []\n",
    "        clinsig_af = []\n",
    "        \n",
    "        #Major allele params\n",
    "        aa_ref_hist = [0] * len(amino_acids_sym)\n",
    "        \n",
    "        #Substitution params\n",
    "        aa_alt_hist = [0] * len(amino_acids_sym)\n",
    "        aa_alt_prob = [0] * len(amino_acids_sym)\n",
    "        aa_alt_prob_avg = [0] * len(amino_acids_sym)\n",
    "        ref_alt_pairs = []\n",
    "        \n",
    "        #protein position params\n",
    "        protein_pos_list = []\n",
    "        protein_len_list = []\n",
    "        \n",
    "        #Populations variables\n",
    "        ac_sum = [0] *len(ac_str)\n",
    "        ac_sum_syn = [0] *len(ac_str)\n",
    "        ac_sum_nonsyn = [0] *len(ac_str)\n",
    "        an_list = [[] for i in range(len(an_str))]\n",
    "        pop_maf_list = [[] for i in range(len(an_str))]\n",
    "        pop_maf_syn_list = [[] for i in range(len(an_str))]\n",
    "        pop_maf_nonsyn_list = [[] for i in range(len(an_str))]\n",
    "        \n",
    "        #Iterating the state dict to get properties\n",
    "        for d in states_dict[state]:\n",
    "            \n",
    "            #a list of all maf per intance\n",
    "            maf_list.append(d[\"af_adj\"])\n",
    "            \n",
    "            #Creating a position pseudo-ref sequence\n",
    "            ref_codon = d[\"bp_ref\"]\n",
    "            ref_seq = ref_seq+ref_codon\n",
    "            \n",
    "            #Calculating frequency-based N/S\n",
    "            bp_af_adj_dict = d[\"bp_af_adj_dict\"]\n",
    "            for alt_codon in bp_af_adj_dict.keys():\n",
    "                alt_aa = codon_table[alt_codon]\n",
    "                #syn\n",
    "                if (alt_aa == d[\"aa_ref\"]):\n",
    "                    Sd += bp_af_adj_dict[alt_codon]\n",
    "                #Non-syn\n",
    "                else:\n",
    "                    Nd += bp_af_adj_dict[alt_codon]\n",
    "            \n",
    "            #Major allele parameters\n",
    "            aa_ref = d[\"aa_ref\"]\n",
    "            aa_ref_pos = amino_acids_sym.index(aa_ref)\n",
    "            aa_ref_hist[aa_ref_pos] += 1\n",
    "            \n",
    "            #Conservation scores\n",
    "            phastCons_curr_list = d[\"phastCons\"]\n",
    "            if (len(phastCons_curr_list) > 0):\n",
    "                phastCons_dict[1].append(phastCons_curr_list[0])\n",
    "            if (len(phastCons_curr_list) > 1):\n",
    "                phastCons_dict[2].append(phastCons_curr_list[1])\n",
    "            else:\n",
    "                phastCons_dict[2].append(np.nan)\n",
    "            if (len(phastCons_curr_list) > 2):\n",
    "                phastCons_dict[3].append(phastCons_curr_list[2])\n",
    "            else:\n",
    "                phastCons_dict[3].append(np.nan)\n",
    "\n",
    "            phyloP_curr_list = d[\"phyloP\"]\n",
    "            if (len(phyloP_curr_list) > 0):\n",
    "                phyloP_dict[1].append(phyloP_curr_list[0])\n",
    "            if (len(phyloP_curr_list) > 1):\n",
    "                phyloP_dict[2].append(phyloP_curr_list[1])\n",
    "            else:\n",
    "                phyloP_dict[2].append(np.nan)\n",
    "            if (len(phyloP_curr_list) > 2):\n",
    "                phyloP_dict[3].append(phyloP_curr_list[2])\n",
    "            else:\n",
    "                phyloP_dict[3].append(np.nan)\n",
    "            \n",
    "            jsd100way_list.append(d[\"100-way-BLOSUM_JSD\"])\n",
    "            \n",
    "            #SPIDER parameters (add only if exist)\n",
    "            if (\"spider2-2nd_struct\" in d.keys()):\n",
    "                spider_dict[\"spider2-2nd_struct\"].append(d[\"spider2-2nd_struct\"])\n",
    "                spider_dict[\"spider2-helix_prob\"].append(float(d[\"spider2-helix_prob\"]))\n",
    "                spider_dict[\"spider2-sheet_prob\"].append(float(d[\"spider2-sheet_prob\"]))\n",
    "                spider_dict[\"spider2-turn_prob\"].append(float(d[\"spider2-turn_prob\"]))\n",
    "                spider_dict[\"spider2-angle_Phi\"].append(float(d[\"spider2-angle_Phi\"]))\n",
    "                spider_dict[\"spider2-angle_Psi\"].append(float(d[\"spider2-angle_Psi\"]))\n",
    "                spider_dict[\"spider2-angle_tau\"].append(float(d[\"spider2-angle_tau\"]))\n",
    "                spider_dict[\"spider2-angle_theta\"].append(float(d[\"spider2-angle_theta\"]))\n",
    "                spider_dict[\"spider2-ASA\"].append(float(d[\"spider2-ASA\"]))\n",
    "                spider_dict[\"spider2-hsa2_HSEu\"].append(float(d[\"spider2-hsa2_HSEu\"]))\n",
    "                spider_dict[\"spider2-hsa2_HSEd\"].append(float(d[\"spider2-hsa2_HSEd\"]))\n",
    "                spider_dict[\"spider2-hsb2_HSEu\"].append(float(d[\"spider2-hsb2_HSEu\"]))\n",
    "                spider_dict[\"spider2-hsb2_HSEd\"].append(float(d[\"spider2-hsb2_HSEd\"]))\n",
    "                spider_dict[\"spider2-hsa2_CN\"].append(float(d[\"spider2-hsa2_CN\"]))\n",
    "                spider_dict[\"spider2-hsb2_CN\"].append(float(d[\"spider2-hsb2_CN\"]))\n",
    "            \n",
    "            protein_pos_list.append(d[\"prot_pos\"])\n",
    "            protein_len_list.append(d[\"prot_len\"])\n",
    "            \n",
    "            if (d[\"af_adj\"] > 0):\n",
    "                sites_aa_alter_num += 1\n",
    "                sites_snp_alter_num += len(d[\"an_adj\"])\n",
    "                \n",
    "                #Number of different polymorphisms at this site\n",
    "                site_poly_num = len(d[\"alterations_af_adj_dict\"].keys())\n",
    "                sites_poly_aa_num += site_poly_num\n",
    "                if (site_poly_num > 1):\n",
    "                    sites_poly_aa_several += 1\n",
    "                \n",
    "                #Rare poly features\n",
    "                \n",
    "                for alt_codon in bp_af_adj_dict.keys():\n",
    "                    #Add to counters only nonsyn SNPs\n",
    "                    if (codon_table[alt_codon] != codon_table[ref_codon]):\n",
    "                        if (bp_af_adj_dict[alt_codon] < MAFT_005):\n",
    "                            rare_005_num += 1\n",
    "                            rare_05_num += 1\n",
    "                            rare_5_num += 1\n",
    "                        elif (bp_af_adj_dict[alt_codon] < MAFT_05):\n",
    "                            rare_05_num += 1\n",
    "                            rare_5_num += 1\n",
    "                        elif (bp_af_adj_dict[alt_codon] < MAFT_5):\n",
    "                            rare_5_num += 1\n",
    "                \n",
    "                #Alt, BLOSUM62 and PAM40 features\n",
    "                ref = d[\"aa_ref\"]\n",
    "                for alt in d[\"alterations_af_adj_dict\"].keys():\n",
    "                    af_adj = np.mean(d[\"alterations_af_adj_dict\"][alt])\n",
    "                    #BLOSUM\n",
    "                    blosum_val = blosum62_dict[ref][alt]\n",
    "                    blosum62_list.append(blosum_val)\n",
    "                    weigted_blosum62_list.append(blosum_val*af_adj)\n",
    "                    #PAM\n",
    "                    pam_val = pam40_dict[ref][alt]\n",
    "                    pam40_list.append(pam_val)\n",
    "                    weigted_pam40_list.append(pam_val*af_adj)\n",
    "                    #Alt aa counts\n",
    "                    aa_alt_pos = amino_acids_sym.index(alt)\n",
    "                    aa_alt_hist[aa_alt_pos] += 1\n",
    "                    #Alt aa prob.\n",
    "                    aa_alt_prob[aa_alt_pos] += af_adj\n",
    "                    #ref-alt pairs\n",
    "                    ref_alt_pairs.append((ref,alt,af_adj))\n",
    "                                    \n",
    "                #SIFT\n",
    "                sift_list = d[\"SIFT\"]\n",
    "                for i in range(len(sift_list)):\n",
    "                    s = sift_list[i]\n",
    "                    if (s != \"\"):\n",
    "                        try:\n",
    "                            s_af = bp_af_adj_dict[d[\"bp_list\"][i]]\n",
    "                        except: \n",
    "                            #The major allele was replaced, no score available for the correct substitution\n",
    "                            continue\n",
    "                        sift_score = float(s[s.find(\"(\")+1:s.find(\")\")])\n",
    "                        sift_scores_list.append(sift_score)\n",
    "                        weighted_sift_scores_list.append(sift_score*s_af)\n",
    "                \n",
    "                #PolyPhen\n",
    "                polyphen_list = d[\"PolyPhen\"] \n",
    "                for i in range(len(polyphen_list)):\n",
    "                    s = polyphen_list[i]\n",
    "                    if (s != \"\"):\n",
    "                        try:\n",
    "                            s_af = bp_af_adj_dict[d[\"bp_list\"][i]]\n",
    "                        except:\n",
    "                            #The major allele was replaced, no score available for the correct substitution\n",
    "                            continue\n",
    "                        polyphen_score = float(s[s.find(\"(\")+1:s.find(\")\")])\n",
    "                        polyphen_scores_list.append(polyphen_score)\n",
    "                        weighted_polyphen_scores_list.append(polyphen_score*s_af)\n",
    "                        polyphen_pred_list.append(s[:s.find(\"(\")])\n",
    "                \n",
    "                #clinVar\n",
    "                curr_clinsig_list = d[\"clin_sig\"]\n",
    "                for i in range(len(curr_clinsig_list)):\n",
    "                    s = curr_clinsig_list[i]\n",
    "                    if (s != \"\"):\n",
    "                        try:\n",
    "                            s_af = bp_af_adj_dict[d[\"bp_list\"][i]]\n",
    "                        except:\n",
    "                            #The major allele was replaced, no score available for the correct substitution\n",
    "                            continue\n",
    "                        clinsig_list.append(s)\n",
    "                        clinsig_af.append(s_af)\n",
    "                        \n",
    "                #Saving indices of syn and non-syn bps\n",
    "                syn_idx = []\n",
    "                nonsyn_idx =[]\n",
    "                for i in range(len(d[\"bp_list\"])):\n",
    "                    ref_aa = d[\"aa_ref\"]\n",
    "                    alt_bp = d[\"bp_list\"][i]\n",
    "                    alt_aa = codon_table[alt_bp.upper()]\n",
    "                    if (alt_aa == ref_aa):\n",
    "                        syn_idx.append(i)\n",
    "                    else:\n",
    "                        nonsyn_idx.append(i)\n",
    "                        \n",
    "                #Summing the AC per population\n",
    "                for i in range(len(ac_str)):\n",
    "                    ac = ac_str[i]\n",
    "                    ac_sum[i] += sum(d[ac])\n",
    "                    #Summing syn and non-syn separately\n",
    "                    ac_sum_syn[i] += sum(np.array(d[ac])[syn_idx])\n",
    "                    ac_sum_nonsyn[i] += sum(np.array(d[ac])[nonsyn_idx])\n",
    "\n",
    "                #Averaging the AN per population, to do that, gathering all an to a list\n",
    "                for i in range(len(an_str)):\n",
    "                    an = an_str[i]\n",
    "                    (an_list[i]).extend(d[an])\n",
    "\n",
    "                #Averaging the MAF per population, to do that: gathering all maf!=0 to a list\n",
    "                for i in range(len(an_str)):\n",
    "                    ac = ac_str[i]\n",
    "                    an = an_str[i]\n",
    "                    for j in range(len(d[ac])):\n",
    "                        if (d[an][j] != 0):\n",
    "                            pop_maf = d[ac][j]/float(d[an][j])\n",
    "                            if (pop_maf != 0):\n",
    "                                if (j in syn_idx):\n",
    "                                    pop_maf_syn_list[i].append(pop_maf)\n",
    "                                else:\n",
    "                                    pop_maf_nonsyn_list[i].append(pop_maf)\n",
    "                                pop_maf_list[i].append(pop_maf)\n",
    "                \n",
    "        #===domain_regular_features===#\n",
    "        features_dict[state_id].append(domain_name)\n",
    "        if (first_pass): table_columns.append(\"domain_name\"); orto_para_cols.append(\"domain_name\")\n",
    "            \n",
    "        domain_idx = (domains.index(domain_name))\n",
    "        features_dict[state_id].append(random_ids[domain_idx])\n",
    "        if (first_pass): table_columns.append(\"domain_id\"); orto_para_cols.append(\"domain_id\")\n",
    "        \n",
    "        #===ExAC MAF Features===#\n",
    "        ExAC_MAF_features(features_dict, state_id, table_columns, first_pass, sites_aa_num, sites_aa_alter_num, maf_list)\n",
    "        \n",
    "        ExAC_population_features(features_dict, state_id, table_columns, first_pass, ac_sum, ac_sum_syn, ac_sum_nonsyn,\n",
    "                                 an_list, pop_maf_list, pop_maf_syn_list, pop_maf_nonsyn_list)\n",
    "        \n",
    "        ExAC_count_features(features_dict, state_id, table_columns, first_pass, sites_aa_num, sites_aa_alter_num, sites_snp_num, sites_snp_alter_num)\n",
    "        \n",
    "        ExAC_rareSNP_features(features_dict, state_id, table_columns, first_pass, sites_snp_alter_num, rare_5_num, rare_05_num, rare_005_num)\n",
    "        \n",
    "        #===Conservation scores features===#\n",
    "        conservation_features(features_dict, state_id, table_columns, first_pass, phastCons_dict, phyloP_dict)\n",
    "        \n",
    "        #===Substitution matrix Features===#\n",
    "        sub_matrix_features(features_dict, state_id, table_columns, first_pass, blosum62_list, weigted_blosum62_list, \"blosum\")\n",
    "\n",
    "        sub_matrix_features(features_dict, state_id, table_columns, first_pass, pam40_list, weigted_pam40_list, \"pam\")\n",
    "\n",
    "        #===pseudo-sequence dN/dS feature===#        \n",
    "        pseudo_dNdS_features(features_dict, state_id, table_columns, first_pass, ref_seq, Nd, Sd)\n",
    "        \n",
    "        #===Pfam HMM-emission probabilities features===#\n",
    "        pfam_emission_prob_features(features_dict, state_id, table_columns, first_pass, domain_name, state)\n",
    "        \n",
    "        pfam_conserved_state_feature(features_dict, state_id, table_columns, first_pass, state, con_states_dict)\n",
    "        \n",
    "        #===SIFT score features===#\n",
    "        SIFT_features(features_dict, state_id, table_columns, first_pass, sift_scores_list, weighted_sift_scores_list)\n",
    "        \n",
    "        #===Polyphen score features===#\n",
    "        PolyPhen_features(features_dict, state_id, table_columns, first_pass, polyphen_scores_list, polyphen_pred_list, weighted_polyphen_scores_list)\n",
    "        \n",
    "        #===ClinVar score features===#\n",
    "        ClinVar_scores(features_dict, state_id, table_columns, first_pass, clinsig_list, clinsig_af)\n",
    "        \n",
    "        #===Entropy features===#\n",
    "        entropy_features(features_dict, state_id, table_columns, first_pass, maf_list)\n",
    "        \n",
    "        #===instances-change to individuals-change ratios & instance-change to 100way vertbrate ratio===#\n",
    "        instance_individuals_100way_change_features(features_dict, state_id, table_columns, first_pass, maf_list, aa_ref_hist, jsd100way_list)\n",
    "        \n",
    "        #===Major allele aa chemical features===#\n",
    "        aa_identity_features(features_dict, state_id, table_columns, first_pass, aa_ref_hist, \"aa_ref\")\n",
    "        \n",
    "        major_allele_charge(features_dict, state_id, table_columns, first_pass, aa_ref_hist) \n",
    "        \n",
    "        major_allele_hydrophobicity(features_dict, state_id, table_columns, first_pass, aa_ref_hist)\n",
    "        \n",
    "        major_allele_volume(features_dict, state_id, table_columns, first_pass, aa_ref_hist)\n",
    "        \n",
    "        major_allele_functional_group(features_dict, state_id, table_columns, first_pass, aa_ref_hist)\n",
    "        \n",
    "        major_allele_propensity(features_dict, state_id, table_columns, first_pass, aa_ref_hist)\n",
    "        \n",
    "        major_allele_h_bonds(features_dict, state_id, table_columns, first_pass, aa_ref_hist)\n",
    "        \n",
    "        #===Substitution features===#\n",
    "        aa_identity_features(features_dict, state_id, table_columns, first_pass, aa_alt_hist, \"aa_alt_cnt\")\n",
    "        \n",
    "        for i in range(len(amino_acids_sym)):\n",
    "            if (aa_alt_prob[i] > 0):\n",
    "                aa_alt_prob_avg[i] = aa_alt_prob[i]/float(aa_alt_hist[i])\n",
    "        aa_identity_features(features_dict, state_id, table_columns, first_pass, aa_alt_prob_avg, \"aa_alt_avg_freq\")\n",
    "        \n",
    "        #===Substitution chemical features===#\n",
    "        sub_diff_hydrophobicity(features_dict, state_id, table_columns, first_pass, ref_alt_pairs)\n",
    "        \n",
    "        sub_diff_volume(features_dict, state_id, table_columns, first_pass, ref_alt_pairs)\n",
    "        \n",
    "        sub_diff_functional_group(features_dict, state_id, table_columns, first_pass,ref_alt_pairs)\n",
    "        \n",
    "        sub_diff_propensity(features_dict, state_id, table_columns, first_pass, ref_alt_pairs)\n",
    "        \n",
    "        sub_diff_h_bonds(features_dict, state_id, table_columns, first_pass, ref_alt_pairs)\n",
    "        \n",
    "        #===SPIDER - secondary structure and solvent accessibility predictions baxsed on the protein sequence===#\n",
    "        spider_solvent_acc_pred(features_dict, state_id, table_columns, first_pass, spider_dict)\n",
    "        \n",
    "        spider_contact_number_pred(features_dict, state_id, table_columns, first_pass, spider_dict)\n",
    "        \n",
    "        spider_angles_pred(features_dict, state_id, table_columns, first_pass, spider_dict)\n",
    "        \n",
    "        spider_struct_pred(features_dict, state_id, table_columns, first_pass, spider_dict)\n",
    "        \n",
    "        spider_half_sphere_exposure_pred(features_dict, state_id, table_columns, first_pass, spider_dict)\n",
    "        \n",
    "        #===Whole-domain aggregated features===#\n",
    "        whole_domain_conservation(features_dict, state_id, table_columns, first_pass, domain_name)\n",
    "        \n",
    "        whole_domain_GO_group(features_dict, state_id, table_columns, first_pass, domain_name)\n",
    "        \n",
    "        #===Position and location features===#\n",
    "        \n",
    "        domain_location_features(features_dict, state_id, table_columns, first_pass, state, max(states_dict.keys()))\n",
    "        \n",
    "        protein_location_features(features_dict, state_id, table_columns, first_pass, protein_pos_list, protein_len_list)\n",
    "          \n",
    "        #===Binding-score features===#\n",
    "        \n",
    "        #if (int(pfam_version) <= 30):\n",
    "         #   binding_scores_features_old_pfam(features_dict, state_id, table_columns, first_pass, domain_name, state)\n",
    "        #else:\n",
    "         #   binding_propensities(features_dict, state_id, table_columns, first_pass, domain_name, state)\n",
    "            \n",
    "        first_pass = False   \n",
    "        \n",
    "    print \"Finished \"+domain_name\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>avg_maf_all</th>\n",
       "      <th>avg_maf_altered</th>\n",
       "      <th>maf_hist_0-0.001</th>\n",
       "      <th>maf_hist_0.001-0.005</th>\n",
       "      <th>maf_hist_0.005-0.01</th>\n",
       "      <th>maf_hist_0.01-0.02</th>\n",
       "      <th>maf_hist_0.02-0.04</th>\n",
       "      <th>maf_hist_0.04-0.06</th>\n",
       "      <th>...</th>\n",
       "      <th>GO:SIGNAL_TRANSDUCTION</th>\n",
       "      <th>domain_pos</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>domain_pos_location_begin</th>\n",
       "      <th>domain_pos_location_middle</th>\n",
       "      <th>domain_pos_location_end</th>\n",
       "      <th>prot_avg_length</th>\n",
       "      <th>prot_pos_location_begin</th>\n",
       "      <th>prot_pos_location_middle</th>\n",
       "      <th>prot_pos_location_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ank_2_1</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.043970e-05</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_10</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>7.688770e-05</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1109.187500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_11</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.313852e-03</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1110.069444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_12</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.952458e-05</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>93</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1112.543430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_13</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>2.022685e-05</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1112.543430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_14</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>4.530364e-05</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>116</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_15</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.520644e-05</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_16</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>3.023469e-06</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_17</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.550392e-04</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_18</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>3.539555e-04</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1112.736961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_19</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.446111e-04</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114.604911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_2</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>4.205822e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_20</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>6.640060e-05</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1114.604911</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_21</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.908081e-05</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1113.057906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_22</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>2.707870e-04</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1112.524554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_23</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>9.112719e-05</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>84</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1113.057906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_24</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>5.297169e-06</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1120.120370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_25</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.941653e-05</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1105.825287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_26</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.906565e-05</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1103.897260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_27</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>6.824880e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1119.902935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_28</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>7.452490e-06</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.516630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_29</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>3.949348e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.516630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_3</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.087332e-05</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1111.291111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_30</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>3.687819e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1106.355705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_31</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>8.499627e-05</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1106.355705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_32</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>8.017989e-05</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1108.464126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_33</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.486238e-05</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1106.355705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_34</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>1.013579e-05</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1106.355705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_35</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>7.821457e-04</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1106.355705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ank_2_36</th>\n",
       "      <td>Ank_2</td>\n",
       "      <td>30</td>\n",
       "      <td>7.584657e-06</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1108.526906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-CCCH_6</th>\n",
       "      <td>zf-CCCH</td>\n",
       "      <td>47</td>\n",
       "      <td>1.440143e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>626.984127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-CCCH_7</th>\n",
       "      <td>zf-CCCH</td>\n",
       "      <td>47</td>\n",
       "      <td>1.843535e-05</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>626.984127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-CCCH_8</th>\n",
       "      <td>zf-CCCH</td>\n",
       "      <td>47</td>\n",
       "      <td>2.993328e-06</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>617.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-CCCH_9</th>\n",
       "      <td>zf-CCCH</td>\n",
       "      <td>47</td>\n",
       "      <td>1.573349e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>626.984127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_1</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.501324e-06</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_10</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.653985e-06</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_11</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.002004e-03</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_12</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>5.673632e-06</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_13</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>3.010735e-06</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_14</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.583309e-06</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_15</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.676544e-06</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_16</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>7.302647e-07</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_17</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.096259e-05</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_18</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.391794e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_19</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.020809e-06</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_2</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>5.141485e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_20</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>3.503735e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_21</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>5.256559e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_22</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.907714e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1085.809524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_23</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>3.906925e-06</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>990.552239</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_24</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>6.183824e-07</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_25</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>6.259176e-06</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_26</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>6.196382e-06</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_3</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>1.824897e-06</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_4</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.035109e-05</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_5</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>3.782912e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_6</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.071103e-06</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_7</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.870485e-06</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_8</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>6.703294e-06</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zf-H2C2_5_9</th>\n",
       "      <td>zf-H2C2_5</td>\n",
       "      <td>44</td>\n",
       "      <td>3.416853e-06</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1009.044118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows  442 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             domain_name  domain_id   avg_maf_all  avg_maf_altered  \\\n",
       "Ank_2_1            Ank_2         30  1.043970e-05         0.000092   \n",
       "Ank_2_10           Ank_2         30  7.688770e-05         0.000322   \n",
       "Ank_2_11           Ank_2         30  1.313852e-03         0.006237   \n",
       "Ank_2_12           Ank_2         30  1.952458e-05         0.000092   \n",
       "Ank_2_13           Ank_2         30  2.022685e-05         0.000082   \n",
       "Ank_2_14           Ank_2         30  4.530364e-05         0.000168   \n",
       "Ank_2_15           Ank_2         30  1.520644e-05         0.000075   \n",
       "Ank_2_16           Ank_2         30  3.023469e-06         0.000026   \n",
       "Ank_2_17           Ank_2         30  1.550392e-04         0.001269   \n",
       "Ank_2_18           Ank_2         30  3.539555e-04         0.001501   \n",
       "Ank_2_19           Ank_2         30  1.446111e-04         0.000675   \n",
       "Ank_2_2            Ank_2         30  4.205822e-06         0.000025   \n",
       "Ank_2_20           Ank_2         30  6.640060e-05         0.000307   \n",
       "Ank_2_21           Ank_2         30  1.908081e-05         0.000081   \n",
       "Ank_2_22           Ank_2         30  2.707870e-04         0.001189   \n",
       "Ank_2_23           Ank_2         30  9.112719e-05         0.000465   \n",
       "Ank_2_24           Ank_2         30  5.297169e-06         0.000032   \n",
       "Ank_2_25           Ank_2         30  1.941653e-05         0.000094   \n",
       "Ank_2_26           Ank_2         30  1.906565e-05         0.000089   \n",
       "Ank_2_27           Ank_2         30  6.824880e-06         0.000039   \n",
       "Ank_2_28           Ank_2         30  7.452490e-06         0.000044   \n",
       "Ank_2_29           Ank_2         30  3.949348e-06         0.000023   \n",
       "Ank_2_3            Ank_2         30  1.087332e-05         0.000056   \n",
       "Ank_2_30           Ank_2         30  3.687819e-06         0.000035   \n",
       "Ank_2_31           Ank_2         30  8.499627e-05         0.000594   \n",
       "Ank_2_32           Ank_2         30  8.017989e-05         0.000406   \n",
       "Ank_2_33           Ank_2         30  1.486238e-05         0.000075   \n",
       "Ank_2_34           Ank_2         30  1.013579e-05         0.000059   \n",
       "Ank_2_35           Ank_2         30  7.821457e-04         0.004212   \n",
       "Ank_2_36           Ank_2         30  7.584657e-06         0.000037   \n",
       "...                  ...        ...           ...              ...   \n",
       "zf-CCCH_6        zf-CCCH         47  1.440143e-06         0.000023   \n",
       "zf-CCCH_7        zf-CCCH         47  1.843535e-05         0.000129   \n",
       "zf-CCCH_8        zf-CCCH         47  2.993328e-06         0.000035   \n",
       "zf-CCCH_9        zf-CCCH         47  1.573349e-06         0.000025   \n",
       "zf-H2C2_5_1    zf-H2C2_5         44  1.501324e-06         0.000011   \n",
       "zf-H2C2_5_10   zf-H2C2_5         44  4.653985e-06         0.000040   \n",
       "zf-H2C2_5_11   zf-H2C2_5         44  1.002004e-03         0.004542   \n",
       "zf-H2C2_5_12   zf-H2C2_5         44  5.673632e-06         0.000055   \n",
       "zf-H2C2_5_13   zf-H2C2_5         44  3.010735e-06         0.000020   \n",
       "zf-H2C2_5_14   zf-H2C2_5         44  1.583309e-06         0.000012   \n",
       "zf-H2C2_5_15   zf-H2C2_5         44  2.676544e-06         0.000030   \n",
       "zf-H2C2_5_16   zf-H2C2_5         44  7.302647e-07         0.000010   \n",
       "zf-H2C2_5_17   zf-H2C2_5         44  1.096259e-05         0.000083   \n",
       "zf-H2C2_5_18   zf-H2C2_5         44  4.391794e-06         0.000019   \n",
       "zf-H2C2_5_19   zf-H2C2_5         44  1.020809e-06         0.000010   \n",
       "zf-H2C2_5_2    zf-H2C2_5         44  5.141485e-06         0.000025   \n",
       "zf-H2C2_5_20   zf-H2C2_5         44  3.503735e-06         0.000024   \n",
       "zf-H2C2_5_21   zf-H2C2_5         44  5.256559e-06         0.000019   \n",
       "zf-H2C2_5_22   zf-H2C2_5         44  2.907714e-06         0.000015   \n",
       "zf-H2C2_5_23   zf-H2C2_5         44  3.906925e-06         0.000020   \n",
       "zf-H2C2_5_24   zf-H2C2_5         44  6.183824e-07         0.000008   \n",
       "zf-H2C2_5_25   zf-H2C2_5         44  6.259176e-06         0.000039   \n",
       "zf-H2C2_5_26   zf-H2C2_5         44  6.196382e-06         0.000053   \n",
       "zf-H2C2_5_3    zf-H2C2_5         44  1.824897e-06         0.000012   \n",
       "zf-H2C2_5_4    zf-H2C2_5         44  4.035109e-05         0.000144   \n",
       "zf-H2C2_5_5    zf-H2C2_5         44  3.782912e-06         0.000023   \n",
       "zf-H2C2_5_6    zf-H2C2_5         44  2.071103e-06         0.000028   \n",
       "zf-H2C2_5_7    zf-H2C2_5         44  4.870485e-06         0.000022   \n",
       "zf-H2C2_5_8    zf-H2C2_5         44  6.703294e-06         0.000038   \n",
       "zf-H2C2_5_9    zf-H2C2_5         44  3.416853e-06         0.000019   \n",
       "\n",
       "              maf_hist_0-0.001  maf_hist_0.001-0.005  maf_hist_0.005-0.01  \\\n",
       "Ank_2_1                     49                     2                    0   \n",
       "Ank_2_10                   101                     0                    1   \n",
       "Ank_2_11                    88                     1                    0   \n",
       "Ank_2_12                    93                     2                    0   \n",
       "Ank_2_13                   109                     2                    0   \n",
       "Ank_2_14                   116                     4                    1   \n",
       "Ank_2_15                    90                     1                    0   \n",
       "Ank_2_16                    52                     0                    0   \n",
       "Ank_2_17                    52                     0                    0   \n",
       "Ank_2_18                   100                     2                    1   \n",
       "Ank_2_19                    92                     2                    0   \n",
       "Ank_2_2                     76                     0                    0   \n",
       "Ank_2_20                    95                     1                    0   \n",
       "Ank_2_21                   104                     2                    0   \n",
       "Ank_2_22                    99                     2                    0   \n",
       "Ank_2_23                    84                     3                    0   \n",
       "Ank_2_24                    72                     0                    0   \n",
       "Ank_2_25                    88                     2                    0   \n",
       "Ank_2_26                    93                     1                    0   \n",
       "Ank_2_27                    78                     0                    0   \n",
       "Ank_2_28                    77                     0                    0   \n",
       "Ank_2_29                    79                     0                    0   \n",
       "Ank_2_3                     86                     1                    0   \n",
       "Ank_2_30                    47                     0                    0   \n",
       "Ank_2_31                    63                     0                    0   \n",
       "Ank_2_32                    86                     0                    1   \n",
       "Ank_2_33                    86                     2                    0   \n",
       "Ank_2_34                    76                     1                    0   \n",
       "Ank_2_35                    80                     2                    0   \n",
       "Ank_2_36                    92                     0                    0   \n",
       "...                        ...                   ...                  ...   \n",
       "zf-CCCH_6                    4                     0                    0   \n",
       "zf-CCCH_7                    9                     0                    0   \n",
       "zf-CCCH_8                    5                     0                    0   \n",
       "zf-CCCH_9                    4                     0                    0   \n",
       "zf-H2C2_5_1                  9                     0                    0   \n",
       "zf-H2C2_5_10                 8                     0                    0   \n",
       "zf-H2C2_5_11                13                     1                    0   \n",
       "zf-H2C2_5_12                 7                     0                    0   \n",
       "zf-H2C2_5_13                10                     0                    0   \n",
       "zf-H2C2_5_14                 9                     0                    0   \n",
       "zf-H2C2_5_15                 6                     0                    0   \n",
       "zf-H2C2_5_16                 5                     0                    0   \n",
       "zf-H2C2_5_17                 9                     0                    0   \n",
       "zf-H2C2_5_18                16                     0                    0   \n",
       "zf-H2C2_5_19                 7                     0                    0   \n",
       "zf-H2C2_5_2                 14                     0                    0   \n",
       "zf-H2C2_5_20                10                     0                    0   \n",
       "zf-H2C2_5_21                19                     0                    0   \n",
       "zf-H2C2_5_22                 4                     0                    0   \n",
       "zf-H2C2_5_23                13                     0                    0   \n",
       "zf-H2C2_5_24                 5                     0                    0   \n",
       "zf-H2C2_5_25                11                     0                    0   \n",
       "zf-H2C2_5_26                 8                     0                    0   \n",
       "zf-H2C2_5_3                 10                     0                    0   \n",
       "zf-H2C2_5_4                 18                     1                    0   \n",
       "zf-H2C2_5_5                 11                     0                    0   \n",
       "zf-H2C2_5_6                  5                     0                    0   \n",
       "zf-H2C2_5_7                 15                     0                    0   \n",
       "zf-H2C2_5_8                 12                     0                    0   \n",
       "zf-H2C2_5_9                 12                     0                    0   \n",
       "\n",
       "              maf_hist_0.01-0.02  maf_hist_0.02-0.04  maf_hist_0.04-0.06  \\\n",
       "Ank_2_1                        0                   0                   0   \n",
       "Ank_2_10                       0                   1                   0   \n",
       "Ank_2_11                       0                   0                   0   \n",
       "Ank_2_12                       0                   0                   0   \n",
       "Ank_2_13                       0                   0                   0   \n",
       "Ank_2_14                       0                   0                   0   \n",
       "Ank_2_15                       0                   0                   0   \n",
       "Ank_2_16                       0                   0                   0   \n",
       "Ank_2_17                       2                   0                   1   \n",
       "Ank_2_18                       0                   0                   0   \n",
       "Ank_2_19                       0                   2                   0   \n",
       "Ank_2_2                        0                   0                   0   \n",
       "Ank_2_20                       0                   1                   0   \n",
       "Ank_2_21                       0                   0                   0   \n",
       "Ank_2_22                       0                   0                   0   \n",
       "Ank_2_23                       0                   1                   0   \n",
       "Ank_2_24                       0                   0                   0   \n",
       "Ank_2_25                       0                   0                   0   \n",
       "Ank_2_26                       0                   0                   0   \n",
       "Ank_2_27                       0                   0                   0   \n",
       "Ank_2_28                       0                   0                   0   \n",
       "Ank_2_29                       0                   0                   0   \n",
       "Ank_2_3                        0                   0                   0   \n",
       "Ank_2_30                       0                   0                   0   \n",
       "Ank_2_31                       0                   1                   0   \n",
       "Ank_2_32                       0                   1                   0   \n",
       "Ank_2_33                       0                   0                   0   \n",
       "Ank_2_34                       0                   0                   0   \n",
       "Ank_2_35                       0                   0                   0   \n",
       "Ank_2_36                       0                   0                   0   \n",
       "...                          ...                 ...                 ...   \n",
       "zf-CCCH_6                      0                   0                   0   \n",
       "zf-CCCH_7                      0                   0                   0   \n",
       "zf-CCCH_8                      0                   0                   0   \n",
       "zf-CCCH_9                      0                   0                   0   \n",
       "zf-H2C2_5_1                    0                   0                   0   \n",
       "zf-H2C2_5_10                   0                   0                   0   \n",
       "zf-H2C2_5_11                   0                   0                   0   \n",
       "zf-H2C2_5_12                   0                   0                   0   \n",
       "zf-H2C2_5_13                   0                   0                   0   \n",
       "zf-H2C2_5_14                   0                   0                   0   \n",
       "zf-H2C2_5_15                   0                   0                   0   \n",
       "zf-H2C2_5_16                   0                   0                   0   \n",
       "zf-H2C2_5_17                   0                   0                   0   \n",
       "zf-H2C2_5_18                   0                   0                   0   \n",
       "zf-H2C2_5_19                   0                   0                   0   \n",
       "zf-H2C2_5_2                    0                   0                   0   \n",
       "zf-H2C2_5_20                   0                   0                   0   \n",
       "zf-H2C2_5_21                   0                   0                   0   \n",
       "zf-H2C2_5_22                   0                   0                   0   \n",
       "zf-H2C2_5_23                   0                   0                   0   \n",
       "zf-H2C2_5_24                   0                   0                   0   \n",
       "zf-H2C2_5_25                   0                   0                   0   \n",
       "zf-H2C2_5_26                   0                   0                   0   \n",
       "zf-H2C2_5_3                    0                   0                   0   \n",
       "zf-H2C2_5_4                    0                   0                   0   \n",
       "zf-H2C2_5_5                    0                   0                   0   \n",
       "zf-H2C2_5_6                    0                   0                   0   \n",
       "zf-H2C2_5_7                    0                   0                   0   \n",
       "zf-H2C2_5_8                    0                   0                   0   \n",
       "zf-H2C2_5_9                    0                   0                   0   \n",
       "\n",
       "                      ...            GO:SIGNAL_TRANSDUCTION  domain_pos  \\\n",
       "Ank_2_1               ...                                 0           1   \n",
       "Ank_2_10              ...                                 0          10   \n",
       "Ank_2_11              ...                                 0          11   \n",
       "Ank_2_12              ...                                 0          12   \n",
       "Ank_2_13              ...                                 0          13   \n",
       "Ank_2_14              ...                                 0          14   \n",
       "Ank_2_15              ...                                 0          15   \n",
       "Ank_2_16              ...                                 0          16   \n",
       "Ank_2_17              ...                                 0          17   \n",
       "Ank_2_18              ...                                 0          18   \n",
       "Ank_2_19              ...                                 0          19   \n",
       "Ank_2_2               ...                                 0           2   \n",
       "Ank_2_20              ...                                 0          20   \n",
       "Ank_2_21              ...                                 0          21   \n",
       "Ank_2_22              ...                                 0          22   \n",
       "Ank_2_23              ...                                 0          23   \n",
       "Ank_2_24              ...                                 0          24   \n",
       "Ank_2_25              ...                                 0          25   \n",
       "Ank_2_26              ...                                 0          26   \n",
       "Ank_2_27              ...                                 0          27   \n",
       "Ank_2_28              ...                                 0          28   \n",
       "Ank_2_29              ...                                 0          29   \n",
       "Ank_2_3               ...                                 0           3   \n",
       "Ank_2_30              ...                                 0          30   \n",
       "Ank_2_31              ...                                 0          31   \n",
       "Ank_2_32              ...                                 0          32   \n",
       "Ank_2_33              ...                                 0          33   \n",
       "Ank_2_34              ...                                 0          34   \n",
       "Ank_2_35              ...                                 0          35   \n",
       "Ank_2_36              ...                                 0          36   \n",
       "...                   ...                               ...         ...   \n",
       "zf-CCCH_6             ...                                 0           6   \n",
       "zf-CCCH_7             ...                                 0           7   \n",
       "zf-CCCH_8             ...                                 0           8   \n",
       "zf-CCCH_9             ...                                 0           9   \n",
       "zf-H2C2_5_1           ...                                 0           1   \n",
       "zf-H2C2_5_10          ...                                 0          10   \n",
       "zf-H2C2_5_11          ...                                 0          11   \n",
       "zf-H2C2_5_12          ...                                 0          12   \n",
       "zf-H2C2_5_13          ...                                 0          13   \n",
       "zf-H2C2_5_14          ...                                 0          14   \n",
       "zf-H2C2_5_15          ...                                 0          15   \n",
       "zf-H2C2_5_16          ...                                 0          16   \n",
       "zf-H2C2_5_17          ...                                 0          17   \n",
       "zf-H2C2_5_18          ...                                 0          18   \n",
       "zf-H2C2_5_19          ...                                 0          19   \n",
       "zf-H2C2_5_2           ...                                 0           2   \n",
       "zf-H2C2_5_20          ...                                 0          20   \n",
       "zf-H2C2_5_21          ...                                 0          21   \n",
       "zf-H2C2_5_22          ...                                 0          22   \n",
       "zf-H2C2_5_23          ...                                 0          23   \n",
       "zf-H2C2_5_24          ...                                 0          24   \n",
       "zf-H2C2_5_25          ...                                 0          25   \n",
       "zf-H2C2_5_26          ...                                 0          26   \n",
       "zf-H2C2_5_3           ...                                 0           3   \n",
       "zf-H2C2_5_4           ...                                 0           4   \n",
       "zf-H2C2_5_5           ...                                 0           5   \n",
       "zf-H2C2_5_6           ...                                 0           6   \n",
       "zf-H2C2_5_7           ...                                 0           7   \n",
       "zf-H2C2_5_8           ...                                 0           8   \n",
       "zf-H2C2_5_9           ...                                 0           9   \n",
       "\n",
       "              domain_length  domain_pos_location_begin  \\\n",
       "Ank_2_1                  83                          1   \n",
       "Ank_2_10                 83                          1   \n",
       "Ank_2_11                 83                          1   \n",
       "Ank_2_12                 83                          1   \n",
       "Ank_2_13                 83                          1   \n",
       "Ank_2_14                 83                          1   \n",
       "Ank_2_15                 83                          1   \n",
       "Ank_2_16                 83                          1   \n",
       "Ank_2_17                 83                          1   \n",
       "Ank_2_18                 83                          1   \n",
       "Ank_2_19                 83                          1   \n",
       "Ank_2_2                  83                          1   \n",
       "Ank_2_20                 83                          1   \n",
       "Ank_2_21                 83                          1   \n",
       "Ank_2_22                 83                          1   \n",
       "Ank_2_23                 83                          1   \n",
       "Ank_2_24                 83                          1   \n",
       "Ank_2_25                 83                          1   \n",
       "Ank_2_26                 83                          1   \n",
       "Ank_2_27                 83                          1   \n",
       "Ank_2_28                 83                          0   \n",
       "Ank_2_29                 83                          0   \n",
       "Ank_2_3                  83                          1   \n",
       "Ank_2_30                 83                          0   \n",
       "Ank_2_31                 83                          0   \n",
       "Ank_2_32                 83                          0   \n",
       "Ank_2_33                 83                          0   \n",
       "Ank_2_34                 83                          0   \n",
       "Ank_2_35                 83                          0   \n",
       "Ank_2_36                 83                          0   \n",
       "...                     ...                        ...   \n",
       "zf-CCCH_6                27                          1   \n",
       "zf-CCCH_7                27                          1   \n",
       "zf-CCCH_8                27                          1   \n",
       "zf-CCCH_9                27                          1   \n",
       "zf-H2C2_5_1              26                          1   \n",
       "zf-H2C2_5_10             26                          0   \n",
       "zf-H2C2_5_11             26                          0   \n",
       "zf-H2C2_5_12             26                          0   \n",
       "zf-H2C2_5_13             26                          0   \n",
       "zf-H2C2_5_14             26                          0   \n",
       "zf-H2C2_5_15             26                          0   \n",
       "zf-H2C2_5_16             26                          0   \n",
       "zf-H2C2_5_17             26                          0   \n",
       "zf-H2C2_5_18             26                          0   \n",
       "zf-H2C2_5_19             26                          0   \n",
       "zf-H2C2_5_2              26                          1   \n",
       "zf-H2C2_5_20             26                          0   \n",
       "zf-H2C2_5_21             26                          0   \n",
       "zf-H2C2_5_22             26                          0   \n",
       "zf-H2C2_5_23             26                          0   \n",
       "zf-H2C2_5_24             26                          0   \n",
       "zf-H2C2_5_25             26                          0   \n",
       "zf-H2C2_5_26             26                          0   \n",
       "zf-H2C2_5_3              26                          1   \n",
       "zf-H2C2_5_4              26                          1   \n",
       "zf-H2C2_5_5              26                          1   \n",
       "zf-H2C2_5_6              26                          1   \n",
       "zf-H2C2_5_7              26                          1   \n",
       "zf-H2C2_5_8              26                          1   \n",
       "zf-H2C2_5_9              26                          0   \n",
       "\n",
       "              domain_pos_location_middle  domain_pos_location_end  \\\n",
       "Ank_2_1                                0                        0   \n",
       "Ank_2_10                               0                        0   \n",
       "Ank_2_11                               0                        0   \n",
       "Ank_2_12                               0                        0   \n",
       "Ank_2_13                               0                        0   \n",
       "Ank_2_14                               0                        0   \n",
       "Ank_2_15                               0                        0   \n",
       "Ank_2_16                               0                        0   \n",
       "Ank_2_17                               0                        0   \n",
       "Ank_2_18                               0                        0   \n",
       "Ank_2_19                               0                        0   \n",
       "Ank_2_2                                0                        0   \n",
       "Ank_2_20                               0                        0   \n",
       "Ank_2_21                               0                        0   \n",
       "Ank_2_22                               0                        0   \n",
       "Ank_2_23                               0                        0   \n",
       "Ank_2_24                               0                        0   \n",
       "Ank_2_25                               0                        0   \n",
       "Ank_2_26                               0                        0   \n",
       "Ank_2_27                               0                        0   \n",
       "Ank_2_28                               1                        0   \n",
       "Ank_2_29                               1                        0   \n",
       "Ank_2_3                                0                        0   \n",
       "Ank_2_30                               1                        0   \n",
       "Ank_2_31                               1                        0   \n",
       "Ank_2_32                               1                        0   \n",
       "Ank_2_33                               1                        0   \n",
       "Ank_2_34                               1                        0   \n",
       "Ank_2_35                               1                        0   \n",
       "Ank_2_36                               1                        0   \n",
       "...                                  ...                      ...   \n",
       "zf-CCCH_6                              0                        0   \n",
       "zf-CCCH_7                              0                        0   \n",
       "zf-CCCH_8                              0                        0   \n",
       "zf-CCCH_9                              0                        0   \n",
       "zf-H2C2_5_1                            0                        0   \n",
       "zf-H2C2_5_10                           1                        0   \n",
       "zf-H2C2_5_11                           1                        0   \n",
       "zf-H2C2_5_12                           1                        0   \n",
       "zf-H2C2_5_13                           1                        0   \n",
       "zf-H2C2_5_14                           1                        0   \n",
       "zf-H2C2_5_15                           1                        0   \n",
       "zf-H2C2_5_16                           1                        0   \n",
       "zf-H2C2_5_17                           1                        0   \n",
       "zf-H2C2_5_18                           0                        1   \n",
       "zf-H2C2_5_19                           0                        1   \n",
       "zf-H2C2_5_2                            0                        0   \n",
       "zf-H2C2_5_20                           0                        1   \n",
       "zf-H2C2_5_21                           0                        1   \n",
       "zf-H2C2_5_22                           0                        1   \n",
       "zf-H2C2_5_23                           0                        1   \n",
       "zf-H2C2_5_24                           0                        1   \n",
       "zf-H2C2_5_25                           0                        1   \n",
       "zf-H2C2_5_26                           0                        1   \n",
       "zf-H2C2_5_3                            0                        0   \n",
       "zf-H2C2_5_4                            0                        0   \n",
       "zf-H2C2_5_5                            0                        0   \n",
       "zf-H2C2_5_6                            0                        0   \n",
       "zf-H2C2_5_7                            0                        0   \n",
       "zf-H2C2_5_8                            0                        0   \n",
       "zf-H2C2_5_9                            1                        0   \n",
       "\n",
       "              prot_avg_length  prot_pos_location_begin  \\\n",
       "Ank_2_1           1111.291111                        0   \n",
       "Ank_2_10          1109.187500                        0   \n",
       "Ank_2_11          1110.069444                        0   \n",
       "Ank_2_12          1112.543430                        0   \n",
       "Ank_2_13          1112.543430                        0   \n",
       "Ank_2_14          1111.291111                        0   \n",
       "Ank_2_15          1111.291111                        0   \n",
       "Ank_2_16          1111.291111                        0   \n",
       "Ank_2_17          1111.291111                        0   \n",
       "Ank_2_18          1112.736961                        0   \n",
       "Ank_2_19          1114.604911                        0   \n",
       "Ank_2_2           1111.291111                        0   \n",
       "Ank_2_20          1114.604911                        0   \n",
       "Ank_2_21          1113.057906                        0   \n",
       "Ank_2_22          1112.524554                        0   \n",
       "Ank_2_23          1113.057906                        0   \n",
       "Ank_2_24          1120.120370                        0   \n",
       "Ank_2_25          1105.825287                        0   \n",
       "Ank_2_26          1103.897260                        0   \n",
       "Ank_2_27          1119.902935                        0   \n",
       "Ank_2_28          1111.516630                        0   \n",
       "Ank_2_29          1111.516630                        0   \n",
       "Ank_2_3           1111.291111                        0   \n",
       "Ank_2_30          1106.355705                        0   \n",
       "Ank_2_31          1106.355705                        0   \n",
       "Ank_2_32          1108.464126                        0   \n",
       "Ank_2_33          1106.355705                        0   \n",
       "Ank_2_34          1106.355705                        0   \n",
       "Ank_2_35          1106.355705                        0   \n",
       "Ank_2_36          1108.526906                        0   \n",
       "...                       ...                      ...   \n",
       "zf-CCCH_6          626.984127                        0   \n",
       "zf-CCCH_7          626.984127                        0   \n",
       "zf-CCCH_8          617.500000                        0   \n",
       "zf-CCCH_9          626.984127                        0   \n",
       "zf-H2C2_5_1       1009.044118                        0   \n",
       "zf-H2C2_5_10      1009.044118                        0   \n",
       "zf-H2C2_5_11      1009.044118                        0   \n",
       "zf-H2C2_5_12      1009.044118                        0   \n",
       "zf-H2C2_5_13      1009.044118                        0   \n",
       "zf-H2C2_5_14      1009.044118                        0   \n",
       "zf-H2C2_5_15      1009.044118                        0   \n",
       "zf-H2C2_5_16      1009.044118                        0   \n",
       "zf-H2C2_5_17      1009.044118                        0   \n",
       "zf-H2C2_5_18      1009.044118                        0   \n",
       "zf-H2C2_5_19      1009.044118                        0   \n",
       "zf-H2C2_5_2       1009.044118                        0   \n",
       "zf-H2C2_5_20      1009.044118                        0   \n",
       "zf-H2C2_5_21      1009.044118                        0   \n",
       "zf-H2C2_5_22      1085.809524                        0   \n",
       "zf-H2C2_5_23       990.552239                        0   \n",
       "zf-H2C2_5_24      1009.044118                        0   \n",
       "zf-H2C2_5_25      1009.044118                        0   \n",
       "zf-H2C2_5_26      1009.044118                        0   \n",
       "zf-H2C2_5_3       1009.044118                        0   \n",
       "zf-H2C2_5_4       1009.044118                        0   \n",
       "zf-H2C2_5_5       1009.044118                        0   \n",
       "zf-H2C2_5_6       1009.044118                        0   \n",
       "zf-H2C2_5_7       1009.044118                        0   \n",
       "zf-H2C2_5_8       1009.044118                        0   \n",
       "zf-H2C2_5_9       1009.044118                        0   \n",
       "\n",
       "              prot_pos_location_middle  prot_pos_location_end  \n",
       "Ank_2_1                              0                      0  \n",
       "Ank_2_10                             0                      0  \n",
       "Ank_2_11                             0                      0  \n",
       "Ank_2_12                             0                      0  \n",
       "Ank_2_13                             0                      0  \n",
       "Ank_2_14                             0                      0  \n",
       "Ank_2_15                             0                      0  \n",
       "Ank_2_16                             0                      0  \n",
       "Ank_2_17                             0                      0  \n",
       "Ank_2_18                             0                      0  \n",
       "Ank_2_19                             0                      0  \n",
       "Ank_2_2                              0                      0  \n",
       "Ank_2_20                             0                      0  \n",
       "Ank_2_21                             0                      0  \n",
       "Ank_2_22                             0                      0  \n",
       "Ank_2_23                             0                      0  \n",
       "Ank_2_24                             0                      0  \n",
       "Ank_2_25                             0                      0  \n",
       "Ank_2_26                             0                      0  \n",
       "Ank_2_27                             0                      0  \n",
       "Ank_2_28                             0                      0  \n",
       "Ank_2_29                             0                      0  \n",
       "Ank_2_3                              0                      0  \n",
       "Ank_2_30                             0                      0  \n",
       "Ank_2_31                             0                      0  \n",
       "Ank_2_32                             0                      0  \n",
       "Ank_2_33                             0                      0  \n",
       "Ank_2_34                             0                      0  \n",
       "Ank_2_35                             0                      0  \n",
       "Ank_2_36                             0                      0  \n",
       "...                                ...                    ...  \n",
       "zf-CCCH_6                            0                      0  \n",
       "zf-CCCH_7                            0                      0  \n",
       "zf-CCCH_8                            0                      0  \n",
       "zf-CCCH_9                            0                      0  \n",
       "zf-H2C2_5_1                          0                      0  \n",
       "zf-H2C2_5_10                         0                      0  \n",
       "zf-H2C2_5_11                         0                      0  \n",
       "zf-H2C2_5_12                         0                      0  \n",
       "zf-H2C2_5_13                         0                      0  \n",
       "zf-H2C2_5_14                         0                      0  \n",
       "zf-H2C2_5_15                         0                      0  \n",
       "zf-H2C2_5_16                         0                      0  \n",
       "zf-H2C2_5_17                         0                      0  \n",
       "zf-H2C2_5_18                         0                      0  \n",
       "zf-H2C2_5_19                         0                      0  \n",
       "zf-H2C2_5_2                          0                      0  \n",
       "zf-H2C2_5_20                         0                      0  \n",
       "zf-H2C2_5_21                         0                      0  \n",
       "zf-H2C2_5_22                         0                      0  \n",
       "zf-H2C2_5_23                         0                      0  \n",
       "zf-H2C2_5_24                         0                      0  \n",
       "zf-H2C2_5_25                         0                      0  \n",
       "zf-H2C2_5_26                         0                      0  \n",
       "zf-H2C2_5_3                          0                      0  \n",
       "zf-H2C2_5_4                          0                      0  \n",
       "zf-H2C2_5_5                          0                      0  \n",
       "zf-H2C2_5_6                          0                      0  \n",
       "zf-H2C2_5_7                          0                      0  \n",
       "zf-H2C2_5_8                          0                      0  \n",
       "zf-H2C2_5_9                          0                      0  \n",
       "\n",
       "[7102 rows x 442 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exporting to data-frames table\n",
    "domains_features_df = pd.DataFrame.from_dict(features_dict,orient='index')\n",
    "domains_features_df.columns = table_columns\n",
    "domains_features_df = domains_features_df.sort_index()\n",
    "#Save to file\n",
    "if (TEST_PROCCESSED_DOMAINS):\n",
    "    domains_features_df.to_csv(curr_dir[0]+\"/features_tables_v\"+pfam_version+\"/positions_features_less_than_10_\"+datetime.date.today().strftime(\"%m.%d.%y\")+\".csv\", sep='\\t')\n",
    "else:\n",
    "    domains_features_df.to_csv(curr_dir[0]+\"/features_tables_v\"+pfam_version+\"/positions_features_fixed_\"+datetime.date.today().strftime(\"%m.%d.%y\")+\".csv\", sep='\\t')\n",
    "domains_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7102, 442)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking table features doesn't have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_path = \"/home/anat/Research/ExAC/9.Features_exploration/binding_df/10/\"\n",
    "# filename = \"positions_features_01.25.18.csv\"\n",
    "# domains_features_df = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "for col in domains_features_df.columns:\n",
    "    if (col == \"domain_name\"):\n",
    "        continue\n",
    "    nan_idx = np.where(np.isnan(domains_features_df[col].tolist()) == True)[0]\n",
    "    if (len(nan_idx) > 0):\n",
    "        print col+\" has NaNs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"31\"\n",
    "domains_features_df = pd.read_csv(curr_dir[0]+\"/features_tables_v\"+pfam_version+\"/positions_features_less_than_10_01.22.19.csv\", sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "502 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['domain_name',\n",
       " 'domain_id',\n",
       " 'avg_maf_all',\n",
       " 'avg_maf_altered',\n",
       " 'maf_hist_0-0.001',\n",
       " 'maf_hist_0.001-0.005',\n",
       " 'maf_hist_0.005-0.01',\n",
       " 'maf_hist_0.01-0.02',\n",
       " 'maf_hist_0.02-0.04',\n",
       " 'maf_hist_0.04-0.06',\n",
       " 'maf_hist_0.06-0.08',\n",
       " 'maf_hist_0.08-0.1',\n",
       " 'maf_hist_0.1-0.2',\n",
       " 'maf_hist_0.2-0.5',\n",
       " 'maf_afr',\n",
       " 'maf_amr',\n",
       " 'maf_eas',\n",
       " 'maf_fin',\n",
       " 'maf_nfe',\n",
       " 'maf_oth',\n",
       " 'maf_sas',\n",
       " 'maf_syn_afr',\n",
       " 'maf_syn_amr',\n",
       " 'maf_syn_eas',\n",
       " 'maf_syn_fin',\n",
       " 'maf_syn_nfe',\n",
       " 'maf_syn_oth',\n",
       " 'maf_syn_sas',\n",
       " 'maf_nonsyn_afr',\n",
       " 'maf_nonsyn_amr',\n",
       " 'maf_nonsyn_eas',\n",
       " 'maf_nonsyn_fin',\n",
       " 'maf_nonsyn_nfe',\n",
       " 'maf_nonsyn_oth',\n",
       " 'maf_nonsyn_sas',\n",
       " 'alter_num_aa',\n",
       " 'alter_num_aa_norm',\n",
       " 'alter_num_snp',\n",
       " 'alter_num_snp_norm',\n",
       " 'avg_aa_polymorphisms',\n",
       " 'frac_poly_aa',\n",
       " 'rare_poly_0.5',\n",
       " 'rare_poly_0.05',\n",
       " 'rare_poly_0.005',\n",
       " 'phastCons1_avg',\n",
       " 'phastCons2_avg',\n",
       " 'phastCons3_avg',\n",
       " 'phyloP1_avg',\n",
       " 'phyloP2_avg',\n",
       " 'phyloP3_avg',\n",
       " 'phastCons1_hist_0.0-0.25',\n",
       " 'phastCons1_hist_0.25-0.5',\n",
       " 'phastCons1_hist_0.5-0.75',\n",
       " 'phastCons1_hist_0.75-0.8',\n",
       " 'phastCons1_hist_0.8-0.8500000000000001',\n",
       " 'phastCons1_hist_0.8500000000000001-0.9',\n",
       " 'phastCons1_hist_0.9-0.95',\n",
       " 'phastCons1_hist_0.95-1.0',\n",
       " 'phastCons2_hist_0.0-0.25',\n",
       " 'phastCons2_hist_0.25-0.5',\n",
       " 'phastCons2_hist_0.5-0.75',\n",
       " 'phastCons2_hist_0.75-0.8',\n",
       " 'phastCons2_hist_0.8-0.8500000000000001',\n",
       " 'phastCons2_hist_0.8500000000000001-0.9',\n",
       " 'phastCons2_hist_0.9-0.95',\n",
       " 'phastCons2_hist_0.95-1.0',\n",
       " 'phastCons3_hist_0.0-0.25',\n",
       " 'phastCons3_hist_0.25-0.5',\n",
       " 'phastCons3_hist_0.5-0.75',\n",
       " 'phastCons3_hist_0.75-0.8',\n",
       " 'phastCons3_hist_0.8-0.8500000000000001',\n",
       " 'phastCons3_hist_0.8500000000000001-0.9',\n",
       " 'phastCons3_hist_0.9-0.95',\n",
       " 'phastCons3_hist_0.95-1.0',\n",
       " 'phyloP1_hist_-14.0--1.0',\n",
       " 'phyloP1_hist_-1.0-0.0',\n",
       " 'phyloP1_hist_0.0-1.0',\n",
       " 'phyloP1_hist_1.0-2.0',\n",
       " 'phyloP1_hist_2.0-3.0',\n",
       " 'phyloP1_hist_3.0-3.5',\n",
       " 'phyloP1_hist_3.5-4.0',\n",
       " 'phyloP1_hist_4.0-4.5',\n",
       " 'phyloP1_hist_4.5-5.0',\n",
       " 'phyloP1_hist_5.0-5.5',\n",
       " 'phyloP1_hist_5.5-6.0',\n",
       " 'phyloP2_hist_-14.0--1.0',\n",
       " 'phyloP2_hist_-1.0-0.0',\n",
       " 'phyloP2_hist_0.0-1.0',\n",
       " 'phyloP2_hist_1.0-2.0',\n",
       " 'phyloP2_hist_2.0-3.0',\n",
       " 'phyloP2_hist_3.0-3.5',\n",
       " 'phyloP2_hist_3.5-4.0',\n",
       " 'phyloP2_hist_4.0-4.5',\n",
       " 'phyloP2_hist_4.5-5.0',\n",
       " 'phyloP2_hist_5.0-5.5',\n",
       " 'phyloP2_hist_5.5-6.0',\n",
       " 'phyloP3_hist_-14.0--1.0',\n",
       " 'phyloP3_hist_-1.0-0.0',\n",
       " 'phyloP3_hist_0.0-1.0',\n",
       " 'phyloP3_hist_1.0-2.0',\n",
       " 'phyloP3_hist_2.0-3.0',\n",
       " 'phyloP3_hist_3.0-3.5',\n",
       " 'phyloP3_hist_3.5-4.0',\n",
       " 'phyloP3_hist_4.0-4.5',\n",
       " 'phyloP3_hist_4.5-5.0',\n",
       " 'phyloP3_hist_5.0-5.5',\n",
       " 'phyloP3_hist_5.5-6.0',\n",
       " 'phastCons_codons_hist_0.0-0.25',\n",
       " 'phastCons_codons_hist_0.25-0.5',\n",
       " 'phastCons_codons_hist_0.5-0.75',\n",
       " 'phastCons_codons_hist_0.75-0.8',\n",
       " 'phastCons_codons_hist_0.8-0.8500000000000001',\n",
       " 'phastCons_codons_hist_0.8500000000000001-0.9',\n",
       " 'phastCons_codons_hist_0.9-0.95',\n",
       " 'phastCons_codons_hist_0.95-1.0',\n",
       " 'phyloP_codons_hist_-14.0--1.0',\n",
       " 'phyloP_codons_hist_-1.0-0.0',\n",
       " 'phyloP_codons_hist_0.0-1.0',\n",
       " 'phyloP_codons_hist_1.0-2.0',\n",
       " 'phyloP_codons_hist_2.0-3.0',\n",
       " 'phyloP_codons_hist_3.0-3.5',\n",
       " 'phyloP_codons_hist_3.5-4.0',\n",
       " 'phyloP_codons_hist_4.0-4.5',\n",
       " 'phyloP_codons_hist_4.5-5.0',\n",
       " 'phyloP_codons_hist_5.0-5.5',\n",
       " 'phyloP_codons_hist_5.5-6.0',\n",
       " 'blosum_avg',\n",
       " 'blosum_avg_weighted',\n",
       " 'blosum_positive_num',\n",
       " 'blosum_negative_num',\n",
       " 'blosum_ratio',\n",
       " 'pam_avg',\n",
       " 'pam_avg_weighted',\n",
       " 'pam_positive_num',\n",
       " 'pam_negative_num',\n",
       " 'pam_ratio',\n",
       " 'pseudo_nonsyn',\n",
       " 'pseudo_syn',\n",
       " 'pseudo_dNdS',\n",
       " 'pfam_prob_max',\n",
       " 'pfam_prob_A',\n",
       " 'pfam_prob_C',\n",
       " 'pfam_prob_D',\n",
       " 'pfam_prob_E',\n",
       " 'pfam_prob_F',\n",
       " 'pfam_prob_G',\n",
       " 'pfam_prob_H',\n",
       " 'pfam_prob_I',\n",
       " 'pfam_prob_K',\n",
       " 'pfam_prob_L',\n",
       " 'pfam_prob_M',\n",
       " 'pfam_prob_N',\n",
       " 'pfam_prob_P',\n",
       " 'pfam_prob_Q',\n",
       " 'pfam_prob_R',\n",
       " 'pfam_prob_S',\n",
       " 'pfam_prob_T',\n",
       " 'pfam_prob_V',\n",
       " 'pfam_prob_W',\n",
       " 'pfam_prob_Y',\n",
       " 'is_pfam_conserved',\n",
       " 'sift_avg',\n",
       " 'sift_avg_weighted',\n",
       " 'sift_deleterious_num',\n",
       " 'sift_tolerated_num',\n",
       " 'sift_ratio',\n",
       " 'sift_majority',\n",
       " 'polyphen_avg',\n",
       " 'polyphen_avg_weighted',\n",
       " 'polyphen_benign_num',\n",
       " 'polyphen_possibly_num',\n",
       " 'polyphen_probably_num',\n",
       " 'polyphen_majority',\n",
       " 'avg_clinvar_score',\n",
       " 'avg_clinvar_weighted',\n",
       " 'snp_nonsyn_entropy',\n",
       " 'instances_change_frac',\n",
       " 'aa_ref_SE',\n",
       " 'aa_ref_jsd',\n",
       " 'med_jsd_100way_blosum',\n",
       " 'jsd_median_hist_0-0.5',\n",
       " 'jsd_median_hist_0.5-0.6',\n",
       " 'jsd_median_hist_0.6-0.7',\n",
       " 'jsd_median_hist_0.7-0.8',\n",
       " 'jsd_median_hist_0.8-1',\n",
       " 'instances_individuals_change_ratio',\n",
       " 'jsd_100way_instances_major_ratio',\n",
       " 'jsd_mul_aa_ref_SE',\n",
       " 'jsd_SE_diff_ratio',\n",
       " 'jsd_SE_sum',\n",
       " 'SE_jsd_diff_ratio',\n",
       " 'jsds_ratio',\n",
       " 'jsds_subtraction',\n",
       " 'aa_ref_hist_A',\n",
       " 'aa_ref_hist_C',\n",
       " 'aa_ref_hist_D',\n",
       " 'aa_ref_hist_E',\n",
       " 'aa_ref_hist_F',\n",
       " 'aa_ref_hist_G',\n",
       " 'aa_ref_hist_H',\n",
       " 'aa_ref_hist_I',\n",
       " 'aa_ref_hist_K',\n",
       " 'aa_ref_hist_L',\n",
       " 'aa_ref_hist_M',\n",
       " 'aa_ref_hist_N',\n",
       " 'aa_ref_hist_P',\n",
       " 'aa_ref_hist_Q',\n",
       " 'aa_ref_hist_R',\n",
       " 'aa_ref_hist_S',\n",
       " 'aa_ref_hist_T',\n",
       " 'aa_ref_hist_V',\n",
       " 'aa_ref_hist_W',\n",
       " 'aa_ref_hist_Y',\n",
       " 'aa_ref_hist_*',\n",
       " 'aa_ref_prob_A',\n",
       " 'aa_ref_prob_C',\n",
       " 'aa_ref_prob_D',\n",
       " 'aa_ref_prob_E',\n",
       " 'aa_ref_prob_F',\n",
       " 'aa_ref_prob_G',\n",
       " 'aa_ref_prob_H',\n",
       " 'aa_ref_prob_I',\n",
       " 'aa_ref_prob_K',\n",
       " 'aa_ref_prob_L',\n",
       " 'aa_ref_prob_M',\n",
       " 'aa_ref_prob_N',\n",
       " 'aa_ref_prob_P',\n",
       " 'aa_ref_prob_Q',\n",
       " 'aa_ref_prob_R',\n",
       " 'aa_ref_prob_S',\n",
       " 'aa_ref_prob_T',\n",
       " 'aa_ref_prob_V',\n",
       " 'aa_ref_prob_W',\n",
       " 'aa_ref_prob_Y',\n",
       " 'aa_ref_prob_*',\n",
       " 'aa_ref_charge_positive_count',\n",
       " 'aa_ref_charge_negative_count',\n",
       " 'aa_ref_charge_neutral_count',\n",
       " 'aa_ref_charge_majority',\n",
       " 'hindex_avg',\n",
       " 'hindex_pos_cnt',\n",
       " 'hindex_neg_cnt',\n",
       " 'vol_avg',\n",
       " 'vol_tiny_cnt',\n",
       " 'vol_small_cnt',\n",
       " 'vol_big_cnt',\n",
       " 'aa_ref_aa_functional_group.ALIPHATIC_count',\n",
       " 'aa_ref_aa_functional_group.AROMATIC_count',\n",
       " 'aa_ref_aa_functional_group.NEGATIVE_count',\n",
       " 'aa_ref_aa_functional_group.POSITIVE_count',\n",
       " 'aa_ref_aa_functional_group.POLAR_count',\n",
       " 'aa_ref_alpha_prop_avg',\n",
       " 'aa_ref_beta_prop_avg',\n",
       " 'aa_ref_turn_prop_avg',\n",
       " 'aa_ref_alpha_is_majority',\n",
       " 'aa_ref_beta_is_majority',\n",
       " 'aa_ref_turn_is_majority',\n",
       " 'H_bond_donor_avg',\n",
       " 'H_bond_acceptor_avg',\n",
       " 'aa_alt_cnt_hist_A',\n",
       " 'aa_alt_cnt_hist_C',\n",
       " 'aa_alt_cnt_hist_D',\n",
       " 'aa_alt_cnt_hist_E',\n",
       " 'aa_alt_cnt_hist_F',\n",
       " 'aa_alt_cnt_hist_G',\n",
       " 'aa_alt_cnt_hist_H',\n",
       " 'aa_alt_cnt_hist_I',\n",
       " 'aa_alt_cnt_hist_K',\n",
       " 'aa_alt_cnt_hist_L',\n",
       " 'aa_alt_cnt_hist_M',\n",
       " 'aa_alt_cnt_hist_N',\n",
       " 'aa_alt_cnt_hist_P',\n",
       " 'aa_alt_cnt_hist_Q',\n",
       " 'aa_alt_cnt_hist_R',\n",
       " 'aa_alt_cnt_hist_S',\n",
       " 'aa_alt_cnt_hist_T',\n",
       " 'aa_alt_cnt_hist_V',\n",
       " 'aa_alt_cnt_hist_W',\n",
       " 'aa_alt_cnt_hist_Y',\n",
       " 'aa_alt_cnt_hist_*',\n",
       " 'aa_alt_cnt_prob_A',\n",
       " 'aa_alt_cnt_prob_C',\n",
       " 'aa_alt_cnt_prob_D',\n",
       " 'aa_alt_cnt_prob_E',\n",
       " 'aa_alt_cnt_prob_F',\n",
       " 'aa_alt_cnt_prob_G',\n",
       " 'aa_alt_cnt_prob_H',\n",
       " 'aa_alt_cnt_prob_I',\n",
       " 'aa_alt_cnt_prob_K',\n",
       " 'aa_alt_cnt_prob_L',\n",
       " 'aa_alt_cnt_prob_M',\n",
       " 'aa_alt_cnt_prob_N',\n",
       " 'aa_alt_cnt_prob_P',\n",
       " 'aa_alt_cnt_prob_Q',\n",
       " 'aa_alt_cnt_prob_R',\n",
       " 'aa_alt_cnt_prob_S',\n",
       " 'aa_alt_cnt_prob_T',\n",
       " 'aa_alt_cnt_prob_V',\n",
       " 'aa_alt_cnt_prob_W',\n",
       " 'aa_alt_cnt_prob_Y',\n",
       " 'aa_alt_cnt_prob_*',\n",
       " 'aa_alt_avg_freq_hist_A',\n",
       " 'aa_alt_avg_freq_hist_C',\n",
       " 'aa_alt_avg_freq_hist_D',\n",
       " 'aa_alt_avg_freq_hist_E',\n",
       " 'aa_alt_avg_freq_hist_F',\n",
       " 'aa_alt_avg_freq_hist_G',\n",
       " 'aa_alt_avg_freq_hist_H',\n",
       " 'aa_alt_avg_freq_hist_I',\n",
       " 'aa_alt_avg_freq_hist_K',\n",
       " 'aa_alt_avg_freq_hist_L',\n",
       " 'aa_alt_avg_freq_hist_M',\n",
       " 'aa_alt_avg_freq_hist_N',\n",
       " 'aa_alt_avg_freq_hist_P',\n",
       " 'aa_alt_avg_freq_hist_Q',\n",
       " 'aa_alt_avg_freq_hist_R',\n",
       " 'aa_alt_avg_freq_hist_S',\n",
       " 'aa_alt_avg_freq_hist_T',\n",
       " 'aa_alt_avg_freq_hist_V',\n",
       " 'aa_alt_avg_freq_hist_W',\n",
       " 'aa_alt_avg_freq_hist_Y',\n",
       " 'aa_alt_avg_freq_hist_*',\n",
       " 'aa_alt_avg_freq_prob_A',\n",
       " 'aa_alt_avg_freq_prob_C',\n",
       " 'aa_alt_avg_freq_prob_D',\n",
       " 'aa_alt_avg_freq_prob_E',\n",
       " 'aa_alt_avg_freq_prob_F',\n",
       " 'aa_alt_avg_freq_prob_G',\n",
       " 'aa_alt_avg_freq_prob_H',\n",
       " 'aa_alt_avg_freq_prob_I',\n",
       " 'aa_alt_avg_freq_prob_K',\n",
       " 'aa_alt_avg_freq_prob_L',\n",
       " 'aa_alt_avg_freq_prob_M',\n",
       " 'aa_alt_avg_freq_prob_N',\n",
       " 'aa_alt_avg_freq_prob_P',\n",
       " 'aa_alt_avg_freq_prob_Q',\n",
       " 'aa_alt_avg_freq_prob_R',\n",
       " 'aa_alt_avg_freq_prob_S',\n",
       " 'aa_alt_avg_freq_prob_T',\n",
       " 'aa_alt_avg_freq_prob_V',\n",
       " 'aa_alt_avg_freq_prob_W',\n",
       " 'aa_alt_avg_freq_prob_Y',\n",
       " 'aa_alt_avg_freq_prob_*',\n",
       " 'sub_diff_hindex_avg',\n",
       " 'sub_diff_hindex_avg_weighted',\n",
       " 'sub_diff_vol_avg',\n",
       " 'sub_diff_vol_avg_weighted',\n",
       " 'sub_func_group_stay_cnt',\n",
       " 'sub_func_group_stay_freq',\n",
       " 'sub_func_group_move_cnt',\n",
       " 'sub_func_group_move_freq',\n",
       " 'sub_func_group_trans_0-0',\n",
       " 'sub_func_group_trans_0-1',\n",
       " 'sub_func_group_trans_0-2',\n",
       " 'sub_func_group_trans_0-3',\n",
       " 'sub_func_group_trans_0-4',\n",
       " 'sub_func_group_trans_0-5',\n",
       " 'sub_func_group_trans_1-0',\n",
       " 'sub_func_group_trans_1-1',\n",
       " 'sub_func_group_trans_1-2',\n",
       " 'sub_func_group_trans_1-3',\n",
       " 'sub_func_group_trans_1-4',\n",
       " 'sub_func_group_trans_1-5',\n",
       " 'sub_func_group_trans_2-0',\n",
       " 'sub_func_group_trans_2-1',\n",
       " 'sub_func_group_trans_2-2',\n",
       " 'sub_func_group_trans_2-3',\n",
       " 'sub_func_group_trans_2-4',\n",
       " 'sub_func_group_trans_2-5',\n",
       " 'sub_func_group_trans_3-0',\n",
       " 'sub_func_group_trans_3-1',\n",
       " 'sub_func_group_trans_3-2',\n",
       " 'sub_func_group_trans_3-3',\n",
       " 'sub_func_group_trans_3-4',\n",
       " 'sub_func_group_trans_3-5',\n",
       " 'sub_func_group_trans_4-0',\n",
       " 'sub_func_group_trans_4-1',\n",
       " 'sub_func_group_trans_4-2',\n",
       " 'sub_func_group_trans_4-3',\n",
       " 'sub_func_group_trans_4-4',\n",
       " 'sub_func_group_trans_4-5',\n",
       " 'sub_diff_prop_avg_alpha',\n",
       " 'sub_diff_prop_avg_beta',\n",
       " 'sub_diff_prop_avg_turn',\n",
       " 'sub_diff_prop_avg_alpha_weighed',\n",
       " 'sub_diff_prop_avg_beta_weighed',\n",
       " 'sub_diff_prop_avg_turn_weighed',\n",
       " 'donor_diff_avg',\n",
       " 'donor_diff_avg_weighted',\n",
       " 'acceptor_diff_avg',\n",
       " 'acceptor_diff_avg_weighted',\n",
       " 'solvent_acc_avg',\n",
       " 'solvent_acc_std',\n",
       " 'hsa2_cn_avg',\n",
       " 'hsa2_cn_std',\n",
       " 'hsb2_cn_avg',\n",
       " 'hsb2_cn_std',\n",
       " 'backbone_Phi_angle_avg',\n",
       " 'backbone_Phi_angle_std',\n",
       " 'backbone_Psi_angle_avg',\n",
       " 'backbone_Psi_angle_std',\n",
       " 'c-alpha_tau_angle_avg',\n",
       " 'c-alph_tau_angle_std',\n",
       " 'c-alpha_theta_angle_avg',\n",
       " 'c-alph_theta_angle_std',\n",
       " 'helix_prob_avg',\n",
       " 'helix_prob_std',\n",
       " 'sheet_prob_avg',\n",
       " 'sheet_prob_std',\n",
       " 'turn_prob_avg',\n",
       " 'turn_prob_std',\n",
       " 'spd_helix_is_majority',\n",
       " 'spd_sheet_is_majority',\n",
       " 'spd_turn_is_majority',\n",
       " 'hsa2_HSE-up_avg',\n",
       " 'hsa2_HSE-up_std',\n",
       " 'hsa2_HSE-down_avg',\n",
       " 'hsa2_HSE-down_std',\n",
       " 'hsb2_HSE-up_avg',\n",
       " 'hsb2_HSE-up_std',\n",
       " 'hsb2_HSE-down_avg',\n",
       " 'hsb2_HSE-down_std',\n",
       " 'whole_domain_phastCons_avg',\n",
       " 'whole_domain_phastCons_std',\n",
       " 'whole_domain_phyloP_avg',\n",
       " 'whole_domain_phyloP_std',\n",
       " 'GO:NO_TERM',\n",
       " 'GO:NUCLEIC_ACID_BINDING',\n",
       " 'GO:PROTEIN_BINDING',\n",
       " 'GO:METAL_ION_BINDING',\n",
       " 'GO:MEMBRANE',\n",
       " 'GO:INTRACELLULAR',\n",
       " 'GO:SIGNAL_TRANSDUCTION',\n",
       " 'domain_pos',\n",
       " 'domain_length',\n",
       " 'domain_pos_location_begin',\n",
       " 'domain_pos_location_middle',\n",
       " 'domain_pos_location_end',\n",
       " 'prot_avg_length',\n",
       " 'prot_pos_location_begin',\n",
       " 'prot_pos_location_middle',\n",
       " 'prot_pos_location_end',\n",
       " 'dna_propensity',\n",
       " 'dna_prop_th_0.1',\n",
       " 'dna_prop_th_0.25',\n",
       " 'dna_prop_th_0.5',\n",
       " 'dna_prop_th_0.75',\n",
       " 'dnabase_propensity',\n",
       " 'dnabase_prop_th_0.1',\n",
       " 'dnabase_prop_th_0.25',\n",
       " 'dnabase_prop_th_0.5',\n",
       " 'dnabase_prop_th_0.75',\n",
       " 'dnabackbone_propensity',\n",
       " 'dnabackbone_prop_th_0.1',\n",
       " 'dnabackbone_prop_th_0.25',\n",
       " 'dnabackbone_prop_th_0.5',\n",
       " 'dnabackbone_prop_th_0.75',\n",
       " 'rna_propensity',\n",
       " 'rna_prop_th_0.1',\n",
       " 'rna_prop_th_0.25',\n",
       " 'rna_prop_th_0.5',\n",
       " 'rna_prop_th_0.75',\n",
       " 'rnabase_propensity',\n",
       " 'rnabase_prop_th_0.1',\n",
       " 'rnabase_prop_th_0.25',\n",
       " 'rnabase_prop_th_0.5',\n",
       " 'rnabase_prop_th_0.75',\n",
       " 'rnabackbone_propensity',\n",
       " 'rnabackbone_prop_th_0.1',\n",
       " 'rnabackbone_prop_th_0.25',\n",
       " 'rnabackbone_prop_th_0.5',\n",
       " 'rnabackbone_prop_th_0.75',\n",
       " 'peptide_propensity',\n",
       " 'peptide_prop_th_0.1',\n",
       " 'peptide_prop_th_0.25',\n",
       " 'peptide_prop_th_0.5',\n",
       " 'peptide_prop_th_0.75',\n",
       " 'ion_propensity',\n",
       " 'ion_prop_th_0.1',\n",
       " 'ion_prop_th_0.25',\n",
       " 'ion_prop_th_0.5',\n",
       " 'ion_prop_th_0.75',\n",
       " 'metabolite_propensity',\n",
       " 'metabolite_prop_th_0.1',\n",
       " 'metabolite_prop_th_0.25',\n",
       " 'metabolite_prop_th_0.5',\n",
       " 'metabolite_prop_th_0.75',\n",
       " 'sm_propensity',\n",
       " 'sm_prop_th_0.1',\n",
       " 'sm_prop_th_0.25',\n",
       " 'sm_prop_th_0.5',\n",
       " 'sm_prop_th_0.75',\n",
       " 'druglike_propensity',\n",
       " 'druglike_prop_th_0.1',\n",
       " 'druglike_prop_th_0.25',\n",
       " 'druglike_prop_th_0.5',\n",
       " 'druglike_prop_th_0.75',\n",
       " 'all_propensity',\n",
       " 'all_prop_th_0.1',\n",
       " 'all_prop_th_0.25',\n",
       " 'all_prop_th_0.5',\n",
       " 'all_prop_th_0.75']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains_features_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains_in_table = domains_features_df[\"domain_name\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COX2\n",
      "COX2_TM\n"
     ]
    }
   ],
   "source": [
    "for domain_name in domains:\n",
    "    if (domain_name not in domains_in_table):\n",
    "        print domain_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking input features doesn't have Infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-5fb02ac7f3e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"domain_name\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0minf_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdomains_features_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minf_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\" has Inf\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isinf' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "for col in domains_features_df.columns:\n",
    "    if (col == \"domain_name\"):\n",
    "        continue\n",
    "    inf_idx = np.where(np.isinf(domains_features_df[col].tolist()) == True)[0]\n",
    "    if (len(inf_idx) > 0):\n",
    "        print col+\" has Inf\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

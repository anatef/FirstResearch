{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Domain Level Features\n",
    "\n",
    "### Requirements\n",
    "1. Dictionary files for each domain\n",
    "2. List of domains\n",
    "3. Domain stats dataframe\n",
    "4. BLOSUM62 dictionary\n",
    "5. pfam emissions probability dictionary\n",
    "6. Fixed threshold clustering csv\n",
    "7. Percentile clustering csv\n",
    "\n",
    "### Instructions\n",
    "Run cells in order.\n",
    "\n",
    "### Output\n",
    "A csv file with rows labelled by domain name and columns by feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import datetime\n",
    "import math\n",
    "import sys\n",
    "curr_dir = !pwd\n",
    "sys.path.append(curr_dir[0] + \"/../5.HMM_alter_align\") \n",
    "from calc_exac_freq_func import codon_table\n",
    "from dnds_func import calculate_ns, seq_ns\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting path\n",
    "curr_dir = !pwd\n",
    "intance_cutoff = \"50\"\n",
    "\n",
    "#Reading the list of filtered domains\n",
    "with open(curr_dir[0]+\"/../5.domains_stats/filtered\"+intance_cutoff+\"_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list = pickle.load(handle)\n",
    "filtered_domains_list.sort()\n",
    "\n",
    "#Reading the table of all domains stats\n",
    "filtered_domains_df = pd.read_csv(curr_dir[0]+\"/../5.domains_stats/filtered\"+intance_cutoff+\"_domains_df.csv\", sep='\\t', index_col=0)\n",
    "\n",
    "#Read the substitutions table (for the dN/dS calculation)\n",
    "with open(curr_dir[0]+\"/codon_ns_table.pik\", 'rb') as handle:\n",
    "    codon_ns_table = pickle.load(handle)\n",
    "\n",
    "#Reading the BLOSUM62 dict\n",
    "with open(curr_dir[0]+\"/../BLOSUM62/BLOSUM62_dict.pik\", 'rb') as handle:\n",
    "    blosum62_dict = pickle.load(handle)\n",
    "    \n",
    "#Reading the HMM dict\n",
    "with open(curr_dir[0]+\"/../2.parse_Pfam/v30/domains_hmm_prob_dict.pik\", 'rb') as handle:\n",
    "    hmm_prob_dict = pickle.load(handle)\n",
    "    \n",
    "#Reading clustering files\n",
    "clustering_thresh = pd.read_csv(curr_dir[0]+\"/clustering_fixedThresh.csv\", sep=',', index_col=0)\n",
    "clustering_percentile = pd.read_csv(curr_dir[0]+\"/clustering_percentile.csv\", sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Functions used in computation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates a normalized Shannon entropy (from Miller et al, 2015)\n",
    "def entropy(a):\n",
    "    a = np.asarray(a) / sum(a)\n",
    "    entropy = 0\n",
    "    for val in a:\n",
    "        if val == 0 or np.isnan(val):\n",
    "            continue\n",
    "        entropy += val * math.log(val)\n",
    "    return(-entropy / math.log(len(a)))\n",
    "\n",
    "# Measure density of vector â€“ still experimental\n",
    "def density(a,window):\n",
    "    norm = []\n",
    "    for i in range(0,len(a)):\n",
    "        norm.append(float(a[i])/sum(a))\n",
    "    sums = np.empty(0)\n",
    "    for i in range(0,len(a)+window-1):\n",
    "        sums = np.append(sums,sum(norm[max(0,i-window+1):min(len(norm),i+1)]))\n",
    "    return(entropy(sums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished domain 7TM_GPCR_Srsx\n",
      "Finished domain 7tm_1\n",
      "Finished domain 7tm_4\n",
      "Finished domain AAA\n",
      "Finished domain AAA_5\n",
      "Finished domain ABC_membrane\n",
      "Finished domain ABC_tran\n",
      "Finished domain Ank\n",
      "Finished domain Ank_2\n",
      "Finished domain Ank_3\n",
      "Finished domain Ank_4\n",
      "Finished domain Ank_5\n",
      "Finished domain Annexin\n",
      "Finished domain Arf\n",
      "Finished domain Arm\n",
      "Finished domain BACK\n",
      "Finished domain BTB\n",
      "Finished domain BTB_2\n",
      "Finished domain Bromodomain\n",
      "Finished domain C1-set\n",
      "Finished domain C1_1\n",
      "Finished domain C2\n",
      "Finished domain C2-set_2\n",
      "Finished domain CBFD_NFYB_HMF\n",
      "Finished domain CH\n",
      "Finished domain CUB\n",
      "Finished domain Cadherin\n",
      "Finished domain Cadherin_2\n",
      "Finished domain Cadherin_3\n",
      "Finished domain Cadherin_C_2\n",
      "Finished domain Cadherin_tail\n",
      "Finished domain Collagen\n",
      "Finished domain DEAD\n",
      "Finished domain DUF1220\n",
      "Finished domain EF-hand_1\n",
      "Finished domain EF-hand_5\n",
      "Finished domain EF-hand_6\n",
      "Finished domain EF-hand_7\n",
      "Finished domain EF-hand_8\n",
      "Finished domain EGF\n",
      "Finished domain EGF_2\n",
      "Finished domain EGF_3\n",
      "Finished domain EGF_CA\n",
      "Finished domain F-box\n",
      "Finished domain F-box-like\n",
      "Finished domain FXa_inhibition\n",
      "Finished domain Filament\n",
      "Finished domain Filamin\n",
      "Finished domain Forkhead\n",
      "Finished domain HLH\n",
      "Finished domain HMG_box\n",
      "Finished domain HMG_box_2\n",
      "Finished domain Helicase_C\n",
      "Finished domain Hemopexin\n",
      "Finished domain Histone\n",
      "Finished domain Homeobox\n",
      "Finished domain Homeobox_KN\n",
      "Finished domain Hormone_recep\n",
      "Finished domain I-set\n",
      "Finished domain IQ\n",
      "Finished domain Ig_2\n",
      "Finished domain Ig_3\n",
      "Finished domain Ion_trans\n",
      "Finished domain Ion_trans_2\n",
      "Finished domain KH_1\n",
      "Finished domain KRAB\n",
      "Finished domain Kazal_1\n",
      "Finished domain Kazal_2\n",
      "Finished domain Kelch_1\n",
      "Finished domain Kelch_2\n",
      "Finished domain Kelch_3\n",
      "Finished domain Kelch_4\n",
      "Finished domain Kelch_6\n",
      "Finished domain Keratin_B2_2\n",
      "Finished domain LIM\n",
      "Finished domain LRRNT\n",
      "Finished domain LRR_4\n",
      "Finished domain LRR_5\n",
      "Finished domain LRR_8\n",
      "Finished domain Laminin_EGF\n",
      "Finished domain Laminin_G_1\n",
      "Finished domain Laminin_G_2\n",
      "Finished domain Ldl_recept_a\n",
      "Finished domain Ldl_recept_b\n",
      "Finished domain Lectin_C\n",
      "Finished domain MAGE\n",
      "Finished domain MFS_1\n",
      "Finished domain MHC_I\n",
      "Finished domain MMR_HSR1\n",
      "Finished domain MORN\n",
      "Finished domain Mito_carr\n",
      "Finished domain Nebulin\n",
      "Finished domain PDZ\n",
      "Finished domain PH\n",
      "Finished domain PHD\n",
      "Finished domain PRY\n",
      "Finished domain Pkinase\n",
      "Finished domain Pkinase_Tyr\n",
      "Finished domain Plectin\n",
      "Finished domain Prok-RING_4\n",
      "Finished domain RCC1\n",
      "Finished domain RCC1_2\n",
      "Finished domain RRM_1\n",
      "Finished domain RabGAP-TBC\n",
      "Finished domain Ras\n",
      "Finished domain ResIII\n",
      "Finished domain RhoGAP\n",
      "Finished domain RhoGEF\n",
      "Finished domain Roc\n",
      "Finished domain SAM_1\n",
      "Finished domain SAM_2\n",
      "Finished domain SCAN\n",
      "Finished domain SH2\n",
      "Finished domain SH3_1\n",
      "Finished domain SH3_2\n",
      "Finished domain SH3_9\n",
      "Finished domain SPRY\n",
      "Finished domain SRCR\n",
      "Finished domain Spectrin\n",
      "Finished domain Sushi\n",
      "Finished domain TAS2R\n",
      "Finished domain TIG\n",
      "Finished domain TPR_1\n",
      "Finished domain TPR_12\n",
      "Finished domain TPR_2\n",
      "Finished domain TSP_1\n",
      "Finished domain Trypsin\n",
      "Finished domain UCH\n",
      "Finished domain UCH_1\n",
      "Finished domain V-set\n",
      "Finished domain VWA\n",
      "Finished domain VWA_2\n",
      "Finished domain VWC\n",
      "Finished domain WD40\n",
      "Finished domain WW\n",
      "Finished domain Y_phosphatase\n",
      "Finished domain adh_short\n",
      "Finished domain adh_short_C2\n",
      "Finished domain cEGF\n",
      "Finished domain fn3\n",
      "Finished domain hEGF\n",
      "Finished domain ig\n",
      "Finished domain p450\n",
      "Finished domain ubiquitin\n",
      "Finished domain zf-B_box\n",
      "Finished domain zf-C2H2\n",
      "Finished domain zf-C2H2_4\n",
      "Finished domain zf-C2H2_6\n",
      "Finished domain zf-C3HC4\n",
      "Finished domain zf-C3HC4_2\n",
      "Finished domain zf-C3HC4_3\n",
      "Finished domain zf-C3HC4_4\n",
      "Finished domain zf-CCCH\n",
      "Finished domain zf-H2C2_2\n",
      "Finished domain zf-H2C2_5\n",
      "Finished domain zf-RING_2\n",
      "Finished domain zf-RING_5\n",
      "Finished domain zf-RING_UBOX\n",
      "Finished domain zf-met\n"
     ]
    }
   ],
   "source": [
    "input_path = curr_dir[0]+\"/../5.HMM_alter_align/domains_states_dicts/pfam-v30/\"\n",
    "features_dict = defaultdict(list)\n",
    "\n",
    "for domain_name in filtered_domains_list:\n",
    "    \n",
    "    #Reading the domain states dictionary\n",
    "    domain_dirfiles = !ls -t $input_path$domain_name\n",
    "    #Find the most recent file\n",
    "    recent_priority = -1\n",
    "    recent_filename = \"\"\n",
    "    for f in domain_dirfiles:\n",
    "        tokens = f.split(\"_\")\n",
    "        date = tokens[len(tokens)-1].split(\".\")\n",
    "        month = int(date[0])\n",
    "        day = int(date[1])\n",
    "        #Not all files have years, but those that do are the most recent\n",
    "        if date[2] != \"pik\":\n",
    "            year = int(date[2])\n",
    "        else:\n",
    "            year = 0\n",
    "        priority = year*1000 + month*50 + day\n",
    "        if priority > recent_priority:\n",
    "            recent_priority = priority\n",
    "            recent_filename = f\n",
    "    with open(input_path+domain_name+\"/\"+recent_filename, 'rb') as handle:\n",
    "        states_dict = pickle.load(handle)\n",
    "        \n",
    "    #Initializing feature counters\n",
    "    maf_sum = 0\n",
    "    sites_aa_num = 0\n",
    "    sites_aa_alter_num = 0\n",
    "    sites_snp_alter_num = 0\n",
    "    sites_poly_aa_num = 0 #The number of different aa in all the altered sites (most are 1)\n",
    "    sites_poly_aa_several = 0\n",
    "    \n",
    "    #Rare-poly-counters\n",
    "    maft_5 =  0.005\n",
    "    maft_05 = 0.0005\n",
    "    maft_005 = 0.00005\n",
    "    rare_5_num = 0\n",
    "    rare_05_num = 0\n",
    "    rare_005_num = 0\n",
    "    \n",
    "    #BLOSUM62_vals\n",
    "    blosum62_list = []\n",
    "    weigted_blosum62_list = []\n",
    "    \n",
    "    #SIFT counters\n",
    "    sift_sum = 0\n",
    "    sift_cnt = 0\n",
    "    \n",
    "    #PolyPhen counters\n",
    "    polyphen_sum = 0\n",
    "    polyphen_cnt = 0\n",
    "    \n",
    "    #dn/ds counters and variables\n",
    "    ref_seq = \"\"\n",
    "    #ref_af_list = []\n",
    "    Nd = 0\n",
    "    Sd = 0\n",
    "    \n",
    "    #Entropy\n",
    "    nonsyn_by_pos = {}\n",
    "    nonsyn_by_gene = {}\n",
    "    \n",
    "    #Conservation scores\n",
    "    phyloP_cutoff = 1.31\n",
    "    phastCons_con_cutoff = 0.95\n",
    "    phastCons_noncon_cutoff = 0.05\n",
    "    counter_phyloP = 0\n",
    "    counter_phastCons = 0\n",
    "    sum_phyloP = 0\n",
    "    sum_phastCons = 0\n",
    "    num_con_phyloP = 0\n",
    "    num_con_phastCons = 0\n",
    "    num_noncon_phyloP = 0\n",
    "    num_noncon_phastCons = 0\n",
    "    \n",
    "    #Nonsyn mutations in conserved aa positions\n",
    "    num_con_nonsyn = 0\n",
    "    \n",
    "    #Very common mutations\n",
    "    common_cutoff = 0.1\n",
    "    num_common = 0\n",
    "    \n",
    "    #pfam conserved sites\n",
    "    num_conserved = 0\n",
    "    sum_max = 0\n",
    "    prob_entropy = []\n",
    "    total_num = len(hmm_prob_dict[domain_name].keys())\n",
    "    con_threshold = 0.8\n",
    "    for state in hmm_prob_dict[domain_name].keys():\n",
    "        prob_list = hmm_prob_dict[domain_name][state]\n",
    "        prob_entropy.append(entropy(prob_list))\n",
    "        sum_max += max(prob_list)\n",
    "        if (max(prob_list) > con_threshold):\n",
    "            num_conserved += 1\n",
    "    \n",
    "    for state in states_dict:\n",
    "        sites_aa_num += len(states_dict[state])\n",
    "        for d in states_dict[state]:\n",
    "            #Creating a position pseudo-ref sequence\n",
    "            ref_codon = d[\"bp_ref\"]\n",
    "            ref_seq = ref_seq+ref_codon\n",
    "            \n",
    "            #Calculating frequency-based N/S\n",
    "            bp_af_adj_dict = d[\"bp_af_adj_dict\"]\n",
    "            for alt_codon in bp_af_adj_dict.keys():\n",
    "                alt_aa = codon_table[alt_codon]\n",
    "                #syn\n",
    "                if (alt_aa == d[\"aa_ref\"]):\n",
    "                    Sd += bp_af_adj_dict[alt_codon]\n",
    "                #Non-syn\n",
    "                else:\n",
    "                    Nd += bp_af_adj_dict[alt_codon]\n",
    "                    \n",
    "            #Conservation\n",
    "            for score in d[\"phyloP\"]:\n",
    "                counter_phyloP += 1\n",
    "                sum_phyloP += score\n",
    "                if score > phyloP_cutoff:\n",
    "                    num_con_phyloP += 1\n",
    "                elif score < -phyloP_cutoff:\n",
    "                    num_noncon_phyloP += 1\n",
    "            for score in d[\"phastCons\"]:\n",
    "                counter_phastCons += 1\n",
    "                sum_phastCons += score\n",
    "                if score > phastCons_con_cutoff:\n",
    "                    num_con_phastCons += 1\n",
    "                elif score < phastCons_noncon_cutoff:\n",
    "                    num_noncon_phastCons += 1\n",
    "            \n",
    "            if (d[\"af_adj\"] > 0):\n",
    "                sites_aa_alter_num += 1\n",
    "                sites_snp_alter_num += len(d[\"an_adj\"])\n",
    "                maf_sum += d[\"af_adj\"]\n",
    "                \n",
    "                #Number of different polymorphisms at this site\n",
    "                site_poly_num = len(d[\"alterations_af_adj_dict\"].keys())\n",
    "                sites_poly_aa_num += site_poly_num\n",
    "                if (site_poly_num > 1):\n",
    "                    sites_poly_aa_several += 1\n",
    "                \n",
    "                #Rare poly features\n",
    "                if (d[\"af_adj\"] < maft_005):\n",
    "                    rare_005_num += 1\n",
    "                    rare_05_num += 1\n",
    "                    rare_5_num += 1\n",
    "                elif (d[\"af_adj\"] < maft_05):\n",
    "                    rare_05_num += 1\n",
    "                    rare_5_num += 1\n",
    "                elif (d[\"af_adj\"] < maft_5):\n",
    "                    rare_5_num += 1\n",
    "                \n",
    "                #Common SNP\n",
    "                if(d[\"af_adj\"] > common_cutoff):\n",
    "                    num_common += 1\n",
    "                    \n",
    "                #BLOSUM62 features\n",
    "                ref = d[\"aa_ref\"]\n",
    "                for alt in d[\"alterations_af_adj_dict\"].keys():\n",
    "                    blosum_val = blosum62_dict[ref][alt]\n",
    "                    af_adj = np.mean(d[\"alterations_af_adj_dict\"][alt])\n",
    "                    blosum62_list.append(blosum_val)\n",
    "                    weigted_blosum62_list.append(blosum_val*af_adj)\n",
    "                \n",
    "                #SIFT\n",
    "                sift_list = d[\"SIFT\"]\n",
    "                for s in sift_list:\n",
    "                    if (s != \"\"):\n",
    "                        sift_sum += float(s[s.find(\"(\")+1:s.find(\")\")])\n",
    "                        sift_cnt += 1\n",
    "                        \n",
    "                #PolyPhen\n",
    "                polyphen_list = d[\"PolyPhen\"]      \n",
    "                for s in polyphen_list:\n",
    "                    if (s != \"\"):\n",
    "                        polyphen_sum += float(s[s.find(\"(\")+1:s.find(\")\")])\n",
    "                        polyphen_cnt += 1\n",
    "                \n",
    "                #Entropy\n",
    "                #Position\n",
    "                if state in nonsyn_by_pos.keys():\n",
    "                    nonsyn_by_pos[state].append(d[\"af_adj\"])\n",
    "                else:\n",
    "                    nonsyn_by_pos[state] = [d[\"af_adj\"]]\n",
    "                #Gene\n",
    "                key = d['ens_gene']\n",
    "                if key in nonsyn_by_gene.keys():\n",
    "                    nonsyn_by_gene[key].append(d[\"af_adj\"])\n",
    "                else:\n",
    "                    nonsyn_by_gene[key] = [d[\"af_adj\"]]\n",
    "\n",
    "                #Nonsyn conserved mutations\n",
    "                if len(d[\"phyloP\"]) == 3 and np.mean(d[\"phyloP\"]) > phyloP_cutoff:\n",
    "                    num_con_nonsyn += 1\n",
    "        \n",
    "    #Feature: domain length\n",
    "    domain_len = len(states_dict.keys())\n",
    "    features_dict[domain_name].append(domain_len)\n",
    "    \n",
    "    #Feature: average MAF overall aa sites\n",
    "    avg_maf_overall = maf_sum/float(sites_aa_num)\n",
    "    features_dict[domain_name].append(avg_maf_overall)\n",
    "    \n",
    "    #Feature: average MAF of all the altered sites\n",
    "    avg_maf_only_altered = maf_sum/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(avg_maf_only_altered)\n",
    "    \n",
    "    #Feature: number of alterations - aa level (raw and normalized by domain length)\n",
    "    norm_aa_alter_num = sites_aa_alter_num/float(domain_len)\n",
    "    features_dict[domain_name].append(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(norm_aa_alter_num)\n",
    "    \n",
    "    #Feature: number of alterations - DNA level (raw and normalized by domain length)\n",
    "    norm_snp_alter_num = sites_snp_alter_num/float(domain_len)\n",
    "    features_dict[domain_name].append(sites_snp_alter_num)\n",
    "    features_dict[domain_name].append(norm_snp_alter_num)\n",
    "    \n",
    "    #Feature: fraction of aa alterations (fraction of non-zero alterations)\n",
    "    frac_alter_aa = sites_aa_alter_num/float(sites_aa_num)\n",
    "    features_dict[domain_name].append(frac_alter_aa)\n",
    "    \n",
    "    #Feature: average number of polymorphisms at one site\n",
    "    avg_poly_aa = sites_poly_aa_num/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(avg_poly_aa)\n",
    "    \n",
    "    #Feature: fraction of altered sites with more than 1 polymorphism\n",
    "    frac_poly_several = sites_poly_aa_several/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(frac_poly_several)\n",
    "    \n",
    "    #Feature: fraction of rare SNPs (0.5%)\n",
    "    frac_rare_5 = rare_5_num/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(frac_rare_5)\n",
    "    \n",
    "    #Feature: fraction of rare SNPs (0.05%)\n",
    "    frac_rare_05 = rare_05_num/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(frac_rare_05)\n",
    "    \n",
    "    #Feature: fraction of rare SNPs (0.005%)\n",
    "    frac_rare_005 = rare_005_num/float(sites_aa_alter_num)\n",
    "    features_dict[domain_name].append(frac_rare_005)\n",
    "    \n",
    "    #Feature: BLOSUM62 average\n",
    "    blosum62_avg = sum(blosum62_list)/float(len(blosum62_list))\n",
    "    weigted_blosum62_avg = sum(weigted_blosum62_list)/float(len(weigted_blosum62_list))\n",
    "    features_dict[domain_name].append(blosum62_avg)\n",
    "    features_dict[domain_name].append(weigted_blosum62_avg)\n",
    "    \n",
    "    #Feature: pseudo-sequence dN/dS        \n",
    "    (N,S) = seq_ns(ref_seq) #Refrence expected syn/nonsyn per site\n",
    "    if (N == 0): \n",
    "        PN = 0\n",
    "    else:\n",
    "        PN = Nd/float(N) #Proportion of nonsyn\n",
    "    if (S == 0):\n",
    "        PS = 0\n",
    "    else:\n",
    "        PS = Sd/float(S) #Proportion of syn\n",
    "\n",
    "    #num of nonsyn substitutions per syn site\n",
    "    dN = -0.75 * (np.log(1-4*PN/float(3)))\n",
    "    #num of syn substitutions per nonsyn site\n",
    "    dS = -0.75 * (np.log(1-4*PS/float(3)))\n",
    "\n",
    "    if (dN ==0 or dS == 0):\n",
    "        dN_dS = 1 #There isn't enough information to calculate dN/dS\n",
    "    else:\n",
    "        dN_dS = dN/dS\n",
    "\n",
    "    features_dict[domain_name].append(dN_dS)\n",
    "    \n",
    "    #Feature: SIFT average\n",
    "    if (sift_cnt > 0):\n",
    "        sift_avg = sift_sum/float(sift_cnt)\n",
    "    else:\n",
    "        sift_avg = -1\n",
    "    features_dict[domain_name].append(sift_avg)\n",
    "    \n",
    "    #Feature: PolyPhen average\n",
    "    if (polyphen_cnt > 0):\n",
    "        polyphen_avg = polyphen_sum/float(polyphen_cnt)\n",
    "    else:\n",
    "        polyphen_avg = -1\n",
    "    features_dict[domain_name].append(polyphen_avg)\n",
    "    \n",
    "    #Feature: Fraction of DNA sites altered\n",
    "    frac_snp_alter = float(sites_snp_alter_num) / (3*sites_aa_num)\n",
    "    features_dict[domain_name].append(frac_snp_alter)\n",
    "    \n",
    "    #Case where there are no mutations for a position is handled, so no need to throw anything\n",
    "    np.seterr(divide='ignore',invalid='ignore')\n",
    "    \n",
    "    #Feature: Entropy by position\n",
    "    avg_nonsyn_pos = np.zeros(len(nonsyn_by_pos.keys()))\n",
    "    index = 0\n",
    "    for key in nonsyn_by_pos.keys():\n",
    "        avg_nonsyn_pos[index] = np.median(nonsyn_by_pos[key])\n",
    "        index += 1\n",
    "    features_dict[domain_name].append(entropy(avg_nonsyn_pos))\n",
    "    \n",
    "    #Feature: Windowed entropy by position\n",
    "    features_dict[domain_name].append(density(avg_nonsyn_pos,20))\n",
    "    \n",
    "    #Feature: Entropy by gene\n",
    "    avg_nonsyn_gene = np.zeros(len(nonsyn_by_gene.keys()))\n",
    "    index = 0\n",
    "    for key in nonsyn_by_gene.keys():\n",
    "        avg_nonsyn_gene[index] = np.median(nonsyn_by_gene[key])\n",
    "        index += 1\n",
    "    features_dict[domain_name].append(entropy(avg_nonsyn_gene))\n",
    "    \n",
    "    #Reset warnings\n",
    "    np.seterr(divide='warn',invalid='warn')\n",
    "    \n",
    "    #Feature: Average phyloP\n",
    "    avg_phyloP = sum_phyloP / counter_phyloP\n",
    "    features_dict[domain_name].append(avg_phyloP)\n",
    "    \n",
    "    #Feature: Average phastCons\n",
    "    avg_phastCons = sum_phastCons / counter_phastCons\n",
    "    features_dict[domain_name].append(avg_phastCons)\n",
    "    \n",
    "    #Feature: Ratio phyloP\n",
    "    ratio_phyloP = float(num_con_phyloP) / num_noncon_phyloP\n",
    "    features_dict[domain_name].append(ratio_phyloP)\n",
    "    \n",
    "    #Feature: Ratio phastCons\n",
    "    ratio_phastCons = float(num_con_phastCons) / num_noncon_phastCons\n",
    "    features_dict[domain_name].append(ratio_phastCons)\n",
    "    \n",
    "    #Feature: pfam emission prob fraction\n",
    "    frac_conserved = float(num_conserved) / total_num\n",
    "    features_dict[domain_name].append(frac_conserved)\n",
    "    \n",
    "    #Feature: pfam emission prob average max\n",
    "    avg_max = sum_max / total_num\n",
    "    features_dict[domain_name].append(avg_max)\n",
    "    \n",
    "    #Feature: Average pfam emission prob entropy\n",
    "    features_dict[domain_name].append(np.mean(prob_entropy))\n",
    "    \n",
    "    #Feature: Clustering with 0.005% cutoff\n",
    "    features_dict[domain_name].append(clustering_thresh.loc[domain_name,\"5e-05\"])\n",
    "    \n",
    "    #Feature: Clustering with 90th percentile\n",
    "    features_dict[domain_name].append(clustering_percentile.loc[domain_name,\"90\"])\n",
    "    \n",
    "    #Feature: Fraction of nonsyn altered positions that are conserved\n",
    "    frac_con = float(num_con_nonsyn) / sites_aa_alter_num\n",
    "    features_dict[domain_name].append(frac_con)\n",
    "    \n",
    "    #Feature: Common SNPs\n",
    "    frac_common = float(num_common) / sites_aa_alter_num\n",
    "    features_dict[domain_name].append(frac_common)\n",
    "    \n",
    "    print(\"Finished domain \"+domain_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export features to a well-formatted data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains_features_df = pd.DataFrame.from_dict(features_dict,orient='index')\n",
    "domains_features_df.columns = [\"length\", \"avg_maf_all\", \"avg_maf_altered\", \"alter_num_aa\", \"alter_num_aa_norm\", \n",
    "                               \"alter_num_dna\", \"alter_num_dna_norm\", \"frac_alter_aa\", \"avg_poly\", \"frac_poly_several\", \n",
    "                               \"rare_poly_0.5%\", \"rare_poly_0.05%\", \"rare_poly_0.005%\", \"BLOSUM_avg\", \"weighted_BLOSUM_avg\", \n",
    "                               \"pseudo_dNdS\", \"SIFT\", \"PolyPhen\",\"frac_alter_dna\", \"entropy_pos_nonsyn\", \"entropy_nonsyn_window\",\n",
    "                               \"entropy_gene_nonsyn\", \"avg_phyloP\", \"avg_phastCons\", \"ratio_phyloP\", \"ratio_phastCons\",\n",
    "                               \"frac_aa_conserved\", \"avg_max_aa_conservation\", \"pfam_prob_entropy\", \"clustering_0.005%\",\n",
    "                               \"clustering_90\", \"frac_aa_nonsyn_conserved\", \"frac_common_poly\"]\n",
    "domains_features_df = domains_features_df.sort_index()\n",
    "\n",
    "#Adding the data from the df\n",
    "domains_features_df[\"num_genes\"] = filtered_domains_df[\"genes\"]\n",
    "domains_features_df[\"num_instances\"] = filtered_domains_df[\"instances\"]\n",
    "\n",
    "#Computing log2 of genes number\n",
    "domains_features_df[\"num_genes_log2\"] = domains_features_df[\"num_genes\"].apply(lambda x: np.log2(x))\n",
    "domains_features_df[\"num_instances_log2\"] = domains_features_df[\"num_instances\"].apply(lambda x: np.log2(x))\n",
    "\n",
    "#Save to file\n",
    "domains_features_df.to_csv(curr_dir[0]+\"/domains_features_df_filtered\"+intance_cutoff+\".csv\", sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

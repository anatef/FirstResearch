{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing ExAC version release 0.3\n",
    "#### Parsing the ExAC VCF file and extract many fields of meta-data and variant calling data.\n",
    "\n",
    "&copy; Anat Etzion-Fuchs, Feb 2017\n",
    "\n",
    "---\n",
    "### Instructions:\n",
    "1. Download the ExAC database from: [ftp://ftp.broadinstitute.org/pub/ExAC_release/release0.3/ExAC.r0.3.sites.vep.vcf.gz](ftp://broadinstitute.org/pub/ExAC_release/release0.3/)\n",
    "2. Save this script and the .vcf.gz in the same dir (or change the `path` in global vars to where you saved the data file). No need to unzip!\n",
    "3. Run all code cells one after the other\n",
    "\n",
    "### Code processing and output:\n",
    "1) Parse the VCF metadata at the beginning. These include metadata of the following types: ALT, FILTER, FORMAT, INFO, contig, reference. \n",
    "\n",
    "**Output:**  1. `metadata_dict` : a dictionary with all the metadata, and keys are the the abovementioned types.        \n",
    "2.`info_df`: a data-frame with the INFO fields. This is where ExAC lists the description of there different data fields and their meaning. A printout of this data frame is in the last cell.\n",
    "\n",
    "2) Parse the VCF data lines, see format at: [VCFv4.1.pdf](https://samtools.github.io/hts-specs/VCFv4.1.pdf)  \n",
    "The header consist of the following: #CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO.  \n",
    "The INFO is the filed that contains most of the information.  \n",
    "The code extract some of the fields realted to the allele frequency.   \n",
    "After the frequency fields, there can be several CSQ.  \n",
    "Each CSQ represent data of a specific `Feature_Type`: different transcipts or non_coding variants. Each CSQ contains a different Ensembl identifiers.  \n",
    "A printout of the sepcific format of the CSQ is in the before last cell.  \n",
    "The meaning of the different fields is described here: [http://useast.ensembl.org/info/docs/tools/vep/vep_formats.html?redirect=no](http://useast.ensembl.org/info/docs/tools/vep/vep_formats.html?redirect=no)\n",
    "\n",
    "**Output:** `parsed` dir is created and inside one file for each chromosome, in .csv format.   \n",
    "Each chromosome file is a table, with one row for each CSQ feature_type (for each VCF data line, there's a seperate line for each CSQ that contains the filds that all the CSQ share and also the CSQ specific fields)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "path = curr_dir[0]+\"/\" #Linux path\n",
    "#myFile = \"ExAC.r0.3.nonTCGA.sites.vep.vcf.gz\"\n",
    "myFile = \"ExAC.r0.3.sites.vep.vcf.gz\"\n",
    "\n",
    "#Positions in the VCF record\n",
    "CHROM = 0\n",
    "POS = 1\n",
    "ID = 2\n",
    "REF = 3\n",
    "ALT = 4\n",
    "QUAL = 5\n",
    "FILTER = 6\n",
    "INFO = 7\n",
    "\n",
    "#fields for extraction (it's important that those names will match *exactly* the dictionary keys in \"data_dict\")\n",
    "headlines = [\"chrom\", \"pos\", \"id\", \"ref\", \"alt\", \"qual\", \"filter\", \"AC\", \"AC_AFR\", \"AC_AMR\", \"AC_Adj\", \"AC_EAS\", \"AC_FIN\", \"AC_Het\", \"AC_Hom\", \"AC_NFE\",\n",
    "             \"AC_OTH\", \"AC_SAS\", \"AF\", \"AN\", \"AN_AFR\", \"AN_AMR\", \"AN_Adj\", \"AN_EAS\", \"AN_FIN\", \"AN_NFE\", \"AN_OTH\", \"AN_SAS\", \"DP\", \"gene\", \"feature\", \n",
    "             \"feature_type\", \"conseq\", \"prot_pos\", \"amino_acids\", \"codons\", \"strand\",\"ENSP\", \"SWISSPROT\", \"SIFT\", \"PolyPhen\", \"exon\", \"intron\", \"domains\", \"clin_sig\"]\n",
    "\n",
    "#CSQ positions\n",
    "#http://useast.ensembl.org/info/docs/tools/vep/vep_formats.html?redirect=no\n",
    "GENE = 0        #Ensembl stable ID of affected gene\n",
    "FEATURE = 1     #Ensembl stable ID of feature\n",
    "FEATURE_TYPE = 2# type of feature. Currently one of Transcript, RegulatoryFeature, MotifFeature\n",
    "CONSEQ = 3      #consequence type of this variant\n",
    "PROT_POS = 6    #relative position of amino acid in protein\n",
    "AMINO_ACIDS = 7 #the change. only given if the variant affects the protein-coding sequence\n",
    "CODONS = 8      #the alternative codons with the variant base in upper case\n",
    "ALLELE_NUM = 10 #Allele number from input; 0 is reference, 1 is first alternate etc\n",
    "STRAND = 12     #the DNA strand (1 or -1) on which the transcript/feature lies\n",
    "ENSP = 19       #the Ensembl protein identifier of the affected transcript\n",
    "SWISSPROT = 20  #UniProtKB/Swiss-Prot identifier of protein product\n",
    "SIFT = 23       #the SIFT prediction and/or score, with both given as prediction(score)\n",
    "POLYPHEN = 24   #the PolyPhen prediction and/or score\n",
    "EXON = 25       #the exon number (out of total number)\n",
    "INTRON = 26     #the intron number (out of total number)\n",
    "DOMAINS = 27    #the source and identifer of any overlapping protein domains\n",
    "GMAF = 30       #Non-reference allele and frequency of existing variant in 1000 Genomes\n",
    "CLIN_SIG = 37   #ClinVar Clinical significance of variant from dbSNP: http://varianttools.sourceforge.net/Annotation/DbSNP\n",
    "                #Variant Clinical Significance, 0 - unknown, 1 -\n",
    "                #untested, 2 - non-pathogenic, 3 - probable-non-pathogenic, 4 - probable-pathogenic, \n",
    "                #5 - pathogenic, 6 - drug-response, 7 - histocompatibility, 255 - other\n",
    "            \n",
    "\n",
    "#Defined here: https://macarthurlab.org/2016/03/17/reproduce-all-the-figures-a-users-guide-to-exac-part-2/#multi-allelic-enriched-regions\n",
    "multi_allelic_regions = {'14': [[106329000, 106331000], [107178000, 107180000]], \n",
    "                         '2': [[89160000, 89162000]],\n",
    "                        '17': [[18967000, 18968000], [19091000, 19092000]],\n",
    "                        '22': [[23223000, 23224000]],\n",
    "                        '1': [[152975000, 152976000]]}\n",
    "#A flag for removing the multi-allelic regions\n",
    "removeMultiAllelic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open the file and process the meta-data rows\n",
    "Processed meta-data is stored in the dictionary: `metadata_dict`.  \n",
    "Metadata of type \"INFO\" is saved into the data frame: `info_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file\n",
    "vcf_file = gzip.open(path+myFile,'r')\n",
    "\n",
    "#Process meta-data\n",
    "metadata_dict = {}\n",
    "data_flag = False\n",
    "for line in vcf_file:\n",
    "    if line[0:2] == \"##\":\n",
    "        #assign keys according to the format\n",
    "        key = line[2:line.index('=')]\n",
    "        if key == \"ALT\":\n",
    "            val = dict.fromkeys([\"ID\",\"Description\"])\n",
    "        elif key == \"FILTER\":\n",
    "            val = dict.fromkeys([\"ID\",\"Description\"])\n",
    "        elif key == \"FORMAT\":\n",
    "            val = dict.fromkeys([\"ID\",\"Number\",\"Type\",\"Description\"])\n",
    "        elif key == \"INFO\":\n",
    "            val = dict.fromkeys([\"ID\",\"Number\", \"Type\", \"Description\"])\n",
    "        elif key == \"contig\":\n",
    "            val = dict.fromkeys([\"ID\",\"length\"])\n",
    "        elif key == \"reference\":\n",
    "            val = dict.fromkeys([\"file\"])\n",
    "        #Not processing other metadata types\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        #fill in the data\n",
    "        for f in val.keys():\n",
    "            f_key = line.find(f)\n",
    "            f_beg = line.find(\"=\", f_key)\n",
    "            if (f_beg < 0):\n",
    "                f_beg = line.find(\":\", f_key) #When parsing reference line\n",
    "            f_end = line.find(\",\", f_beg)\n",
    "            if (f_end < 0):\n",
    "                f_end = line.find(\">\")\n",
    "            if (f_end < 0): #When parsing reference line\n",
    "                f_end = line.find(\"\\n\")\n",
    "            val[f] = line[f_beg + 1:f_end]\n",
    "            \n",
    "        #Adding to the metadata dictionary\n",
    "        if not metadata_dict.has_key(key):\n",
    "            metadata_dict[key] = [val]\n",
    "        else:\n",
    "            metadata_dict[key].append(val)\n",
    "            \n",
    "    #Processing the data starting the next line\n",
    "    elif line[0:6] == \"#CHROM\":\n",
    "        data_flag = True\n",
    "        break\n",
    "\n",
    "#Arrange the INFO metadata to a data-frame\n",
    "info_df = pd.DataFrame(metadata_dict[\"INFO\"])\n",
    "info_df = info_df.sort_values(\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the variant calling data rows\n",
    "Output: `parsed/` dir with one file for each parsed chromosome: `parsed_chrom#.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nth(s, x, n=0, overlap=False):\n",
    "    \"\"\"A function to find the nth position on a substring x in the string s\"\"\"\n",
    "    \n",
    "    l = 1 if overlap else len(x)\n",
    "    i = -l\n",
    "    for c in xrange(n + 1):\n",
    "        i = s.find(x, i + l)\n",
    "        if i < 0:\n",
    "            break\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_to_df_csv(data_dict, headlines, chrom_num):\n",
    "    \"\"\"A function that saves the data dictionary to DataFrame and then to .csv\"\"\"\n",
    "    \n",
    "    #Creating a data_frame from all the parsed values of the chromosome\n",
    "    df = pd.DataFrame([data_dict[h] for h in headlines])\n",
    "    df = df.transpose()\n",
    "    df.columns = headlines\n",
    "    \n",
    "    !mkdir -p $path\"parsed\"\n",
    "    #Saving the df to a file\n",
    "    df.to_csv(path+\"parsed/parsed_chrom\"+chrom_num+\".csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_main_fields(line_parts, data_dict):\n",
    "    \"\"\"A function that extract the main fields from line_parts and adds them to the data dictionary.\n",
    "    Returining the extracted info field for further processing\"\"\"\n",
    "    \n",
    "    #Extracting Chromosome number\n",
    "    data_dict[\"chrom\"].append(line_parts[CHROM])\n",
    "    \n",
    "    #Extracting position\n",
    "    data_dict[\"pos\"].append(int(line_parts[POS]))\n",
    "    \n",
    "    #Extracting id\n",
    "    data_dict[\"id\"].append(line_parts[ID])\n",
    "    \n",
    "    #Extracting ref\n",
    "    data_dict[\"ref\"].append(line_parts[REF])\n",
    "    \n",
    "    #Extracting quality\n",
    "    data_dict[\"qual\"].append(line_parts[QUAL])\n",
    "    \n",
    "    #Extracting filter\n",
    "    data_dict[\"filter\"].append(line_parts[FILTER])\n",
    "    \n",
    "    #Extracting fields from the info\n",
    "    info = line_parts[INFO]\n",
    "    \n",
    "    #AC = Allele Count\n",
    "    AC_beg = info.find(\"AC=\")\n",
    "    AC_end = info.find(\";\", AC_beg)\n",
    "    AC_list = (info[AC_beg+3:AC_end]).split(\",\")\n",
    "    \n",
    "    #AC_AFR = Allele Count African population\n",
    "    AC_AFR_beg = info.find(\"AC_AFR=\")\n",
    "    AC_AFR_end = info.find(\";\", AC_AFR_beg)\n",
    "    AC_AFR_list = (info[AC_AFR_beg+7:AC_AFR_end]).split(\",\")\n",
    "    \n",
    "    #AC_AMR = Allele count American population\n",
    "    AC_AMR_beg = info.find(\"AC_AMR=\")\n",
    "    AC_AMR_end = info.find(\";\", AC_AMR_beg)\n",
    "    AC_AMR_list = (info[AC_AMR_beg+7:AC_AMR_end]).split(\",\")\n",
    "    \n",
    "    #AC_adjusted = Adjusted Allele Count\n",
    "    AC_adj_beg = info.find(\"AC_Adj=\")\n",
    "    AC_adj_end = info.find(\";\", AC_adj_beg)\n",
    "    AC_adj_list = (info[AC_adj_beg+7:AC_adj_end]).split(\",\")\n",
    "    \n",
    "    #AC_EAS = Allele Count East Asian population\n",
    "    AC_EAS_beg = info.find(\"AC_EAS=\")\n",
    "    AC_EAS_end = info.find(\";\", AC_EAS_beg)\n",
    "    AC_EAS_list = (info[AC_EAS_beg+7:AC_EAS_end]).split(\",\")\n",
    "    \n",
    "    #AC_FIN = Allele Count Finish population\n",
    "    AC_FIN_beg = info.find(\"AC_FIN=\")\n",
    "    AC_FIN_end = info.find(\";\", AC_FIN_beg)\n",
    "    AC_FIN_list = (info[AC_FIN_beg+7:AC_FIN_end]).split(\",\")\n",
    "    \n",
    "    #AC_Het = Allele Count (adjusted) Heterozygous\n",
    "    AC_Het_beg = info.find(\"AC_Het=\")\n",
    "    AC_Het_end = info.find(\";\", AC_Het_beg)\n",
    "    AC_Het_list = (info[AC_Het_beg+7:AC_Het_end]).split(\",\")\n",
    "    \n",
    "    #AC_Hom = Allele Count (adjusted) Homozygous\n",
    "    AC_Hom_beg = info.find(\"AC_Hom=\")\n",
    "    AC_Hom_end = info.find(\";\", AC_Hom_beg)\n",
    "    AC_Hom_list = (info[AC_Hom_beg+7:AC_Hom_end]).split(\",\")\n",
    "    \n",
    "    #AC_NFE = Allele Count Non-Finnish European population\n",
    "    AC_NFE_beg = info.find(\"AC_NFE=\")\n",
    "    AC_NFE_end = info.find(\";\", AC_NFE_beg)\n",
    "    AC_NFE_list = (info[AC_NFE_beg+7:AC_NFE_end]).split(\",\")\n",
    "    \n",
    "    #AC_OTH = Allele Count Other populations\n",
    "    AC_OTH_beg = info.find(\"AC_OTH=\")\n",
    "    AC_OTH_end = info.find(\";\", AC_OTH_beg)\n",
    "    AC_OTH_list = (info[AC_OTH_beg+7:AC_OTH_end]).split(\",\")\n",
    "    \n",
    "    #AC_SAS = Allele Count South Asian population\n",
    "    AC_SAS_beg = info.find(\"AC_SAS=\")\n",
    "    AC_SAS_end = info.find(\";\", AC_SAS_beg)\n",
    "    AC_SAS_list = (info[AC_SAS_beg+7:AC_SAS_end]).split(\",\")\n",
    "    \n",
    "    #AF = Allele Frequency \n",
    "    AF_beg = info.find(\"AF=\")\n",
    "    AF_end = info.find(\";\", AF_beg)\n",
    "    AF_list = (info[AF_beg+3:AF_end]).split(\",\")\n",
    "    \n",
    "    #AN = Allele Number\n",
    "    AN_beg = info.find(\"AN=\")\n",
    "    AN_end = info.find(\";\", AN_beg)\n",
    "    data_dict[\"AN\"].append(info[AN_beg+3:AN_end])\n",
    "    \n",
    "    #AN_AFR = Allele Number African population\n",
    "    AN_AFR_beg = info.find(\"AN_AFR=\")\n",
    "    AN_AFR_end = info.find(\";\", AN_AFR_beg)\n",
    "    data_dict[\"AN_AFR\"].append(info[AN_AFR_beg+7:AN_AFR_end])\n",
    "    \n",
    "    #AN_AMR = Allele Number American population\n",
    "    AN_AMR_beg = info.find(\"AN_AMR=\")\n",
    "    AN_AMR_end = info.find(\";\", AN_AMR_beg)\n",
    "    data_dict[\"AN_AMR\"].append(info[AN_AMR_beg+7:AN_AMR_end])\n",
    "    \n",
    "    #AN_adj = Adjusted Allele Number\n",
    "    AN_adj_beg = info.find(\"AN_Adj=\")\n",
    "    AN_adj_end = info.find(\";\", AN_adj_beg)\n",
    "    data_dict[\"AN_Adj\"].append(info[AN_adj_beg+7:AN_adj_end])\n",
    "    \n",
    "    #AN_EAS = Allele Number East Asian population\n",
    "    AN_EAS_beg = info.find(\"AN_EAS=\")\n",
    "    AN_EAS_end = info.find(\";\", AN_EAS_beg)\n",
    "    data_dict[\"AN_EAS\"].append(info[AN_EAS_beg+7:AN_EAS_end])\n",
    "    \n",
    "    #AN_FIN = Allele Number Finish population\n",
    "    AN_FIN_beg = info.find(\"AN_FIN=\")\n",
    "    AN_FIN_end = info.find(\";\", AN_FIN_beg)\n",
    "    data_dict[\"AN_FIN\"].append(info[AN_FIN_beg+7:AN_FIN_end])\n",
    "    \n",
    "    #AN_NFE = Allele Number Non-Finnish European population\n",
    "    AN_NFE_beg = info.find(\"AN_NFE=\")\n",
    "    AN_NFE_end = info.find(\";\", AN_NFE_beg)\n",
    "    data_dict[\"AN_NFE\"].append(info[AN_NFE_beg+7:AN_NFE_end])\n",
    "    \n",
    "    #AN_OTH = Allele Number other populations\n",
    "    AN_OTH_beg = info.find(\"AN_OTH=\")\n",
    "    AN_OTH_end = info.find(\";\", AN_OTH_beg)\n",
    "    data_dict[\"AN_OTH\"].append(info[AN_OTH_beg+7:AN_OTH_end])\n",
    "    \n",
    "    #AN_SAS = Allele Number South Asian population\n",
    "    AN_SAS_beg = info.find(\"AN_SAS=\")\n",
    "    AN_SAS_end = info.find(\";\", AN_SAS_beg)\n",
    "    data_dict[\"AN_SAS\"].append(info[AN_SAS_beg+7:AN_SAS_end])\n",
    "    \n",
    "    #DP = \"Approximate read depth\n",
    "    DP_beg = info.find(\"DP=\")\n",
    "    DP_end = info.find(\";\", DP_beg)\n",
    "    data_dict[\"DP\"].append(info[DP_beg+3:DP_end])\n",
    "    \n",
    "    return (AC_list, AC_AFR_list, AC_AMR_list, AC_adj_list, AC_EAS_list, AC_FIN_list, AC_Het_list, AC_Hom_list, AC_NFE_list, AC_OTH_list, AC_SAS_list, AF_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_empty_fields(line_parts, alt_list, data_dict):\n",
    "    \"\"\"A function that updates empty strings for CSQ fields when there's no CSQ data.\"\"\"\n",
    "    \n",
    "    #Adding one line per each variation (can be several even when there's no CSQ)\n",
    "    for i in range(len(alt_list)):\n",
    "        \n",
    "        #This command has to be inside the loop, it adds elements to some dictionary fields\n",
    "        (AC_list, AC_AFR_list, AC_AMR_list, AC_adj_list, AC_EAS_list, AC_FIN_list, \n",
    "         AC_Het_list, AC_Hom_list, AC_NFE_list, AC_OTH_list, AC_SAS_list, AF_list) = update_main_fields(line_parts, data_dict)\n",
    "        \n",
    "        #Update the main fields\n",
    "        data_dict[\"AC\"].append(AC_list[i])\n",
    "        data_dict[\"AC_AFR\"].append(AC_AFR_list[i])\n",
    "        data_dict[\"AC_AMR\"].append(AC_AMR_list[i])\n",
    "        data_dict[\"AC_Adj\"].append(AC_adj_list[i])\n",
    "        data_dict[\"AC_EAS\"].append(AC_EAS_list[i])\n",
    "        data_dict[\"AC_FIN\"].append(AC_FIN_list[i])\n",
    "        data_dict[\"AC_Het\"].append(AC_Het_list[i])\n",
    "        data_dict[\"AC_Hom\"].append(AC_Hom_list[i])\n",
    "        data_dict[\"AC_NFE\"].append(AC_NFE_list[i])\n",
    "        data_dict[\"AC_OTH\"].append(AC_OTH_list[i])\n",
    "        data_dict[\"AC_SAS\"].append(AC_SAS_list[i])\n",
    "        data_dict[\"AF\"].append(AF_list[i])\n",
    "    \n",
    "        #Update the alt\n",
    "        data_dict[\"alt\"].append(alt_list[i])\n",
    "    \n",
    "        #Update the rest of fields with empty string\n",
    "        data_dict[\"gene\"].append(\"\")\n",
    "        data_dict[\"feature\"].append(\"\")\n",
    "        data_dict[\"feature_type\"].append(\"\")\n",
    "        data_dict[\"conseq\"].append(\"\")\n",
    "        data_dict[\"prot_pos\"].append(\"\")\n",
    "        data_dict[\"amino_acids\"].append(\"\")\n",
    "        data_dict[\"codons\"].append(\"\")\n",
    "        data_dict[\"strand\"].append(\"\")\n",
    "        data_dict[\"ENSP\"].append(\"\")\n",
    "        data_dict[\"SWISSPROT\"].append(\"\")\n",
    "        data_dict[\"SIFT\"].append(\"\")\n",
    "        data_dict[\"PolyPhen\"].append(\"\")\n",
    "        data_dict[\"exon\"].append(\"\")\n",
    "        data_dict[\"intron\"].append(\"\")\n",
    "        data_dict[\"domains\"].append(\"\")\n",
    "        data_dict[\"clin_sig\"].append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished chromosome1\n",
      "finished chromosome2\n",
      "finished chromosome3\n",
      "finished chromosome4\n",
      "finished chromosome5\n",
      "finished chromosome6\n",
      "finished chromosome7\n",
      "finished chromosome8\n",
      "finished chromosome9\n",
      "finished chromosome10\n",
      "finished chromosome11\n",
      "finished chromosome12\n",
      "finished chromosome13\n",
      "finished chromosome14\n",
      "finished chromosome15\n",
      "finished chromosome16\n",
      "finished chromosome17\n",
      "finished chromosome18\n",
      "finished chromosome19\n",
      "finished chromosome20\n",
      "finished chromosome21\n",
      "finished chromosome22\n",
      "finished chromosomeX\n",
      "finished chromosomeY\n"
     ]
    }
   ],
   "source": [
    "#Process the data records of the vcf and save each chromosome to a seperate file\n",
    "chromosome_iter = '1'\n",
    "data_dict = defaultdict(list)\n",
    "multi_allele_skipped = 0\n",
    "\n",
    "for line in vcf_file:\n",
    "    line_parts = line.split(\"\\t\")\n",
    "    \n",
    "    #Excluding multi-allelic regions\n",
    "    if (removeMultiAllelic == True):\n",
    "        chrom = line_parts[CHROM]\n",
    "        if (chrom in multi_allelic_regions.keys()):\n",
    "            pos = int(line_parts[POS])\n",
    "            regions = multi_allelic_regions[chrom]\n",
    "            for region in regions:\n",
    "                if (pos >= region[0] and pos <= region[1]):\n",
    "                    #Multi-allelic region - excluding from analysis\n",
    "                    multi_allele_skipped += 1\n",
    "                    continue\n",
    "    \n",
    "    #If the next line belongs to a different chromosome - saving to file\n",
    "    if line_parts[CHROM] != chromosome_iter:\n",
    "        data_to_df_csv(data_dict, headlines, chromosome_iter)\n",
    "        #Initializing the data dictionary\n",
    "        data_dict = defaultdict(list)\n",
    "        print \"finished chromosome\"+chromosome_iter\n",
    "        chromosome_iter = line_parts[CHROM]\n",
    "    \n",
    "    #Extracting alt\n",
    "    alt_list = line_parts[ALT].split(\",\")\n",
    "    \n",
    "    #Extracting fields from the info\n",
    "    info = line_parts[INFO]\n",
    "    \n",
    "    #CSQ = Consequence type as predicted by VEP\n",
    "    CSQ_beg = info.find(\"CSQ=\")\n",
    "    if (CSQ_beg == -1):\n",
    "        #NO CSQ data: just fill in empty strings instead\n",
    "        fill_empty_fields(line_parts, alt_list, data_dict)\n",
    "    else:    \n",
    "        CSQ_data = info[CSQ_beg+4:]\n",
    "        CSQ_features = CSQ_data.split(\",\")\n",
    "    \n",
    "        for CSQ in CSQ_features:\n",
    "            #Update the main fields for each CSQ feature (so each CSQ will appear in a different line)\n",
    "            (AC_list, AC_AFR_list, AC_AMR_list, AC_adj_list, AC_EAS_list, AC_FIN_list,\n",
    "             AC_Het_list, AC_Hom_list, AC_NFE_list, AC_OTH_list, AC_SAS_list, AF_list) = update_main_fields(line_parts, data_dict)\n",
    "\n",
    "            #Allele_num for deciding which alt, AC and AF to add\n",
    "            allele_num_beg = find_nth(CSQ, \"|\", ALLELE_NUM)\n",
    "            allele_num_end = CSQ.find(\"|\", allele_num_beg+1)\n",
    "            allele_num = int(CSQ[allele_num_beg+1:allele_num_end])\n",
    "            #Adding the corresponding alt\n",
    "            if (allele_num == 0):\n",
    "                print \"allele num = 0 \"+line_parts[POS] #Making sure all the features correspond to an alt (0 = ref)\n",
    "            else:\n",
    "                data_dict[\"alt\"].append(alt_list[allele_num-1])\n",
    "                data_dict[\"AC\"].append(AC_list[allele_num-1])\n",
    "                data_dict[\"AC_AFR\"].append(AC_AFR_list[allele_num-1])\n",
    "                data_dict[\"AC_AMR\"].append(AC_AMR_list[allele_num-1])\n",
    "                data_dict[\"AC_Adj\"].append(AC_adj_list[allele_num-1])\n",
    "                data_dict[\"AC_EAS\"].append(AC_EAS_list[allele_num-1])\n",
    "                data_dict[\"AC_FIN\"].append(AC_FIN_list[allele_num-1])\n",
    "                data_dict[\"AC_Het\"].append(AC_Het_list[allele_num-1])\n",
    "                data_dict[\"AC_Hom\"].append(AC_Hom_list[allele_num-1])\n",
    "                data_dict[\"AC_NFE\"].append(AC_NFE_list[allele_num-1])\n",
    "                data_dict[\"AC_OTH\"].append(AC_OTH_list[allele_num-1])\n",
    "                data_dict[\"AC_SAS\"].append(AC_SAS_list[allele_num-1])\n",
    "                data_dict[\"AF\"].append(AF_list[allele_num-1])\n",
    "\n",
    "            #Gene\n",
    "            gene_beg = find_nth(CSQ, \"|\", GENE)\n",
    "            gene_end = CSQ.find(\"|\", gene_beg+1)\n",
    "            data_dict[\"gene\"].append(CSQ[gene_beg+1:gene_end])\n",
    "            #Feature\n",
    "            feature_beg = find_nth(CSQ, \"|\", FEATURE)\n",
    "            feature_end = CSQ.find(\"|\", feature_beg+1)\n",
    "            data_dict[\"feature\"].append(CSQ[feature_beg+1:feature_end])\n",
    "            #Feature Type\n",
    "            feature_type_beg = find_nth(CSQ, \"|\", FEATURE_TYPE)\n",
    "            feature_type_end = CSQ.find(\"|\", feature_type_beg+1)\n",
    "            data_dict[\"feature_type\"].append(CSQ[feature_type_beg+1:feature_type_end])\n",
    "            #Consequence\n",
    "            conseq_beg = find_nth(CSQ, \"|\", CONSEQ)\n",
    "            conseq_end = CSQ.find(\"|\", conseq_beg+1)\n",
    "            data_dict[\"conseq\"].append(CSQ[conseq_beg+1:conseq_end])\n",
    "            #Protein_pos\n",
    "            prot_pos_beg = find_nth(CSQ, \"|\", PROT_POS)\n",
    "            prot_pos_end = CSQ.find(\"|\", prot_pos_beg+1)\n",
    "            data_dict[\"prot_pos\"].append(CSQ[prot_pos_beg+1:prot_pos_end])\n",
    "            #Amino Acids\n",
    "            aa_beg = find_nth(CSQ, \"|\", AMINO_ACIDS)\n",
    "            aa_end = CSQ.find(\"|\", aa_beg+1)\n",
    "            data_dict[\"amino_acids\"].append(CSQ[aa_beg+1:aa_end])\n",
    "            #Codons\n",
    "            codons_beg = find_nth(CSQ, \"|\", CODONS)\n",
    "            codons_end = CSQ.find(\"|\", codons_beg+1)\n",
    "            data_dict[\"codons\"].append(CSQ[codons_beg+1:codons_end])\n",
    "            #Strand\n",
    "            strand_beg = find_nth(CSQ, \"|\", STRAND)\n",
    "            strand_end = CSQ.find(\"|\", strand_beg+1)\n",
    "            data_dict[\"strand\"].append(CSQ[strand_beg+1:strand_end])\n",
    "            #ENSP\n",
    "            ENSP_beg = find_nth(CSQ, \"|\", ENSP)\n",
    "            ENSP_end = CSQ.find(\"|\", ENSP_beg+1)\n",
    "            data_dict[\"ENSP\"].append(CSQ[ENSP_beg+1:ENSP_end])\n",
    "            #Swissprot\n",
    "            swiss_beg = find_nth(CSQ, \"|\", SWISSPROT)\n",
    "            swiss_end = CSQ.find(\"|\", swiss_beg+1)\n",
    "            data_dict[\"SWISSPROT\"].append(CSQ[swiss_beg+1:swiss_end])\n",
    "            #SIFT\n",
    "            sift_beg = find_nth(CSQ, \"|\", SIFT)\n",
    "            sift_end = CSQ.find(\"|\", sift_beg+1)\n",
    "            data_dict[\"SIFT\"].append(CSQ[sift_beg+1:sift_end])\n",
    "            #PolyPhen\n",
    "            polyphen_beg = find_nth(CSQ, \"|\", POLYPHEN)\n",
    "            polyphen_end = CSQ.find(\"|\", polyphen_beg+1)\n",
    "            data_dict[\"PolyPhen\"].append(CSQ[polyphen_beg+1:polyphen_end])\n",
    "            #Exon\n",
    "            exon_beg = find_nth(CSQ, \"|\", EXON)\n",
    "            exon_end = CSQ.find(\"|\", exon_beg+1)\n",
    "            data_dict[\"exon\"].append(CSQ[exon_beg+1:exon_end])\n",
    "            #Intron\n",
    "            intron_beg = find_nth(CSQ, \"|\", INTRON)\n",
    "            intron_end = CSQ.find(\"|\", intron_beg+1)\n",
    "            data_dict[\"intron\"].append(CSQ[intron_beg+1:intron_end])\n",
    "            #Domains\n",
    "            domains_beg = find_nth(CSQ, \"|\", DOMAINS)\n",
    "            domains_end = CSQ.find(\"|\", domains_beg+1)\n",
    "            data_dict[\"domains\"].append(CSQ[domains_beg+1:domains_end])\n",
    "            #clin_sig\n",
    "            clin_sig_beg = find_nth(CSQ, \"|\", CLIN_SIG)\n",
    "            clin_sig_end = CSQ.find(\"|\", clin_sig_beg+1)\n",
    "            data_dict[\"clin_sig\"].append(CSQ[clin_sig_beg+1:clin_sig_end])\n",
    "\n",
    "#Saving the data of the last chromosome\n",
    "data_to_df_csv(data_dict, headlines, chromosome_iter)\n",
    "print \"finished chromosome\"+chromosome_iter\n",
    "\n",
    "vcf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2779\n"
     ]
    }
   ],
   "source": [
    "print multi_allele_skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printouts for clarification - you don't have to run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>ID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>\"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|ALLELE_NUM|DISTANCE|STRAND|SYMBOL|SYMBOL_SOURCE|HGNC_ID|BIOTYPE|CANONICAL|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|SIFT|PolyPhen|EXON|INTRON|DOMAINS|HGVSc|HGVSp|GMAF|AFR_MAF|AMR_MAF|ASN_MAF|EUR_MAF|AA_MAF|EA_MAF|CLIN_SIG|SOMATIC|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF_info|LoF_flags|LoF_filter|LoF\"</td>\n",
       "      <td>CSQ</td>\n",
       "      <td>.</td>\n",
       "      <td>String</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description  \\\n",
       "70  \"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|Existing_variation|ALLELE_NUM|DISTANCE|STRAND|SYMBOL|SYMBOL_SOURCE|HGNC_ID|BIOTYPE|CANONICAL|CCDS|ENSP|SWISSPROT|TREMBL|UNIPARC|SIFT|PolyPhen|EXON|INTRON|DOMAINS|HGVSc|HGVSp|GMAF|AFR_MAF|AMR_MAF|ASN_MAF|EUR_MAF|AA_MAF|EA_MAF|CLIN_SIG|SOMATIC|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|LoF_info|LoF_flags|LoF_filter|LoF\"   \n",
       "\n",
       "     ID Number    Type  \n",
       "70  CSQ      .  String  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The different fields of the CSQ\n",
    "pd.options.display.max_colwidth =600\n",
    "info_df[info_df['ID'] == \"CSQ\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>ID</th>\n",
       "      <th>Number</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Allele count in genotypes</td>\n",
       "      <td>AC</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"African/African American Allele Counts\"</td>\n",
       "      <td>AC_AFR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"American Allele Counts\"</td>\n",
       "      <td>AC_AMR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Adjusted Allele Counts\"</td>\n",
       "      <td>AC_Adj</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"East Asian Allele Counts\"</td>\n",
       "      <td>AC_EAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"Finnish Allele Counts\"</td>\n",
       "      <td>AC_FIN</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Adjusted Hemizygous Counts\"</td>\n",
       "      <td>AC_Hemi</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"Adjusted Heterozygous Counts\"</td>\n",
       "      <td>AC_Het</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"Adjusted Homozygous Counts\"</td>\n",
       "      <td>AC_Hom</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Non-Finnish European Allele Counts\"</td>\n",
       "      <td>AC_NFE</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"Other Allele Counts\"</td>\n",
       "      <td>AC_OTH</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\"South Asian Allele Counts\"</td>\n",
       "      <td>AC_SAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\"Allele Frequency</td>\n",
       "      <td>AF</td>\n",
       "      <td>A</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Total number of alleles in called genotypes\"</td>\n",
       "      <td>AN</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>\"African/African American Chromosome Count\"</td>\n",
       "      <td>AN_AFR</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"American Chromosome Count\"</td>\n",
       "      <td>AN_AMR</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"Adjusted Chromosome Count\"</td>\n",
       "      <td>AN_Adj</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>\"East Asian Chromosome Count\"</td>\n",
       "      <td>AN_EAS</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Finnish Chromosome Count\"</td>\n",
       "      <td>AN_FIN</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>\"Non-Finnish European Chromosome Count\"</td>\n",
       "      <td>AN_NFE</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\"Other Chromosome Count\"</td>\n",
       "      <td>AN_OTH</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>\"South Asian Chromosome Count\"</td>\n",
       "      <td>AN_SAS</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>\"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\"</td>\n",
       "      <td>BaseQRankSum</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>\"Number of called chromosomes\"</td>\n",
       "      <td>CCC</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>\"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA...</td>\n",
       "      <td>CSQ</td>\n",
       "      <td>.</td>\n",
       "      <td>String</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>\"Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\"</td>\n",
       "      <td>ClippingRankSum</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>\"dbSNP Membership\"</td>\n",
       "      <td>DB</td>\n",
       "      <td>0</td>\n",
       "      <td>Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"Approximate read depth; some reads may have been filtered\"</td>\n",
       "      <td>DP</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>\"Histogram for DP; Mids: 2.5|7.5|12.5|17.5|22.5|27.5|32.5|37.5|42.5|47.5|52.5|57.5|62.5|67.5|72....</td>\n",
       "      <td>DP_HIST</td>\n",
       "      <td>A</td>\n",
       "      <td>String</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\"Were any of the samples downsampled?\"</td>\n",
       "      <td>DS</td>\n",
       "      <td>0</td>\n",
       "      <td>Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"Non-Finnish European Hemizygous Counts\"</td>\n",
       "      <td>Hemi_NFE</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"Other Hemizygous Counts\"</td>\n",
       "      <td>Hemi_OTH</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\"South Asian Hemizygous Counts\"</td>\n",
       "      <td>Hemi_SAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"African/African American Heterozygous Counts\"</td>\n",
       "      <td>Het_AFR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\"American Heterozygous Counts\"</td>\n",
       "      <td>Het_AMR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"East Asian Heterozygous Counts\"</td>\n",
       "      <td>Het_EAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"Finnish Heterozygous Counts\"</td>\n",
       "      <td>Het_FIN</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\"Non-Finnish European Heterozygous Counts\"</td>\n",
       "      <td>Het_NFE</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\"Other Heterozygous Counts\"</td>\n",
       "      <td>Het_OTH</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\"South Asian Heterozygous Counts\"</td>\n",
       "      <td>Het_SAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\"African/African American Homozygous Counts\"</td>\n",
       "      <td>Hom_AFR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>\"American Homozygous Counts\"</td>\n",
       "      <td>Hom_AMR</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>\"East Asian Homozygous Counts\"</td>\n",
       "      <td>Hom_EAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>\"Finnish Homozygous Counts\"</td>\n",
       "      <td>Hom_FIN</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>\"Non-Finnish European Homozygous Counts\"</td>\n",
       "      <td>Hom_NFE</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>\"Other Homozygous Counts\"</td>\n",
       "      <td>Hom_OTH</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>\"South Asian Homozygous Counts\"</td>\n",
       "      <td>Hom_SAS</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>\"Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared agai...</td>\n",
       "      <td>InbreedingCoeff</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>\"Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC)</td>\n",
       "      <td>MLEAC</td>\n",
       "      <td>A</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>\"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF)</td>\n",
       "      <td>MLEAF</td>\n",
       "      <td>A</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>\"RMS Mapping Quality\"</td>\n",
       "      <td>MQ</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>\"Total Mapping Quality Zero Reads\"</td>\n",
       "      <td>MQ0</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>\"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\"</td>\n",
       "      <td>MQRankSum</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>\"Number of no-called samples\"</td>\n",
       "      <td>NCC</td>\n",
       "      <td>1</td>\n",
       "      <td>Integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>\"This variant was used to build the negative training set of bad variants\"</td>\n",
       "      <td>NEGATIVE_TRAIN_SITE</td>\n",
       "      <td>0</td>\n",
       "      <td>Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\"This variant was used to build the positive training set of good variants\"</td>\n",
       "      <td>POSITIVE_TRAIN_SITE</td>\n",
       "      <td>0</td>\n",
       "      <td>Flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>\"Variant Confidence/Quality by Depth\"</td>\n",
       "      <td>QD</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>\"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\"</td>\n",
       "      <td>ReadPosRankSum</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\"Log odds ratio of being a true variant versus being false under the trained gaussian mixture mo...</td>\n",
       "      <td>VQSLOD</td>\n",
       "      <td>1</td>\n",
       "      <td>Float</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>\"The annotation which was the worst performing in the Gaussian mixture model</td>\n",
       "      <td>culprit</td>\n",
       "      <td>1</td>\n",
       "      <td>String</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            Description  \\\n",
       "0                                                                            \"Allele count in genotypes   \n",
       "1                                                              \"African/African American Allele Counts\"   \n",
       "2                                                                              \"American Allele Counts\"   \n",
       "3                                                                              \"Adjusted Allele Counts\"   \n",
       "4                                                                            \"East Asian Allele Counts\"   \n",
       "5                                                                               \"Finnish Allele Counts\"   \n",
       "6                                                                          \"Adjusted Hemizygous Counts\"   \n",
       "7                                                                        \"Adjusted Heterozygous Counts\"   \n",
       "8                                                                          \"Adjusted Homozygous Counts\"   \n",
       "9                                                                  \"Non-Finnish European Allele Counts\"   \n",
       "10                                                                                \"Other Allele Counts\"   \n",
       "11                                                                          \"South Asian Allele Counts\"   \n",
       "12                                                                                    \"Allele Frequency   \n",
       "13                                                        \"Total number of alleles in called genotypes\"   \n",
       "14                                                          \"African/African American Chromosome Count\"   \n",
       "15                                                                          \"American Chromosome Count\"   \n",
       "16                                                                          \"Adjusted Chromosome Count\"   \n",
       "17                                                                        \"East Asian Chromosome Count\"   \n",
       "18                                                                           \"Finnish Chromosome Count\"   \n",
       "19                                                              \"Non-Finnish European Chromosome Count\"   \n",
       "20                                                                             \"Other Chromosome Count\"   \n",
       "21                                                                       \"South Asian Chromosome Count\"   \n",
       "22                                  \"Z-score from Wilcoxon rank sum test of Alt Vs. Ref base qualities\"   \n",
       "23                                                                       \"Number of called chromosomes\"   \n",
       "70  \"Consequence type as predicted by VEP. Format: Allele|Gene|Feature|Feature_type|Consequence|cDNA...   \n",
       "24                    \"Z-score From Wilcoxon rank sum test of Alt vs. Ref number of hard clipped bases\"   \n",
       "25                                                                                   \"dbSNP Membership\"   \n",
       "26                                          \"Approximate read depth; some reads may have been filtered\"   \n",
       "68  \"Histogram for DP; Mids: 2.5|7.5|12.5|17.5|22.5|27.5|32.5|37.5|42.5|47.5|52.5|57.5|62.5|67.5|72....   \n",
       "27                                                               \"Were any of the samples downsampled?\"   \n",
       "..                                                                                                  ...   \n",
       "38                                                             \"Non-Finnish European Hemizygous Counts\"   \n",
       "39                                                                            \"Other Hemizygous Counts\"   \n",
       "40                                                                      \"South Asian Hemizygous Counts\"   \n",
       "41                                                       \"African/African American Heterozygous Counts\"   \n",
       "42                                                                       \"American Heterozygous Counts\"   \n",
       "43                                                                     \"East Asian Heterozygous Counts\"   \n",
       "44                                                                        \"Finnish Heterozygous Counts\"   \n",
       "45                                                           \"Non-Finnish European Heterozygous Counts\"   \n",
       "46                                                                          \"Other Heterozygous Counts\"   \n",
       "47                                                                    \"South Asian Heterozygous Counts\"   \n",
       "48                                                         \"African/African American Homozygous Counts\"   \n",
       "49                                                                         \"American Homozygous Counts\"   \n",
       "50                                                                       \"East Asian Homozygous Counts\"   \n",
       "51                                                                          \"Finnish Homozygous Counts\"   \n",
       "52                                                             \"Non-Finnish European Homozygous Counts\"   \n",
       "53                                                                            \"Other Homozygous Counts\"   \n",
       "54                                                                      \"South Asian Homozygous Counts\"   \n",
       "55  \"Inbreeding coefficient as estimated from the genotype likelihoods per-sample when compared agai...   \n",
       "56     \"Maximum likelihood expectation (MLE) for the allele counts (not necessarily the same as the AC)   \n",
       "57  \"Maximum likelihood expectation (MLE) for the allele frequency (not necessarily the same as the AF)   \n",
       "58                                                                                \"RMS Mapping Quality\"   \n",
       "59                                                                   \"Total Mapping Quality Zero Reads\"   \n",
       "60                          \"Z-score From Wilcoxon rank sum test of Alt vs. Ref read mapping qualities\"   \n",
       "61                                                                        \"Number of no-called samples\"   \n",
       "62                           \"This variant was used to build the negative training set of bad variants\"   \n",
       "63                          \"This variant was used to build the positive training set of good variants\"   \n",
       "64                                                                \"Variant Confidence/Quality by Depth\"   \n",
       "65                              \"Z-score from Wilcoxon rank sum test of Alt vs. Ref read position bias\"   \n",
       "66  \"Log odds ratio of being a true variant versus being false under the trained gaussian mixture mo...   \n",
       "67                         \"The annotation which was the worst performing in the Gaussian mixture model   \n",
       "\n",
       "                     ID Number     Type  \n",
       "0                    AC      A  Integer  \n",
       "1                AC_AFR      A  Integer  \n",
       "2                AC_AMR      A  Integer  \n",
       "3                AC_Adj      A  Integer  \n",
       "4                AC_EAS      A  Integer  \n",
       "5                AC_FIN      A  Integer  \n",
       "6               AC_Hemi      A  Integer  \n",
       "7                AC_Het      A  Integer  \n",
       "8                AC_Hom      A  Integer  \n",
       "9                AC_NFE      A  Integer  \n",
       "10               AC_OTH      A  Integer  \n",
       "11               AC_SAS      A  Integer  \n",
       "12                   AF      A    Float  \n",
       "13                   AN      1  Integer  \n",
       "14               AN_AFR      1  Integer  \n",
       "15               AN_AMR      1  Integer  \n",
       "16               AN_Adj      1  Integer  \n",
       "17               AN_EAS      1  Integer  \n",
       "18               AN_FIN      1  Integer  \n",
       "19               AN_NFE      1  Integer  \n",
       "20               AN_OTH      1  Integer  \n",
       "21               AN_SAS      1  Integer  \n",
       "22         BaseQRankSum      1    Float  \n",
       "23                  CCC      1  Integer  \n",
       "70                  CSQ      .   String  \n",
       "24      ClippingRankSum      1    Float  \n",
       "25                   DB      0     Flag  \n",
       "26                   DP      1  Integer  \n",
       "68              DP_HIST      A   String  \n",
       "27                   DS      0     Flag  \n",
       "..                  ...    ...      ...  \n",
       "38             Hemi_NFE      A  Integer  \n",
       "39             Hemi_OTH      A  Integer  \n",
       "40             Hemi_SAS      A  Integer  \n",
       "41              Het_AFR      A  Integer  \n",
       "42              Het_AMR      A  Integer  \n",
       "43              Het_EAS      A  Integer  \n",
       "44              Het_FIN      A  Integer  \n",
       "45              Het_NFE      A  Integer  \n",
       "46              Het_OTH      A  Integer  \n",
       "47              Het_SAS      A  Integer  \n",
       "48              Hom_AFR      A  Integer  \n",
       "49              Hom_AMR      A  Integer  \n",
       "50              Hom_EAS      A  Integer  \n",
       "51              Hom_FIN      A  Integer  \n",
       "52              Hom_NFE      A  Integer  \n",
       "53              Hom_OTH      A  Integer  \n",
       "54              Hom_SAS      A  Integer  \n",
       "55      InbreedingCoeff      1    Float  \n",
       "56                MLEAC      A  Integer  \n",
       "57                MLEAF      A    Float  \n",
       "58                   MQ      1    Float  \n",
       "59                  MQ0      1  Integer  \n",
       "60            MQRankSum      1    Float  \n",
       "61                  NCC      1  Integer  \n",
       "62  NEGATIVE_TRAIN_SITE      0     Flag  \n",
       "63  POSITIVE_TRAIN_SITE      0     Flag  \n",
       "64                   QD      1    Float  \n",
       "65       ReadPosRankSum      1    Float  \n",
       "66               VQSLOD      1    Float  \n",
       "67              culprit      1   String  \n",
       "\n",
       "[71 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The info fields of the meta-data\n",
    "pd.options.display.max_colwidth =100\n",
    "info_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

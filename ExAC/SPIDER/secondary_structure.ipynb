{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPIDER2 Secondary Structure\n",
    "\n",
    "Creates dictionaries with SPIDER2 characteristics for each domain\n",
    "\n",
    "SPIDER2 with HSE can be downloaded from http://sparks-lab.org/index.php/Main/Downloads.\n",
    "Follow the instructions in the README to setup.\n",
    "\n",
    "### Other Requirements:\n",
    "1. List of domains\n",
    "2. List of genes associated with each domain and sequences\n",
    "\n",
    "### Running:\n",
    "Run the cells in order\n",
    "\n",
    "### Output:\n",
    "A dictionary for each domain where each position has a solvent accessibility score, contact number, and predicted secondary structure, along with the other outputs of SPIDER2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get list of genes for all domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import cPickle as pickle\n",
    "\n",
    "# Getting path\n",
    "files_dir = '/Users/davidandrewtodd/summer_research/ExAC/' \n",
    "spider_dir = '/Users/davidandrewtodd/summer_research/ExAC/SPIDER/SPIDER2/protein_seq_results'\n",
    "\n",
    "# Reading the list of filtered domains\n",
    "with open(files_dir+\"5.domains_stats/pfam-v31/filtered10_list.pik\", 'rb') as handle:\n",
    "    filtered_domains_list10 = pickle.load(handle)\n",
    "filtered_domains_list10.sort()\n",
    "\n",
    "# Map of all genes to protein seqs\n",
    "with open(files_dir+\"3.parse_HMMER/canonic_prot_seq/pfam-v31/all_domains_genes_prot_seq.pik\", 'rb') as handle:\n",
    "    all_genes = pickle.load(handle)\n",
    "    \n",
    "# Diff between v30 and v31\n",
    "with open(spider_dir+\"/../../v30-v31_diff_domains_genes_prot_seq.pik\", 'rb') as handle:\n",
    "    diff_genes = pickle.load(handle)\n",
    "    \n",
    "chromosome_names = ['X','Y']\n",
    "for i in range(1,23):\n",
    "    chromosome_names.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Map domain to sequences of canonic proteins\n",
    "\n",
    "domain_to_protein_seq_dict = defaultdict(dict)\n",
    "\n",
    "genes_list = []\n",
    "\n",
    "for domain_name in filtered_domains_list10:\n",
    "    #Get the canonic protein id\n",
    "    with open(files_dir+\"4.parse_Uniprot/domains_canonic_prot/pfam-v31/\"+domain_name+\"_canonic_prot.pik\", 'rb') as handle:\n",
    "        canonic_protein = pickle.load(handle)\n",
    "    \n",
    "    for gene in canonic_protein:\n",
    "        # Restrict to diff dictionary\n",
    "        if not gene in diff_genes:\n",
    "            continue\n",
    "        # No need to process a gene twice\n",
    "        if gene in domain_to_protein_seq_dict[domain_name]:\n",
    "            continue\n",
    "        domain_to_protein_seq_dict[domain_name][gene] = {}\n",
    "        \n",
    "        # Get sequence\n",
    "        protein = canonic_protein[gene]\n",
    "        \n",
    "        for prot in diff_genes[gene].keys():\n",
    "            domain_to_protein_seq_dict[domain_name][gene][prot] = diff_genes[gene][prot].replace('*','').replace('-','').replace('X','').replace('.',' ').upper()\n",
    "        \n",
    "        genes_list.append(gene)\n",
    "    #print(\"Finished domain \"+domain_name)\n",
    "\n",
    "# Saving to file\n",
    "with open(files_dir+'SPIDER/domain_to_protein_seq_dict.pik', 'wb') as handle:\n",
    "    pickle.dump(domain_to_protein_seq_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SPIDER2 program\n",
    "\n",
    "After downloading SPIDER from the link above, generate a .seq file in the seq/ directory for each gene, and make the call:\n",
    "\n",
    "    run_local filename.seq\n",
    "    \n",
    "from the directory that contains run_local.sh\n",
    "\n",
    "See the rerun code below as an example.\n",
    "\n",
    "-------------\n",
    "\n",
    "Alternately, for running on a cluster, move the dictionary domain_to_protein_seq_dict created above to a directory that contains run_spider.py and spider2.py, in addition to the same file structure as the local environment described above (that is with the SPIDER code). Make the call:\n",
    "\n",
    "    python run_spider.py\n",
    "    \n",
    "to submit all necessary jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for genes that crashed and rerun as needed\n",
    "\n",
    "Skip these next two cells if everything worked perfectly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dirfiles = !ls -t $'./SPIDER2/protein_seq_results/out'\n",
    "\n",
    "# Only look at new out jobs\n",
    "threshold = 4018018\n",
    "\n",
    "for f in dirfiles:\n",
    "    # Only check out files\n",
    "    if f[len(f)-3:len(f)] != 'out' or int(f.split(\"-\")[1].split(\".\")[0]) <= threshold:\n",
    "        continue\n",
    "    # Check for print statement at end\n",
    "    out = open(spider_dir+'/out/'+f).read()\n",
    "    if not 'SUCCESS!!!' in out or 'Error' in out:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerunning might take a bit, so only do it if you're sure\n",
    "import subprocess\n",
    "rerun_list = ['ENSG00000085276.13-ENSP00000417899.1']\n",
    "\n",
    "for term in rerun_list:\n",
    "    gene = term.split(\"-\")[0]\n",
    "    prot = term.split(\"-\")[1]\n",
    "    # Save sequence to file\n",
    "    filename = files_dir+\"/SPIDER/seq/\"+term.replace('.','-')+'.seq'\n",
    "    with open(filename,'w') as f:\n",
    "        f.write(diff_genes[gene][prot].replace('*',''))\n",
    "    f.close\n",
    "\n",
    "    # Run SPIDER2\n",
    "    subprocess.call([files_dir+'/SPIDER/misc/run_local.sh',filename])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the raw output files into dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract features from files\n",
    "def read_file(filepath,output_dict):\n",
    "    # Differentiate between files with same feature names\n",
    "    tokens = filepath.split('.')\n",
    "    extension = tokens[len(tokens)-1]\n",
    "    \n",
    "    # Read files and save to dict\n",
    "    with open(filepath,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            # Parse header\n",
    "            if line[0] == '#':\n",
    "                tokens = line.split()\n",
    "                features = tokens[1:len(tokens)]\n",
    "                continue\n",
    "\n",
    "            # Parse lines\n",
    "            tokens = line.split()\n",
    "            if not int(tokens[0]) in output_dict.keys():\n",
    "                output_dict[int(tokens[0])] = {}\n",
    "            for i in range(0,len(features)):\n",
    "                output_dict[int(tokens[0])][extension+\"_\"+features[i]] = tokens[i+1]\n",
    "\n",
    "\n",
    "# Load genes to aa sequence mapping for each domain\n",
    "with open(files_dir+\"SPIDER/domain_to_protein_seq_dict.pik\", 'rb') as handle:\n",
    "    domain_to_protein_seq_dict = pickle.load(handle)\n",
    "    \n",
    "    \n",
    "# For testing\n",
    "num_excluded = 0\n",
    "no_spd3 = []\n",
    "no_hsa2 = []\n",
    "no_hsb2 = []\n",
    "\n",
    "# Read files and save to dict\n",
    "for domain in domain_to_protein_seq_dict:\n",
    "    secondary_struct_dict = defaultdict(dict)\n",
    "    \n",
    "    for gene in domain_to_protein_seq_dict[domain]:\n",
    "        if gene not in all_genes:\n",
    "            num_excluded += 1\n",
    "            continue\n",
    "\n",
    "        secondary_struct_dict[gene] = {}\n",
    "        \n",
    "        # Should only be one protein\n",
    "        prot = domain_to_protein_seq_dict[domain][gene].keys()[0]\n",
    "            \n",
    "        # Some files also include the protein name, so check if this is the case first\n",
    "        prefix = gene.replace('.','-') + \"-\" + prot.replace('.','-')\n",
    "        if not os.path.isfile(spider_dir+\"/pssm/\"+prefix+\".pssm\"):\n",
    "            prefix = gene.replace('.','-')\n",
    "\n",
    "        try:\n",
    "            read_file(spider_dir+\"/spd3/\"+prefix+\".spd3\",secondary_struct_dict[gene])\n",
    "        except IOError:\n",
    "            no_spd3.append(gene)\n",
    "\n",
    "        try:\n",
    "            read_file(spider_dir+\"/hsa2/\"+prefix+\".hsa2\",secondary_struct_dict[gene])\n",
    "        except IOError:\n",
    "            no_hsa2.append(gene)\n",
    "\n",
    "        try:\n",
    "            read_file(spider_dir+\"/hsb2/\"+prefix+\".hsb2\",secondary_struct_dict[gene])\n",
    "        except IOError:\n",
    "            no_hsb2.append(gene)\n",
    "            \n",
    "    print(secondary_struct_dict.keys())\n",
    "                \n",
    "    # Check if dict for domain already present\n",
    "    try:\n",
    "        with open(spider_dir+'/domain_dicts/'+domain+'_secondary_struct_dict.pik', 'rb') as handle:\n",
    "            old_dict = pickle.load(handle)\n",
    "        print(old_dict.keys())\n",
    "        # Overwrites old info if overlap\n",
    "        old_dict.update(secondary_struct_dict)\n",
    "        secondary_struct_dict = old_dict\n",
    "    except IOError:\n",
    "        pass\n",
    "        \n",
    "    # Save to file\n",
    "    with open(spider_dir+'/domain_dicts_diff/'+domain+'_secondary_struct_dict.pik', 'wb') as handle:\n",
    "        pickle.dump(secondary_struct_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check if file missing\n",
    "print(num_excluded)\n",
    "print(len(no_spd3))\n",
    "print(len(no_hsa2))\n",
    "print(len(no_hsb2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

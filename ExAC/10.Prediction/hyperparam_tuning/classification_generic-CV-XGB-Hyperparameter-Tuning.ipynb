{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve, average_precision_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "import xgboost as xgb\n",
    "\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "#from matplotlib.pylab import rcParams\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "#from sklearn.grid_search import \n",
    "\n",
    "\n",
    "#Downsamplers imports - prototype generation\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "#Downsamplers imports - prototype selection - controlled\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RepeatedEditedNearestNeighbours\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques - Condensed nearest neighbors and derived algorithms\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, OneSidedSelection, NeighbourhoodCleaningRule\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "ABSOLUTE_NEGATIVES = False\n",
    "FILTER_DOMAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples positions #: 38944\n"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "input_path = curr_dir[0]+\"/domains_similarity/filtered_features_table/\"\n",
    "filename = \"positions_features_mediode_filter_01.25.18.csv\"\n",
    "\n",
    "#input_path = curr_dir[0]+\"/../9.Features_exploration/binding_df/10/\"\n",
    "#filename = \"positions_features_01.25.18.csv\"\n",
    "\n",
    "bind_scores_num = 10\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "features_cols = features_all.columns[1:-bind_scores_num] #removing binding scores and domain name\n",
    "ligands = [\"dna\", \"dnabase\", \"dnabackbone\", \"rna\", \"rnabase\", \"rnabackbone\", \"peptide\", \"ion\", \"metabolite\"]\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#lignd binding domains dictionary\n",
    "with open(curr_dir[0]+\"/ligands_negatives_domains_dict.pik\", 'rb') as handle:\n",
    "        negatives_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_to_ligand_binding_domains(use_max_binding_score):\n",
    "    \n",
    "    ligands_negatives_df = {}\n",
    "    for ligand in ligands:\n",
    "        \n",
    "        ligands_negatives_df[ligand] = pd.DataFrame()\n",
    "        for domain in negatives_dict[ligand].keys():\n",
    "            if domain == 'negatives' or domain == 'domains':\n",
    "                continue\n",
    "            domain_all = features_all.loc[features_all.loc[:,\"domain_name\"] == domain,:]\n",
    "            \n",
    "            #In case this domain was previously filtered\n",
    "            if len(domain_all) == 0:\n",
    "                continue\n",
    "            \n",
    "            if (use_max_binding_score):\n",
    "                ligands_negatives_df[ligand] = pd.concat([ligands_negatives_df[ligand],domain_all.loc[domain_all.loc[:,\"max_binding_score\"] == 0,:]])\n",
    "            else:\n",
    "                ligand_bind_str = ligand+\"_binding_score\"\n",
    "                ligands_negatives_df[ligand] = pd.concat([ligands_negatives_df[ligand],domain_all.loc[domain_all.loc[:,ligand_bind_str] == 0,:]])\n",
    "        \n",
    "    #Handeling the ligand \"all_ligands\"\n",
    "    all_ligands_negatives_df = pd.concat([ligands_negatives_df[\"dna\"], ligands_negatives_df[\"dnabase\"], ligands_negatives_df[\"dnabackbone\"], ligands_negatives_df[\"rna\"], ligands_negatives_df[\"rnabase\"], \n",
    "                                 ligands_negatives_df[\"rnabackbone\"], ligands_negatives_df[\"ion\"], ligands_negatives_df[\"peptide\"], ligands_negatives_df[\"metabolite\"]])\n",
    "    all_ligands_negatives_df = all_ligands_negatives_df.drop_duplicates()\n",
    "    #Filter to just positions with max. binding score = 0\n",
    "    all_ligands_negatives_df = all_ligands_negatives_df[all_ligands_negatives_df[\"max_binding_score\"] == 0]\n",
    "    ligands_negatives_df[\"all_ligands\"] = all_ligands_negatives_df\n",
    "    \n",
    "    #Leaving just the features columns\n",
    "    for ligand in ligands_negatives_df.keys():   \n",
    "        ligands_negatives_df[ligand] = ligands_negatives_df[ligand][features_cols]\n",
    "        print(ligand+\" non-binding #:\"+str(len(ligands_negatives_df[ligand])))\n",
    "    \n",
    "    return ligands_negatives_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negatives_by_binding_score(use_max_binding_score):\n",
    "    \n",
    "    ligands_negatives_df = {}\n",
    "    for ligand in ligands:\n",
    "        \n",
    "        if use_max_binding_score:\n",
    "            ligand_bind_str = \"max_binding_score\"\n",
    "        else:\n",
    "            ligand_bind_str = ligand+\"_binding_score\"\n",
    "        \n",
    "        ligands_negatives_df[ligand] = features_all[features_all[ligand_bind_str] == 0]\n",
    "        ligands_negatives_df[ligand] = ligands_negatives_df[ligand].loc[:,features_cols]\n",
    "        print(ligand+\" non-binding #:\"+str(len(ligands_negatives_df[ligand])))\n",
    "        \n",
    "    #Handeling the ligand \"all_ligands\"\n",
    "    ligands_negatives_df[\"all_ligands\"] = features_all[features_all[\"max_binding_score\"] == 0]\n",
    "    ligands_negatives_df[\"all_ligands\"] = ligands_negatives_df[\"all_ligands\"].loc[:,features_cols]\n",
    "    print(\"all_ligands non-binding #:\"+str(len(ligands_negatives_df[\"all_ligands\"])))\n",
    "    \n",
    "    return ligands_negatives_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:38095\n",
      "dnabase non-binding #:38577\n",
      "dnabackbone non-binding #:38203\n",
      "rna non-binding #:38047\n",
      "rnabase non-binding #:38407\n",
      "rnabackbone non-binding #:38223\n",
      "peptide non-binding #:35437\n",
      "ion non-binding #:34488\n",
      "metabolite non-binding #:33971\n",
      "all_ligands non-binding #:27191\n"
     ]
    }
   ],
   "source": [
    "#Create negatives datasets\n",
    "if FILTER_DOMAIN:\n",
    "    if ABSOLUTE_NEGATIVES:\n",
    "        ligands_negatives_df = filter_to_ligand_binding_domains(True)\n",
    "    else:\n",
    "        ligands_negatives_df = filter_to_ligand_binding_domains(False)\n",
    "else:\n",
    "    if ABSOLUTE_NEGATIVES:\n",
    "        ligands_negatives_df = negatives_by_binding_score(True)\n",
    "    else:\n",
    "        ligands_negatives_df = negatives_by_binding_score(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 501\n",
      "dnabase #: 193\n",
      "dnabackbone #: 408\n",
      "rna #: 433\n",
      "rnabase #: 224\n",
      "rnabackbone #: 308\n",
      "peptide #: 1496\n",
      "ion #: 1093\n",
      "metabolite #: 1525\n"
     ]
    }
   ],
   "source": [
    "bind_th = 0.1\n",
    "ligands_features_df = {}\n",
    "    \n",
    "for ligand in ligands:\n",
    "    score_col_str = ligand+\"_binding_score\"\n",
    "    ligand_binding_df = features_all[features_all[score_col_str] >= bind_th]\n",
    "    print ligand+\" #: \"+str(ligand_binding_df.shape[0])\n",
    "    ligands_features_df[ligand] = ligand_binding_df.loc[:,features_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of positive examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ligands #: 4518\n"
     ]
    }
   ],
   "source": [
    "all_ligands_features_df = pd.concat([ligands_features_df[\"dna\"], ligands_features_df[\"dnabase\"], ligands_features_df[\"dnabackbone\"], ligands_features_df[\"rna\"], ligands_features_df[\"rnabase\"], \n",
    "                                     ligands_features_df[\"rnabackbone\"], ligands_features_df[\"ion\"], ligands_features_df[\"peptide\"], ligands_features_df[\"metabolite\"]])\n",
    "all_ligands_features_df = all_ligands_features_df.drop_duplicates()\n",
    "print \"all_ligands #: \"+str(all_ligands_features_df.shape[0])\n",
    "ligands_features_df[\"all_ligands\"] = all_ligands_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models tested (and their hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers[\"Logistic\"] = LogisticRegression(C=0.001, random_state=0)\n",
    "classifiers[\"RF\"] = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=0)  \n",
    "#classifiers[\"RF\"] = RandomForestRegressor(n_estimators=1000)  \n",
    "classifiers[\"KNN\"] = KNeighborsClassifier(n_neighbors=100, n_jobs=-1)\n",
    "#classifiers[\"KNN\"] = KNeighborsRegressor(n_neighbors=100)\n",
    "classifiers[\"SVM\"] = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "classifiers[\"ADA-RF\"] = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "classifiers[\"ADA-Log\"] = AdaBoostClassifier(base_estimator=classifiers[\"Logistic\"], n_estimators=1000, random_state=0)\n",
    "#classifiers[\"Bag-Log\"] = BaggingClassifier(base_estimator=classifiers[\"Logistic\"], n_estimators=1000, n_jobs=-1, random_state=0)\n",
    "classifiers[\"XGB\"] = XGBClassifier(n_estimators=1000, n_jobs=-1, random_state=0, max_depth=6, min_child_weight=0.05, colsample_bytree=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsamplers tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#documentation on techniques: http://contrib.scikit-learn.org/imbalanced-learn/stable/under_sampling.html#cleaning-under-sampling-techniques\n",
    "downsamplers = defaultdict(dict)\n",
    "\n",
    "##Prototype generation##\n",
    "downsamplers[\"ClusterCentroids\"] = ClusterCentroids(random_state=0)\n",
    "\n",
    "##Prototype selection##\n",
    "#Contolled#\n",
    "downsamplers[\"RandomUnderSampler\"] = RandomUnderSampler(random_state=0)\n",
    "downsamplers[\"NearMiss3\"] = NearMiss(random_state=0, version=3)\n",
    "downsamplers[\"NearMiss2\"] = NearMiss(random_state=0, version=2)\n",
    "downsamplers[\"NearMiss1\"] = NearMiss(random_state=0, version=1)\n",
    "\n",
    "#Cleaning#\n",
    "downsamplers[\"TomekLinks\"] = TomekLinks(random_state=0)\n",
    "downsamplers[\"EditedNearestNeighbours\"] = EditedNearestNeighbours(random_state=0)\n",
    "downsamplers[\"RepeatedEditedNearestNeighbours\"] = RepeatedEditedNearestNeighbours(random_state=0)\n",
    "downsamplers[\"NeighbourhoodCleaningRule\"] = NeighbourhoodCleaningRule(random_state=0)\n",
    "\n",
    "# Instance hardness threshold#\n",
    "downsamplers[\"InstanceHardnessThreshold\"][\"KNN\"] = InstanceHardnessThreshold(random_state=0, estimator=classifiers[\"KNN\"])\n",
    "#downsamplers[\"InstanceHardnessThreshold\"][\"KNN\"] = InstanceHardnessThreshold(random_state=0, estimator= KNeighborsClassifier(n_neighbors=100))\n",
    "downsamplers[\"InstanceHardnessThreshold\"][\"SVM\"] = InstanceHardnessThreshold(random_state=0, estimator=classifiers[\"SVM\"])\n",
    "downsamplers[\"InstanceHardnessThreshold\"][\"RF\"] = InstanceHardnessThreshold(random_state=0, estimator=classifiers[\"RF\"])\n",
    "#downsamplers[\"InstanceHardnessThreshold\"][\"RF\"] = InstanceHardnessThreshold(random_state=0, estimator=RandomForestClassifier(n_estimators=1000))\n",
    "downsamplers[\"InstanceHardnessThreshold\"][\"Logistic\"] = InstanceHardnessThreshold(random_state=0, estimator=classifiers[\"Logistic\"])\n",
    "#downsamplers[\"InstanceHardnessThreshold\"][\"ADA\"] = InstanceHardnessThreshold(random_state=0, estimator=classifiers[\"ADA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dnabase\n",
      "downsample_method = NoDown\n",
      "classifier_method = XGB\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dnabase\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    downsample_method = environ['down']\n",
    "except:\n",
    "    downsample_method = \"NoDown\"\n",
    "print \"downsample_method = \"+downsample_method\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"XGB\"\n",
    "print \"classifier_method = \"+classifier_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(pred_dict, auc_dict, auprc_dict, ligand_bind_features, ligand_negatives_features, ligand_name, downsample_method, features=[]):\n",
    "    \"\"\"\n",
    "    Test different models in 10-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "        \n",
    "    #Arranging the features table by the CV order, for each model\n",
    "    features_pred_dfs = dict.fromkeys(classifiers.keys())\n",
    "    \n",
    "    models_req_scaling = [\"SVM\", \"KNN\"]\n",
    "    \n",
    "    for classifier in classifiers.keys():\n",
    "        print classifier\n",
    "        classifier = classifier_method\n",
    "        model = classifiers[classifier]\n",
    "        features_pred_dfs[classifier] = pd.DataFrame()\n",
    "        \n",
    "        #Create X and y with included features\n",
    "        X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "        \n",
    "        if (classifier in models_req_scaling):\n",
    "            idx = X.index\n",
    "            cols = X.columns\n",
    "            X = pd.DataFrame(scale(X)) #Is z-scoring the data needed?\n",
    "            X.index = idx #Restoring indices after scaling\n",
    "            X.columns = cols\n",
    "\n",
    "        y = [1] * ligand_bind_features.shape[0]\n",
    "        y.extend([0] * ligand_negatives_features.shape[0])\n",
    "        y = np.array(y)\n",
    "\n",
    "        binding_skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "        pred_idx = 1\n",
    "\n",
    "        for train_index, test_index in binding_skf.split(X, y):\n",
    "            print \"fold #: \"+str(pred_idx)\n",
    "            X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            #Down-sample negative examples to have balanced classes\n",
    "            if (downsample_method == \"NoDown\"):\n",
    "                X_train_sampled = X_train\n",
    "                y_train_sampled = y_train\n",
    "            else:\n",
    "                if (downsample_method == \"InstanceHardnessThreshold\"):\n",
    "                    downsampler = downsamplers[downsample_method][classifier]\n",
    "                else:\n",
    "                    downsampler = downsamplers[downsample_method]\n",
    "\n",
    "                X_train_sampled, y_train_sampled = downsampler.fit_sample(X_train, y_train)\n",
    "            \n",
    "            #fit to training data\n",
    "            model = classifiers[classifier]\n",
    "            model.fit(X_train_sampled, y_train_sampled)\n",
    "            probs_list = []\n",
    "\n",
    "            #probs = model.predict(X_test)\n",
    "            #probs_list = probs\n",
    "            \n",
    "            probs = model.predict_proba(X_test)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "                \n",
    "            pred_dict[\"obs\"].extend(y_test)\n",
    "            pred_dict[\"prob\"].extend(probs_list)\n",
    "            fold_list = [pred_idx] * len(probs_list)\n",
    "            pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "            model_list = [classifier] * len(probs_list)\n",
    "            pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "            #Update auc auprc dictionaries\n",
    "            auc_dict[classifier].append(roc_auc_score(y_test, probs[:, 1]))\n",
    "            precision, recall, _ = precision_recall_curve(y_test, probs[:, 1])\n",
    "            \n",
    "            #auc_dict[classifier].append(roc_auc_score(y_test, probs))\n",
    "            #precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "            \n",
    "            auprc_dict[classifier].append(auc(recall, precision))\n",
    "            \n",
    "            #Update features table\n",
    "            features_pred_dfs[classifier] = features_pred_dfs[classifier].append(X_test)\n",
    "            pred_idx += 1\n",
    "            \n",
    "            print \"AUC = \"+str(auc_dict[classifier][-1])\n",
    "            print \"AUPRC = \"+str(auprc_dict[classifier][-1])\n",
    "\n",
    "        avg_auc = np.sum(auc_dict[classifier])/10.0\n",
    "        print \"avg auc = \"+str(avg_auc)\n",
    "        \n",
    "        avg_auprc = np.sum(auprc_dict[classifier])/10.0\n",
    "        print \"avg auprc = \"+str(avg_auprc)\n",
    "            \n",
    "        print \"Finished \"+ligand+\" \"+classifier\n",
    "        break\n",
    "    \n",
    "    return features_pred_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_features_predictions(ligand, ordered_features, pred_df):\n",
    "    \n",
    "    pred_res = pred_df.copy(deep=True)\n",
    "    for classifier in classifiers.keys():\n",
    "        classifier = classifier_method\n",
    "        model_pred = pred_res[pred_res[\"model\"] == classifier]\n",
    "        model_pred.index = ordered_features[classifier].index\n",
    "        \n",
    "        #Creating the combined table\n",
    "        features_pred = pd.concat([ordered_features[classifier], model_pred], axis=1)\n",
    "        \n",
    "        #Saving\n",
    "        #features_pred.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/mediode_NegLigand_NoFilter/\"+downsample_method+\"/01.25.2018/features_pred_tables/\"+ligand+\"_\"+classifier+\"_features_pred.csv\", sep='\\t')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#for ligand in ligands:\n",
    "#    print ligand\n",
    "\n",
    "#Initialize dictionary\n",
    "#pred_dict = defaultdict(list)\n",
    "#auc_dict = defaultdict(list)\n",
    "#auprc_dict = defaultdict(list)\n",
    "\n",
    "#ordered_features = test_model(pred_dict, auc_dict, auprc_dict, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand, downsample_method)\n",
    "\n",
    "#pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "#auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "#auprc_df = pd.DataFrame.from_dict(auprc_dict)\n",
    "\n",
    "#Save to file\n",
    "#pred_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/mediode_NegLigand_NoFilter/\"+downsample_method+\"/01.25.2018/\"+ligand+\"_\"+classifier_method+\"_0.1.csv\", sep='\\t')\n",
    "#auc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/mediode_NegLigand_NoFilter/\"+downsample_method+\"/01.25.2018/\"+ligand+\"_\"+classifier_method+\"_0.1_auc.csv\", sep='\\t')\n",
    "#auprc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/mediode_NegLigand_NoFilter/\"+downsample_method+\"/01.25.2018/\"+ligand+\"_\"+classifier_method+\"_0.1_auprc.csv\", sep='\\t')\n",
    "\n",
    "#Combine features and pred results to a unified table\n",
    "#combine_features_predictions(ligand, ordered_features, pred_df)\n",
    "\n",
    "#print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, ligand_bind_features, ligand_negatives_features, ligand_name, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print \"modelfit\"\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(X, label=y)\n",
    "    #print alg.get_params()['n_estimators']\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, \n",
    "                      metrics='map', early_stopping_rounds=early_stopping_rounds)\n",
    "    alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    print \"Optimal n_estimators: \" + str(cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    #print \"fitting\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.25)\n",
    "    #print X_train\n",
    "    %time alg.fit(X_train, y_train,eval_metric='map')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    #probs = alg.predict_proba(X_test)\n",
    "    \n",
    "    #Print model report:\n",
    "    #print \"\\nModel Report\"\n",
    "    #auc_score = roc_auc_score(y_test, probs[:, 1])\n",
    "    #print y_test\n",
    "    #print probs[:, 1]\n",
    "    #precision , recall, _ = precision_recall_curve(y_test, probs[:, 1])\n",
    "    #auprc = auc(recall, precision)    \n",
    "\n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy(Train): %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "    print \"Average Precision: %.4g\" % metrics.average_precision_score(y_train, dtrain_predprob)\n",
    "    #print \"AUC (Test) = \"+str(auc_score)\n",
    "    #print \"AUPRC (Test) = \"+str(auprc)\n",
    "    \"\"\"               \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \"\"\"\n",
    "    return alg,cvresult#,dtrain_predictions,dtrain_predprob,alg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit_test(clf,ligand_bind_features, ligand_negatives_features, ligand_name, features=[]):\n",
    "    \"\"\"\n",
    "    Test different models in 10-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "        \n",
    "    #Arranging the features table by the CV order, for each model\n",
    "    features_pred_dfs = dict.fromkeys(classifiers.keys())\n",
    "    \n",
    "    #models_req_scaling = [\"SVM\", \"KNN\"]\n",
    "    \n",
    "    classifier = classifier_method\n",
    "    #model = classifiers[classifier]\n",
    "    model = clf\n",
    "    features_pred_dfs[classifier] = pd.DataFrame()\n",
    "\n",
    "    #Create X and y with included features\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.25)\n",
    "    \n",
    "    #binding_skf = StratifiedKFold(n_splits=1, shuffle=True, random_state=0)\n",
    "    pred_idx = 1\n",
    "\n",
    "    #for train_index, test_index in binding_skf.split(X, y):\n",
    "        #print \"fold #: \"+str(pred_idx)\n",
    "        #X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        #y_train, y_test = y[train_index], y[test_index]\n",
    "    X_train_sampled = X_train\n",
    "    y_train_sampled = y_train\n",
    "        \n",
    "    #fit to training data\n",
    "    %time model.fit(X_train_sampled, y_train_sampled)\n",
    "    probs_list = []\n",
    "        \n",
    "    probs = model.predict_proba(X_test)\n",
    "    for l in probs:\n",
    "        probs_list.append(l[1])\n",
    "        \n",
    "    auc_score = roc_auc_score(y_test, probs[:, 1])\n",
    "    #print y_test\n",
    "    #print probs[:, 1]\n",
    "    precision , recall, _ = precision_recall_curve(y_test, probs[:, 1])\n",
    "    auprc = auc(recall, precision)    \n",
    "    \n",
    "    dtrain_predictions = model.predict(X_train)\n",
    "    dtrain_predprob = model.predict_proba(X_train)[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy(Train): %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "    print \"AUC (Test) = \"+str(auc_score)\n",
    "    print \"AUPRC (Test) = \"+str(auprc)\n",
    "    \n",
    "    \n",
    "    #feat_imp = pd.Series(model.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')\n",
    "                                  \n",
    "    return features_pred_dfs,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to run\n",
      "modelfit\n",
      "Optimal n_estimators: 108\n",
      "CPU times: user 1min 23s, sys: 354 ms, total: 1min 23s\n",
      "Wall time: 21.9 s\n",
      "\n",
      "Model Report\n",
      "Accuracy(Train): 0.9996\n",
      "AUC Score (Train): 1.000000\n",
      "Average Precision: 1\n",
      "Optimal n_estimators: 108\n",
      "CPU times: user 12min 51s, sys: 2.29 s, total: 12min 54s\n",
      "Wall time: 3min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Choose all predictors except target & IDcols\n",
    "\n",
    "#%matplotlib inline\n",
    "#rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "\"\"\"\n",
    "ligand_bind_features = ligands_features_df[ligand]\n",
    "ligand_negatives_features = ligands_negatives_df[ligand]\n",
    "features = features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "train = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "\n",
    "y = [1] * ligand_bind_features.shape[0]\n",
    "y.extend([0] * ligand_negatives_features.shape[0])\n",
    "y = np.array(y)\n",
    "train = train.assign(Disbursed=y)\n",
    "target = 'Disbursed'\n",
    "IDcol = 'ID'\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\"\"\"\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "print \"about to run\"\n",
    "returns = modelfit(xgb1, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "print \"Optimal n_estimators: \"+str(returns[1].shape[0]) \n",
    "optimized_n_est = returns[1].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ligand_bind_features = ligands_features_df[ligand]\n",
    "ligand_negatives_features = ligands_negatives_df[ligand]\n",
    "features = features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "y = [1] * ligand_bind_features.shape[0]\n",
    "y.extend([0] * ligand_negatives_features.shape[0])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making GridSearchCV object\n",
      "Fitting\n",
      "CPU times: user 147 ms, sys: 71 ms, total: 218 ms\n",
      "Wall time: 218 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27, \n",
    " param_grid = param_test1, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=3))\n",
    "print \"Fitting\"\n",
    "gsearch1.fit(X,y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.14453, std: 0.18337, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       " mean: 0.14071, std: 0.18196, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       " mean: 0.15011, std: 0.17757, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       " mean: 0.10233, std: 0.13135, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       " mean: 0.08294, std: 0.06544, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       " mean: 0.11572, std: 0.11639, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       " mean: 0.08769, std: 0.09143, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       " mean: 0.08281, std: 0.06587, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       " mean: 0.09790, std: 0.11390, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       " mean: 0.08695, std: 0.07276, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       " mean: 0.08511, std: 0.07007, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       " mean: 0.09251, std: 0.09015, params: {'max_depth': 9, 'min_child_weight': 5}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making GridSearchCV object\n",
      "Fitting\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=1, min_child_weight=4 .................................\n",
      "[CV]  max_depth=1, min_child_weight=4, score=0.683692652021, total=   6.4s\n",
      "[CV] max_depth=1, min_child_weight=4 .................................\n",
      "[CV]  max_depth=1, min_child_weight=4, score=0.035514267901, total=   6.5s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=1, min_child_weight=4 .................................\n",
      "[CV]  max_depth=1, min_child_weight=4, score=0.0369951634474, total=   6.3s\n",
      "[CV] max_depth=1, min_child_weight=4 .................................\n",
      "[CV]  max_depth=1, min_child_weight=4, score=0.159002309132, total=   6.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   22.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   29.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=1, min_child_weight=4 .................................\n",
      "[CV]  max_depth=1, min_child_weight=4, score=0.0415413885066, total=   6.4s\n",
      "[CV] max_depth=1, min_child_weight=5 .................................\n",
      "[CV]  max_depth=1, min_child_weight=5, score=0.68972048855, total=   6.3s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   37.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   44.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=1, min_child_weight=5 .................................\n",
      "[CV]  max_depth=1, min_child_weight=5, score=0.0346486226579, total=   6.3s\n",
      "[CV] max_depth=1, min_child_weight=5 .................................\n",
      "[CV]  max_depth=1, min_child_weight=5, score=0.0384724467929, total=   6.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   52.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   59.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=1, min_child_weight=5 .................................\n",
      "[CV]  max_depth=1, min_child_weight=5, score=0.148916296532, total=   6.2s\n",
      "[CV] max_depth=1, min_child_weight=5 .................................\n",
      "[CV]  max_depth=1, min_child_weight=5, score=0.0571348192738, total=   6.2s\n",
      "[CV] max_depth=1, min_child_weight=6 .................................\n",
      "[CV]  max_depth=1, min_child_weight=6, score=0.684079833265, total=   6.1s\n",
      "[CV] max_depth=1, min_child_weight=6 .................................\n",
      "[CV]  max_depth=1, min_child_weight=6, score=0.0343248050016, total=   6.2s\n",
      "[CV] max_depth=1, min_child_weight=6 .................................\n",
      "[CV]  max_depth=1, min_child_weight=6, score=0.0456784784749, total=   6.3s\n",
      "[CV] max_depth=1, min_child_weight=6 .................................\n",
      "[CV]  max_depth=1, min_child_weight=6, score=0.145841281561, total=   6.4s\n",
      "[CV] max_depth=1, min_child_weight=6 .................................\n",
      "[CV]  max_depth=1, min_child_weight=6, score=0.085279204625, total=   6.1s\n",
      "[CV] max_depth=2, min_child_weight=4 .................................\n",
      "[CV]  max_depth=2, min_child_weight=4, score=0.505582400737, total=   9.0s\n",
      "[CV] max_depth=2, min_child_weight=4 .................................\n",
      "[CV]  max_depth=2, min_child_weight=4, score=0.0403095801676, total=   8.9s\n",
      "[CV] max_depth=2, min_child_weight=4 .................................\n",
      "[CV]  max_depth=2, min_child_weight=4, score=0.0358531224028, total=   9.3s\n",
      "[CV] max_depth=2, min_child_weight=4 .................................\n",
      "[CV]  max_depth=2, min_child_weight=4, score=0.139751744033, total=   9.4s\n",
      "[CV] max_depth=2, min_child_weight=4 .................................\n",
      "[CV]  max_depth=2, min_child_weight=4, score=0.0289585226978, total=   9.5s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV]  max_depth=2, min_child_weight=5, score=0.496269881492, total=   9.3s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV]  max_depth=2, min_child_weight=5, score=0.0395419313786, total=   9.2s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV]  max_depth=2, min_child_weight=5, score=0.0431267251003, total=   9.3s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV]  max_depth=2, min_child_weight=5, score=0.16057465257, total=   9.2s\n",
      "[CV] max_depth=2, min_child_weight=5 .................................\n",
      "[CV]  max_depth=2, min_child_weight=5, score=0.0254916226836, total=   9.1s\n",
      "[CV] max_depth=2, min_child_weight=6 .................................\n",
      "[CV]  max_depth=2, min_child_weight=6, score=0.592320584324, total=   9.5s\n",
      "[CV] max_depth=2, min_child_weight=6 .................................\n",
      "[CV]  max_depth=2, min_child_weight=6, score=0.0405199802689, total=   9.4s\n",
      "[CV] max_depth=2, min_child_weight=6 .................................\n",
      "[CV]  max_depth=2, min_child_weight=6, score=0.0413502098415, total=   9.4s\n",
      "[CV] max_depth=2, min_child_weight=6 .................................\n",
      "[CV]  max_depth=2, min_child_weight=6, score=0.109770045658, total=   9.0s\n",
      "[CV] max_depth=2, min_child_weight=6 .................................\n",
      "[CV]  max_depth=2, min_child_weight=6, score=0.0254269139537, total=   9.0s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV]  max_depth=3, min_child_weight=4, score=0.527496029309, total=  12.3s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV]  max_depth=3, min_child_weight=4, score=0.0349492978448, total=  12.2s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV]  max_depth=3, min_child_weight=4, score=0.0303660279401, total=  12.2s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV]  max_depth=3, min_child_weight=4, score=0.15207467494, total=  12.4s\n",
      "[CV] max_depth=3, min_child_weight=4 .................................\n",
      "[CV]  max_depth=3, min_child_weight=4, score=0.0486612541254, total=  12.0s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.496770159552, total=  12.1s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.0352555874352, total=  12.3s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.0320126203969, total=  12.5s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.137290475083, total=  12.3s\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV]  max_depth=3, min_child_weight=5, score=0.0492290219572, total=  12.1s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV]  max_depth=3, min_child_weight=6, score=0.510991169185, total=  12.1s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV]  max_depth=3, min_child_weight=6, score=0.0330693315181, total=  12.0s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV]  max_depth=3, min_child_weight=6, score=0.0346017881579, total=  12.0s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV]  max_depth=3, min_child_weight=6, score=0.166699153958, total=  12.1s\n",
      "[CV] max_depth=3, min_child_weight=6 .................................\n",
      "[CV]  max_depth=3, min_child_weight=6, score=0.0484073959009, total=  12.1s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV]  max_depth=4, min_child_weight=4, score=0.419740966541, total=  15.0s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV]  max_depth=4, min_child_weight=4, score=0.0290102340876, total=  15.1s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV]  max_depth=4, min_child_weight=4, score=0.0281463735436, total=  15.1s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV]  max_depth=4, min_child_weight=4, score=0.17365444083, total=  14.9s\n",
      "[CV] max_depth=4, min_child_weight=4 .................................\n",
      "[CV]  max_depth=4, min_child_weight=4, score=0.0538311639528, total=  15.5s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV]  max_depth=4, min_child_weight=5, score=0.432219499282, total=  15.2s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV]  max_depth=4, min_child_weight=5, score=0.0308024604866, total=  15.3s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV]  max_depth=4, min_child_weight=5, score=0.0269252080245, total=  15.1s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV]  max_depth=4, min_child_weight=5, score=0.161940025065, total=  15.1s\n",
      "[CV] max_depth=4, min_child_weight=5 .................................\n",
      "[CV]  max_depth=4, min_child_weight=5, score=0.0497321161326, total=  14.9s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV]  max_depth=4, min_child_weight=6, score=0.389473911272, total=  15.0s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV]  max_depth=4, min_child_weight=6, score=0.0281182886141, total=  14.9s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV]  max_depth=4, min_child_weight=6, score=0.0265798128344, total=  14.9s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV]  max_depth=4, min_child_weight=6, score=0.104138317034, total=  14.9s\n",
      "[CV] max_depth=4, min_child_weight=6 .................................\n",
      "[CV]  max_depth=4, min_child_weight=6, score=0.0496882667434, total=  14.8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 39min 20s, sys: 21.8 s, total: 39min 41s\n",
      "Wall time: 11min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "optimized_n_est = 98\n",
    "param_test2 = {\n",
    " 'max_depth':[1,2,3,4],#range(3,10,2),\n",
    " 'min_child_weight':[4,5,6]#range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=10)\n",
    "print \"Fitting\"\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "opt_max_depth = gsearch2.best_params_[\"max_depth\"]\n",
    "opt_min_child_weight = gsearch2.best_params[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.19135, std: 0.25060, params: {'max_depth': 1, 'min_child_weight': 4},\n",
       "  mean: 0.19378, std: 0.25143, params: {'max_depth': 1, 'min_child_weight': 5},\n",
       "  mean: 0.19904, std: 0.24564, params: {'max_depth': 1, 'min_child_weight': 6},\n",
       "  mean: 0.15009, std: 0.18235, params: {'max_depth': 2, 'min_child_weight': 4},\n",
       "  mean: 0.15300, std: 0.17838, params: {'max_depth': 2, 'min_child_weight': 5},\n",
       "  mean: 0.16188, std: 0.21720, params: {'max_depth': 2, 'min_child_weight': 6},\n",
       "  mean: 0.15871, std: 0.18971, params: {'max_depth': 3, 'min_child_weight': 4},\n",
       "  mean: 0.15011, std: 0.17757, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.15875, std: 0.18304, params: {'max_depth': 3, 'min_child_weight': 6},\n",
       "  mean: 0.14088, std: 0.14942, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.14032, std: 0.15410, params: {'max_depth': 4, 'min_child_weight': 5},\n",
       "  mean: 0.11960, std: 0.13783, params: {'max_depth': 4, 'min_child_weight': 6}],\n",
       " {'max_depth': 1, 'min_child_weight': 6})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_max_depth = gsearch2.best_params_[\"max_depth\"]\n",
    "gsearch2.grid_scores_,gsearch2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  6.0min finished\n",
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making GridSearchCV object\n",
      "Fitting\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-54476f5b248a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'optimized_n_est = 98\\nparam_test2 = {\\n \\'min_child_weight\\':[6,8,10,12,14,16,18,20,22,24]#range(1,6,2)\\n}\\nprint \"Making GridSearchCV object\"\\ngsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=opt_max_depth,\\n min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\\n objective= \\'binary:logistic\\', nthread=4, scale_pos_weight=1, seed=27), \\n param_grid = param_test2, scoring=\\'average_precision\\',n_jobs=1,iid=False, cv=5, verbose=1)\\nprint \"Fitting\"\\ngsearch2.fit(X,y)\\ngsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\\nopt_min_child_weight = gsearch2.best_params[\"min_child_weight\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_params'"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "optimized_n_est = 98\n",
    "param_test2 = {\n",
    " 'min_child_weight':[6,8,10,12,14,16,18,20,22,24]#range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=opt_max_depth,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=1)\n",
    "print \"Fitting\"\n",
    "gsearch2.fit(X,y)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "opt_min_child_weight = gsearch2.best_params_[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.19904, std: 0.24564, params: {'min_child_weight': 6},\n",
       " mean: 0.14365, std: 0.10743, params: {'min_child_weight': 8},\n",
       " mean: 0.16635, std: 0.12464, params: {'min_child_weight': 10},\n",
       " mean: 0.15985, std: 0.10408, params: {'min_child_weight': 12},\n",
       " mean: 0.22473, std: 0.21265, params: {'min_child_weight': 14},\n",
       " mean: 0.23041, std: 0.24218, params: {'min_child_weight': 16},\n",
       " mean: 0.22585, std: 0.24681, params: {'min_child_weight': 18},\n",
       " mean: 0.22531, std: 0.25044, params: {'min_child_weight': 20},\n",
       " mean: 0.22125, std: 0.24620, params: {'min_child_weight': 22},\n",
       " mean: 0.22623, std: 0.24473, params: {'min_child_weight': 24}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch2.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt_max_depth = 1\n",
    "opt_min_child_weight = 16\n",
    "optimized_n_est = 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] ........................................ gamma=0.0, total=   5.4s\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] ........................................ gamma=0.0, total=   5.2s\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] ........................................ gamma=0.0, total=   5.2s\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] ........................................ gamma=0.0, total=   5.3s\n",
      "[CV] gamma=0.0 .......................................................\n",
      "[CV] ........................................ gamma=0.0, total=   5.2s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   5.2s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   5.2s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   5.2s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   5.2s\n",
      "[CV] gamma=0.1 .......................................................\n",
      "[CV] ........................................ gamma=0.1, total=   5.3s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] ........................................ gamma=0.2, total=   5.4s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] ........................................ gamma=0.2, total=   5.3s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] ........................................ gamma=0.2, total=   5.4s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] ........................................ gamma=0.2, total=   5.3s\n",
      "[CV] gamma=0.2 .......................................................\n",
      "[CV] ........................................ gamma=0.2, total=   5.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ........................................ gamma=0.3, total=   5.4s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ........................................ gamma=0.3, total=   5.3s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ........................................ gamma=0.3, total=   5.2s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ........................................ gamma=0.3, total=   5.2s\n",
      "[CV] gamma=0.3 .......................................................\n",
      "[CV] ........................................ gamma=0.3, total=   5.2s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ........................................ gamma=0.4, total=   5.3s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ........................................ gamma=0.4, total=   5.2s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ........................................ gamma=0.4, total=   5.1s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ........................................ gamma=0.4, total=   5.2s\n",
      "[CV] gamma=0.4 .......................................................\n",
      "[CV] ........................................ gamma=0.4, total=   5.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[mean: 0.23041, std: 0.24218, params: {'gamma': 0.0}, mean: 0.23041, std: 0.24218, params: {'gamma': 0.1}, mean: 0.23041, std: 0.24218, params: {'gamma': 0.2}, mean: 0.23041, std: 0.24218, params: {'gamma': 0.3}, mean: 0.23041, std: 0.24218, params: {'gamma': 0.4}] {'gamma': 0.0} 0.23041349903421232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='average_precision',n_jobs=1,iid=False, cv=5,verbose=2)\n",
    "gsearch3.fit(X,y)\n",
    "print gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "opt_gamma = gsearch3.best_params_[\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch3.grid_scores_\n",
    "opt_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsharan/miniconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.06643, std: 0.02815, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       " mean: 0.06781, std: 0.02693, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       " mean: 0.06845, std: 0.02790, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       " mean: 0.06256, std: 0.02220, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       " mean: 0.06280, std: 0.02203, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       " mean: 0.06606, std: 0.02392, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       " mean: 0.06009, std: 0.02191, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       " mean: 0.06245, std: 0.02378, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       " mean: 0.06526, std: 0.02807, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       " mean: 0.06134, std: 0.02261, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       " mean: 0.06147, std: 0.02359, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       " mean: 0.06347, std: 0.02713, params: {'max_depth': 9, 'min_child_weight': 5}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_gamma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] objective=reg:linear ............................................\n",
      "[CV] ...... objective=reg:linear, score=0.0674008103229, total= 1.7min\n",
      "[CV] objective=reg:linear ............................................\n",
      "[CV] ...... objective=reg:linear, score=0.0206680681253, total= 1.7min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] objective=reg:linear ............................................\n",
      "[CV] ...... objective=reg:linear, score=0.0168567222175, total= 1.7min\n",
      "[CV] objective=reg:linear ............................................\n",
      "[CV] ...... objective=reg:linear, score=0.0317870364368, total= 1.7min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] objective=reg:linear ............................................\n",
      "[CV] ...... objective=reg:linear, score=0.0527066819977, total= 1.7min\n",
      "[CV] objective=binary:logistic .......................................\n",
      "[CV] .. objective=binary:logistic, score=0.291835621816, total= 1.8min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 10.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] objective=binary:logistic .......................................\n",
      "[CV] . objective=binary:logistic, score=0.0242029477699, total= 1.8min\n",
      "[CV] objective=binary:logistic .......................................\n",
      "[CV] . objective=binary:logistic, score=0.0218292191785, total= 1.8min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 12.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 14.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] objective=binary:logistic .......................................\n",
      "[CV] . objective=binary:logistic, score=0.0754873503236, total= 1.8min\n",
      "[CV] objective=binary:logistic .......................................\n",
      "[CV] . objective=binary:logistic, score=0.0685046548804, total= 1.8min"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 15.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 17.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1h 38min 4s, sys: 4.86 s, total: 1h 38min 9s\n",
      "Wall time: 20min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ligand_bind_features = ligands_features_df[ligand]\n",
    "ligand_negatives_features = ligands_negatives_df[ligand]\n",
    "features = features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "y = [1] * ligand_bind_features.shape[0]\n",
    "y.extend([0] * ligand_negatives_features.shape[0])\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "param_test2 = {\n",
    "    #'max_depth':[1],\n",
    "    #'min_child_weight':range(1,6,2),\n",
    "    'objective':['reg:linear','binary:logistic']\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier(n_estimators=1000, n_jobs=5, random_state=0, max_depth=6, min_child_weight=0, colsample_bytree=0.5), \n",
    " param_grid = param_test2, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose = 10)\n",
    "gsearch4.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelfit\n",
      "Optimal n_estimators: 553\n",
      "CPU times: user 1min 35s, sys: 206 ms, total: 1min 35s\n",
      "Wall time: 25 s\n",
      "\n",
      "Model Report\n",
      "Accuracy(Train): 0.9957\n",
      "AUC Score (Train): 0.971171\n",
      "Optimal n_estimators: 553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight,\n",
    " gamma=opt_gamma,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "returns = modelfit(xgb2, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "print \"Optimal n_estimators: \"+str(returns[1].shape[0]) \n",
    "optimized_n_est_new = returns[1].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.6, score=0.694812607951, total=   5.5s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.6, score=0.0585643227998, total=   5.4s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   13.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.6, score=0.12467589588, total=   5.3s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.6, score=0.150642010309, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.6, score=0.101328776833, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.6, score=0.692534304121, total=   5.5s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.6, score=0.0416589623288, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.6, score=0.165510288351, total=   5.5s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.6, score=0.164292490471, total=   5.5s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.6, score=0.0811733319638, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.6, score=0.696763941004, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.6, score=0.0352861548228, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.6, score=0.180424968457, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.6, score=0.155409280243, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.6, score=0.0685589173606, total=   5.5s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.6, score=0.646752468915, total=   5.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.6, score=0.0350740757539, total=   5.2s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.6, score=0.166764969364, total=   5.3s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.6, score=0.159221181371, total=   5.3s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.6 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.6, score=0.0966855025925, total=   5.5s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.6, score=0.45465858439, total=  23.1s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.6, score=0.0520095913075, total=  23.2s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.6, score=0.0834862029141, total=  23.5s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.6, score=0.159352203393, total=  23.3s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.6, score=0.0951490537336, total=  23.2s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.6, score=0.329719770676, total=  23.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.6, score=0.0474650599939, total=  22.6s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.6, score=0.0698291340026, total=  22.4s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.6, score=0.142716957524, total=  22.8s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.6, score=0.106302462059, total=  22.9s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.6, score=0.273044981662, total=  22.8s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.6, score=0.0441914176654, total=  22.2s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.6, score=0.0516559884618, total=  23.1s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.6, score=0.155497068033, total=  22.9s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.6, score=0.0875330749495, total=  22.8s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.6, score=0.231421823992, total=  22.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.6, score=0.043631378634, total=  22.9s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.6, score=0.0520613755124, total=  22.3s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.6, score=0.149487659401, total=  22.7s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.6, score=0.100135225744, total=  23.0s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.7, score=0.713738977462, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.7, score=0.0389404652039, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.7, score=0.126434822437, total=   6.0s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.7, score=0.162265497957, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.7, score=0.0687758436923, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.7, score=0.694812937188, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.7, score=0.0388681809204, total=   6.0s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.7, score=0.172138384732, total=   6.0s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.7, score=0.156185294267, total=   5.9s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.7, score=0.0751585558523, total=   5.8s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.7, score=0.709370589107, total=   5.8s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.7, score=0.0363579578725, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.7, score=0.166704808516, total=   5.7s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.7, score=0.169353651273, total=   5.7s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.7, score=0.0870075920501, total=   5.8s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.7, score=0.642080236996, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.7, score=0.0367152885252, total=   5.7s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.7, score=0.139860455032, total=   5.7s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.7, score=0.163262547457, total=   5.6s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.7 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.7, score=0.106328990491, total=   5.6s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.7, score=0.498168107505, total=  25.0s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.7, score=0.0484110579791, total=  25.3s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.7, score=0.0961656898158, total=  24.8s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.7, score=0.150737320298, total=  24.9s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.7, score=0.118729227525, total=  24.7s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.7, score=0.352772167523, total=  25.0s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.7, score=0.0475344766699, total=  25.0s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.7, score=0.0637278905696, total=  25.3s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.7, score=0.146150513808, total=  25.2s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.7, score=0.107503417201, total=  24.8s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.7, score=0.263536615438, total=  24.9s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.7, score=0.0438782366331, total=  24.8s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.7, score=0.0541494617009, total=  25.4s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.7, score=0.162638079053, total=  25.0s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.7, score=0.0890866149404, total=  24.9s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.7, score=0.222280219888, total=  24.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.7, score=0.0432682344771, total=  24.0s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.7, score=0.0502408015403, total=  24.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.7, score=0.15058353989, total=  24.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.7, score=0.0976338242228, total=  24.4s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.8, score=0.712468746392, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.8, score=0.0343955427522, total=   6.3s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.8, score=0.126415396616, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.8, score=0.168885207977, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.8, score=0.073196229309, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.8, score=0.690396760823, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.8, score=0.036764497654, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.8, score=0.162522528944, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.8, score=0.168339723424, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.8, score=0.0659385195695, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.8, score=0.706661037737, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.8, score=0.0378266665192, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.8, score=0.156540927461, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.8, score=0.156339342591, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.8, score=0.0946995208636, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.8, score=0.633888154266, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.8, score=0.039887553193, total=   6.0s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.8, score=0.141588222342, total=   6.2s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.8, score=0.167063517287, total=   6.1s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.8 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.8, score=0.0923035401569, total=   6.1s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.8, score=0.475112468115, total=  27.6s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.8, score=0.0473186911958, total=  26.9s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.8, score=0.0833003827713, total=  27.9s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.8, score=0.155748416945, total=  27.2s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.8, score=0.0914616988494, total=  27.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.8, score=0.335562975317, total=  26.8s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.8, score=0.0482748026565, total=  27.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.8, score=0.0675867341782, total=  27.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.8, score=0.148556308629, total=  27.3s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.8, score=0.0875636771348, total=  27.2s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.8, score=0.303369654333, total=  27.0s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.8, score=0.0454982480902, total=  26.6s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.8, score=0.0586982091539, total=  26.5s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.8, score=0.161997035144, total=  26.8s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.8, score=0.0992784572937, total=  26.9s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.8, score=0.225054521435, total=  27.0s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.8, score=0.0436076877108, total=  26.5s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.8, score=0.0505032137323, total=  26.9s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.8, score=0.151753236227, total=  26.9s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.8, score=0.10106643965, total=  26.6s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.9, score=0.704259371251, total=   6.7s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.9, score=0.0373952436502, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.9, score=0.119534547848, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.9, score=0.172013346572, total=   6.5s\n",
      "[CV] n_estimators=98, subsample=0.6, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.6, colsample_bytree=0.9, score=0.0762526127753, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.9, score=0.683635929488, total=   6.5s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.9, score=0.0495878210287, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.9, score=0.133432410578, total=   6.7s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.9, score=0.159166077757, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.7, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.7, colsample_bytree=0.9, score=0.0701086606057, total=   6.5s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.9, score=0.714376392489, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.9, score=0.0385054211086, total=   6.5s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.9, score=0.169140901788, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.9, score=0.16066464721, total=   6.6s\n",
      "[CV] n_estimators=98, subsample=0.8, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.8, colsample_bytree=0.9, score=0.0701367438428, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.9, score=0.648479860036, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.9, score=0.0388000406682, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.9, score=0.146575657313, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.9, score=0.163261040987, total=   6.4s\n",
      "[CV] n_estimators=98, subsample=0.9, colsample_bytree=0.9 ............\n",
      "[CV]  n_estimators=98, subsample=0.9, colsample_bytree=0.9, score=0.0912733113208, total=   6.4s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.9, score=0.453578963305, total=  28.9s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.9, score=0.0480110336927, total=  28.8s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.9, score=0.0816367239308, total=  29.1s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.9, score=0.157400289592, total=  29.5s\n",
      "[CV] n_estimators=553, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.6, colsample_bytree=0.9, score=0.086655537128, total=  29.6s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.9, score=0.359527838821, total=  29.0s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.9, score=0.0463190881494, total=  29.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.9, score=0.0557628631488, total=  29.1s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.9, score=0.1472208397, total=  29.4s\n",
      "[CV] n_estimators=553, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.7, colsample_bytree=0.9, score=0.0984867718905, total=  28.8s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.9, score=0.307657254443, total=  29.1s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.9, score=0.0445697878257, total=  29.0s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.9, score=0.0564503568626, total=  28.5s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.9, score=0.163946665627, total=  28.0s\n",
      "[CV] n_estimators=553, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.8, colsample_bytree=0.9, score=0.0912705787121, total=  28.7s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.9, score=0.221532417926, total=  28.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.9, score=0.0431234078036, total=  28.4s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.9, score=0.0536457221484, total=  28.6s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.9, score=0.149835467271, total=  28.6s\n",
      "[CV] n_estimators=553, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=553, subsample=0.9, colsample_bytree=0.9, score=0.103923884295, total=  28.7s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 45.7min finished\n",
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[mean: 0.22600, std: 0.23635, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.6}, mean: 0.22903, std: 0.23666, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.6}, mean: 0.22729, std: 0.24076, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.6}, mean: 0.22090, std: 0.21820, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.6}, mean: 0.16893, std: 0.14707, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.6}, mean: 0.13921, std: 0.10062, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.6}, mean: 0.12238, std: 0.08500, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.6}, mean: 0.11535, std: 0.06931, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.6}, mean: 0.22203, std: 0.24960, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.7}, mean: 0.22743, std: 0.23888, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.23376, std: 0.24304, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.21765, std: 0.21646, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.18244, std: 0.16134, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.7}, mean: 0.14354, std: 0.11015, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.12266, std: 0.08182, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.11280, std: 0.06692, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.22307, std: 0.24894, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.8}, mean: 0.22479, std: 0.23851, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.23041, std: 0.24218, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.21495, std: 0.21395, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.17059, std: 0.15622, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.8}, mean: 0.13751, std: 0.10459, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.13377, std: 0.09400, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.11440, std: 0.06769, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.22189, std: 0.24531, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.9}, mean: 0.21919, std: 0.23565, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.23056, std: 0.24713, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.21768, std: 0.21981, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.9}, mean: 0.16546, std: 0.14840, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.9}, mean: 0.14146, std: 0.11474, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.13278, std: 0.09683, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.11441, std: 0.06575, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.9}] {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.7} 0.23375891976379512\n"
     ]
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'n_estimators':[optimized_n_est,optimized_n_est_new],\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=98, max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight, gamma=opt_gamma, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='average_precision',n_jobs=1,iid=False, cv=5,verbose=3)\n",
    "gsearch4.fit(X,y)\n",
    "print gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7, 'n_estimators': 98, 'subsample': 0.8}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gsearch4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.22600, std: 0.23635, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       " mean: 0.22903, std: 0.23666, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       " mean: 0.22729, std: 0.24076, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       " mean: 0.22090, std: 0.21820, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       " mean: 0.16893, std: 0.14707, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       " mean: 0.13921, std: 0.10062, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       " mean: 0.12238, std: 0.08500, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       " mean: 0.11535, std: 0.06931, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       " mean: 0.22203, std: 0.24960, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       " mean: 0.22743, std: 0.23888, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       " mean: 0.23376, std: 0.24304, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       " mean: 0.21765, std: 0.21646, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       " mean: 0.18244, std: 0.16134, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       " mean: 0.14354, std: 0.11015, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       " mean: 0.12266, std: 0.08182, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       " mean: 0.11280, std: 0.06692, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       " mean: 0.22307, std: 0.24894, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       " mean: 0.22479, std: 0.23851, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       " mean: 0.23041, std: 0.24218, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       " mean: 0.21495, std: 0.21395, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       " mean: 0.17059, std: 0.15622, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       " mean: 0.13751, std: 0.10459, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       " mean: 0.13377, std: 0.09400, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       " mean: 0.11440, std: 0.06769, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       " mean: 0.22189, std: 0.24531, params: {'n_estimators': 98, 'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       " mean: 0.21919, std: 0.23565, params: {'n_estimators': 98, 'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       " mean: 0.23056, std: 0.24713, params: {'n_estimators': 98, 'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       " mean: 0.21768, std: 0.21981, params: {'n_estimators': 98, 'subsample': 0.9, 'colsample_bytree': 0.9},\n",
       " mean: 0.16546, std: 0.14840, params: {'n_estimators': 553, 'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       " mean: 0.14146, std: 0.11474, params: {'n_estimators': 553, 'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       " mean: 0.13278, std: 0.09683, params: {'n_estimators': 553, 'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       " mean: 0.11441, std: 0.06575, params: {'n_estimators': 553, 'subsample': 0.9, 'colsample_bytree': 0.9}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch4.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsearch4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a761fb93f26f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgsearch4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gsearch4' is not defined"
     ]
    }
   ],
   "source": [
    "type(gsearch4.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

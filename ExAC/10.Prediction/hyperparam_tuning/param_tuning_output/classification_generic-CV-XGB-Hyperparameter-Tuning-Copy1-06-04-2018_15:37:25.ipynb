{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve, average_precision_score, make_scorer\n",
    "from sklearn.model_selection import StratifiedKFold,train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "import xgboost as xgb\n",
    "\n",
    "#import matplotlib.pylab as plt\n",
    "\n",
    "#from matplotlib.pylab import rcParams\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "#from sklearn.grid_search import \n",
    "\n",
    "\n",
    "#Downsamplers imports - prototype generation\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "#Downsamplers imports - prototype selection - controlled\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours, RepeatedEditedNearestNeighbours\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques - Condensed nearest neighbors and derived algorithms\n",
    "from imblearn.under_sampling import CondensedNearestNeighbour, OneSidedSelection, NeighbourhoodCleaningRule\n",
    "\n",
    "#Downsamplers imports - prototype selection - Cleaning techniques\n",
    "from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")\n",
    "\n",
    "ABSOLUTE_NEGATIVES = False\n",
    "FILTER_DOMAIN = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples positions #: 38944\n"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "input_path = curr_dir[0]+\"/domains_similarity/filtered_features_table/\"\n",
    "filename = \"positions_features_mediode_filter_01.25.18.csv\"\n",
    "\n",
    "#input_path = curr_dir[0]+\"/../9.Features_exploration/binding_df/10/\"\n",
    "#filename = \"positions_features_01.25.18.csv\"\n",
    "\n",
    "bind_scores_num = 10\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "features_cols = features_all.columns[1:-bind_scores_num] #removing binding scores and domain name\n",
    "ligands = [\"dna\", \"dnabase\", \"dnabackbone\", \"rna\", \"rnabase\", \"rnabackbone\", \"peptide\", \"ion\", \"metabolite\"]\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#lignd binding domains dictionary\n",
    "with open(curr_dir[0]+\"/ligands_negatives_domains_dict.pik\", 'rb') as handle:\n",
    "        negatives_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_to_ligand_binding_domains(use_max_binding_score):\n",
    "    \n",
    "    ligands_negatives_df = {}\n",
    "    for ligand in ligands:\n",
    "        \n",
    "        ligands_negatives_df[ligand] = pd.DataFrame()\n",
    "        for domain in negatives_dict[ligand].keys():\n",
    "            if domain == 'negatives' or domain == 'domains':\n",
    "                continue\n",
    "            domain_all = features_all.loc[features_all.loc[:,\"domain_name\"] == domain,:]\n",
    "            \n",
    "            #In case this domain was previously filtered\n",
    "            if len(domain_all) == 0:\n",
    "                continue\n",
    "            \n",
    "            if (use_max_binding_score):\n",
    "                ligands_negatives_df[ligand] = pd.concat([ligands_negatives_df[ligand],domain_all.loc[domain_all.loc[:,\"max_binding_score\"] == 0,:]])\n",
    "            else:\n",
    "                ligand_bind_str = ligand+\"_binding_score\"\n",
    "                ligands_negatives_df[ligand] = pd.concat([ligands_negatives_df[ligand],domain_all.loc[domain_all.loc[:,ligand_bind_str] == 0,:]])\n",
    "        \n",
    "    #Handeling the ligand \"all_ligands\"\n",
    "    all_ligands_negatives_df = pd.concat([ligands_negatives_df[\"dna\"], ligands_negatives_df[\"dnabase\"], ligands_negatives_df[\"dnabackbone\"], ligands_negatives_df[\"rna\"], ligands_negatives_df[\"rnabase\"], \n",
    "                                 ligands_negatives_df[\"rnabackbone\"], ligands_negatives_df[\"ion\"], ligands_negatives_df[\"peptide\"], ligands_negatives_df[\"metabolite\"]])\n",
    "    all_ligands_negatives_df = all_ligands_negatives_df.drop_duplicates()\n",
    "    #Filter to just positions with max. binding score = 0\n",
    "    all_ligands_negatives_df = all_ligands_negatives_df[all_ligands_negatives_df[\"max_binding_score\"] == 0]\n",
    "    ligands_negatives_df[\"all_ligands\"] = all_ligands_negatives_df\n",
    "    \n",
    "    #Leaving just the features columns\n",
    "    for ligand in ligands_negatives_df.keys():   \n",
    "        ligands_negatives_df[ligand] = ligands_negatives_df[ligand][features_cols]\n",
    "        print(ligand+\" non-binding #:\"+str(len(ligands_negatives_df[ligand])))\n",
    "    \n",
    "    return ligands_negatives_df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negatives_by_binding_score(use_max_binding_score):\n",
    "    \n",
    "    ligands_negatives_df = {}\n",
    "    for ligand in ligands:\n",
    "        \n",
    "        if use_max_binding_score:\n",
    "            ligand_bind_str = \"max_binding_score\"\n",
    "        else:\n",
    "            ligand_bind_str = ligand+\"_binding_score\"\n",
    "        \n",
    "        ligands_negatives_df[ligand] = features_all[features_all[ligand_bind_str] == 0]\n",
    "        ligands_negatives_df[ligand] = ligands_negatives_df[ligand].loc[:,features_cols]\n",
    "        print(ligand+\" non-binding #:\"+str(len(ligands_negatives_df[ligand])))\n",
    "        \n",
    "    #Handeling the ligand \"all_ligands\"\n",
    "    ligands_negatives_df[\"all_ligands\"] = features_all[features_all[\"max_binding_score\"] == 0]\n",
    "    ligands_negatives_df[\"all_ligands\"] = ligands_negatives_df[\"all_ligands\"].loc[:,features_cols]\n",
    "    print(\"all_ligands non-binding #:\"+str(len(ligands_negatives_df[\"all_ligands\"])))\n",
    "    \n",
    "    return ligands_negatives_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:38095\n",
      "dnabase non-binding #:38577\n",
      "dnabackbone non-binding #:38203\n",
      "rna non-binding #:38047\n",
      "rnabase non-binding #:38407\n",
      "rnabackbone non-binding #:38223\n",
      "peptide non-binding #:35437\n",
      "ion non-binding #:34488\n",
      "metabolite non-binding #:33971\n",
      "all_ligands non-binding #:27191\n"
     ]
    }
   ],
   "source": [
    "#Create negatives datasets\n",
    "if FILTER_DOMAIN:\n",
    "    if ABSOLUTE_NEGATIVES:\n",
    "        ligands_negatives_df = filter_to_ligand_binding_domains(True)\n",
    "    else:\n",
    "        ligands_negatives_df = filter_to_ligand_binding_domains(False)\n",
    "else:\n",
    "    if ABSOLUTE_NEGATIVES:\n",
    "        ligands_negatives_df = negatives_by_binding_score(True)\n",
    "    else:\n",
    "        ligands_negatives_df = negatives_by_binding_score(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 501\n",
      "dnabase #: 193\n",
      "dnabackbone #: 408\n",
      "rna #: 433\n",
      "rnabase #: 224\n",
      "rnabackbone #: 308\n",
      "peptide #: 1496\n",
      "ion #: 1093\n",
      "metabolite #: 1525\n"
     ]
    }
   ],
   "source": [
    "bind_th = 0.1\n",
    "ligands_features_df = {}\n",
    "    \n",
    "for ligand in ligands:\n",
    "    score_col_str = ligand+\"_binding_score\"\n",
    "    ligand_binding_df = features_all[features_all[score_col_str] >= bind_th]\n",
    "    print ligand+\" #: \"+str(ligand_binding_df.shape[0])\n",
    "    ligands_features_df[ligand] = ligand_binding_df.loc[:,features_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of positive examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ligands #: 4518\n"
     ]
    }
   ],
   "source": [
    "all_ligands_features_df = pd.concat([ligands_features_df[\"dna\"], ligands_features_df[\"dnabase\"], ligands_features_df[\"dnabackbone\"], ligands_features_df[\"rna\"], ligands_features_df[\"rnabase\"], \n",
    "                                     ligands_features_df[\"rnabackbone\"], ligands_features_df[\"ion\"], ligands_features_df[\"peptide\"], ligands_features_df[\"metabolite\"]])\n",
    "all_ligands_features_df = all_ligands_features_df.drop_duplicates()\n",
    "print \"all_ligands #: \"+str(all_ligands_features_df.shape[0])\n",
    "ligands_features_df[\"all_ligands\"] = all_ligands_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dnabase\n",
      "downsample_method = NoDown\n",
      "classifier_method = XGB\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dnabase\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    downsample_method = environ['down']\n",
    "except:\n",
    "    downsample_method = \"NoDown\"\n",
    "print \"downsample_method = \"+downsample_method\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"XGB\"\n",
    "print \"classifier_method = \"+classifier_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, ligand_bind_features, ligand_negatives_features, ligand_name, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "    features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print \"modelfit\"\n",
    "    xgb_param = alg.get_xgb_params()\n",
    "    xgtrain = xgb.DMatrix(X, label=y)\n",
    "    #print alg.get_params()['n_estimators']\n",
    "    cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds, \n",
    "                      metrics='map', early_stopping_rounds=early_stopping_rounds)\n",
    "    alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    print \"Optimal n_estimators: \" + str(cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    #print \"fitting\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,stratify=y,test_size=0.25)\n",
    "    #print X_train\n",
    "    %time alg.fit(X_train, y_train,eval_metric='map')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "    \n",
    "    #Predict test set:\n",
    "    #probs = alg.predict_proba(X_test)\n",
    "    \n",
    "    #Print model report:\n",
    "    #print \"\\nModel Report\"\n",
    "    #auc_score = roc_auc_score(y_test, probs[:, 1])\n",
    "    #print y_test\n",
    "    #print probs[:, 1]\n",
    "    #precision , recall, _ = precision_recall_curve(y_test, probs[:, 1])\n",
    "    #auprc = auc(recall, precision)    \n",
    "\n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy(Train): %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "    print \"Average Precision: %.4g\" % metrics.average_precision_score(y_train, dtrain_predprob)\n",
    "    #print \"AUC (Test) = \"+str(auc_score)\n",
    "    #print \"AUPRC (Test) = \"+str(auprc)\n",
    "    \"\"\"               \n",
    "    feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    \"\"\"\n",
    "    return alg,cvresult#,dtrain_predictions,dtrain_predprob,alg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "about to run\n",
      "modelfit\n",
      "Optimal n_estimators: 108\n",
      "CPU times: user 1min 23s, sys: 167 ms, total: 1min 23s\n",
      "Wall time: 21.9 s\n",
      "\n",
      "Model Report\n",
      "Accuracy(Train): 0.9996\n",
      "AUC Score (Train): 1.000000\n",
      "Average Precision: 1\n",
      "Optimal n_estimators: 108\n",
      "CPU times: user 12min 53s, sys: 2.14 s, total: 12min 55s\n",
      "Wall time: 3min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Choose all predictors except target & IDcols\n",
    "\n",
    "#%matplotlib inline\n",
    "#rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "\"\"\"\n",
    "ligand_bind_features = ligands_features_df[ligand]\n",
    "ligand_negatives_features = ligands_negatives_df[ligand]\n",
    "features = features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "train = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "\n",
    "y = [1] * ligand_bind_features.shape[0]\n",
    "y.extend([0] * ligand_negatives_features.shape[0])\n",
    "y = np.array(y)\n",
    "train = train.assign(Disbursed=y)\n",
    "target = 'Disbursed'\n",
    "IDcol = 'ID'\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "\"\"\"\n",
    "\n",
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "print \"about to run\"\n",
    "returns = modelfit(xgb1, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "print \"Optimal n_estimators: \"+str(returns[1].shape[0]) \n",
    "optimized_n_est = returns[1].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ligand_bind_features = ligands_features_df[ligand]\n",
    "ligand_negatives_features = ligands_negatives_df[ligand]\n",
    "features = features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "y = [1] * ligand_bind_features.shape[0]\n",
    "y.extend([0] * ligand_negatives_features.shape[0])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%time\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27),\n",
    " param_grid = param_test1, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=3)\n",
    "print \"Fitting\"\n",
    "#gsearch1.fit(X,y)\n",
    "#gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "%%time \n",
    "optimized_n_est = 98\n",
    "param_test2 = {\n",
    " 'max_depth':[1,2,3,4],#range(3,10,2),\n",
    " 'min_child_weight':[4,5,6]#range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=10)\n",
    "print \"Fitting\"\n",
    "#gsearch2.fit(X,y)\n",
    "#gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "#opt_max_depth = gsearch2.best_params_[\"max_depth\"]\n",
    "#opt_min_child_weight = gsearch2.best_params[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "%%time \n",
    "optimized_n_est = 98\n",
    "param_test2 = {\n",
    " 'min_child_weight':[6,8,10,12,14,16,18,20,22,24]#range(1,6,2)\n",
    "}\n",
    "print \"Making GridSearchCV object\"\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=opt_max_depth,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test2, scoring='average_precision',n_jobs=1,iid=False, cv=5, verbose=1)\n",
    "print \"Fitting\"\n",
    "#gsearch2.fit(X,y)\n",
    "#gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_\n",
    "#opt_min_child_weight = gsearch2.best_params_[\"min_child_weight\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=optimized_n_est, max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='average_precision',n_jobs=1,iid=False, cv=5,verbose=2)\n",
    "#gsearch3.fit(X,y)\n",
    "#print gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n",
    "#opt_gamma = gsearch3.best_params_[\"gamma\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelfit\n",
      "Optimal n_estimators: 353\n",
      "CPU times: user 1min 12s, sys: 183 ms, total: 1min 12s\n",
      "Wall time: 19.3 s\n",
      "\n",
      "Model Report\n",
      "Accuracy(Train): 0.9954\n",
      "AUC Score (Train): 0.953009\n",
      "Average Precision: 0.4449\n",
      "Optimal n_estimators: 353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "opt_max_depth = 1\n",
    "opt_min_child_weight = 16\n",
    "opt_gamma = 0\n",
    "#optimized_n_est = 108\n",
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight,\n",
    " gamma=opt_gamma,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "returns = modelfit(xgb2, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "print \"Optimal n_estimators: \"+str(returns[1].shape[0]) \n",
    "optimized_n_est_new = returns[1].shape[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.6, score=0.667977077015, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.6, score=0.0608219520214, total=   6.9s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.6, score=0.144719783052, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.6, score=0.149352509646, total=   7.0s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.6, score=0.104889295203, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.6, score=0.69573640341, total=   7.2s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.6, score=0.0384085532672, total=   7.1s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.6, score=0.149095377902, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.6, score=0.168948008711, total=   6.5s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.6, score=0.0730156975488, total=   6.2s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.6, score=0.682400322826, total=   6.3s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.6, score=0.0369688288835, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.6, score=0.181481576765, total=   5.7s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.6, score=0.158430068683, total=   6.4s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.6, score=0.0715573268321, total=   6.3s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.6, score=0.510463543907, total=   6.4s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.6, score=0.0384286436536, total=   6.9s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.6, score=0.174378262264, total=   6.2s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.6, score=0.159640322443, total=   6.1s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.6, score=0.0946701450688, total=   5.9s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.6, score=0.556993681459, total=  15.9s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.6, score=0.0498694023085, total=  16.1s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.6, score=0.122555503415, total=  17.7s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.6, score=0.164526852786, total=  17.5s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.6, score=0.113385461098, total=  17.4s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.6, score=0.407819184822, total=  16.8s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.6, score=0.0479278972078, total=  16.6s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.6, score=0.0870164674978, total=  18.6s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.6, score=0.16013570844, total=  17.8s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.6, score=0.0903719860479, total=  19.2s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.6, score=0.307629738963, total=  16.4s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.6, score=0.0447916649754, total=  16.5s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.6, score=0.0694488684937, total=  17.5s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.6, score=0.158077397129, total=  18.6s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.6, score=0.0959389452423, total=  18.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.6, score=0.250520541511, total=  18.1s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.6, score=0.0441760788141, total=  17.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.6, score=0.0554202949821, total=  17.3s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.6, score=0.154109006099, total=  19.1s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.6 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.6, score=0.0955251359825, total=  17.6s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.7, score=0.705158836348, total=   7.5s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.7, score=0.0426596846836, total=   7.6s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.7, score=0.146611204757, total=   8.2s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.7, score=0.162076058412, total=   8.0s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.7, score=0.0741338641036, total=   6.8s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.7, score=0.691684527605, total=   6.4s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.7, score=0.0392867768365, total=   6.5s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.7, score=0.177072742831, total=   7.1s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.7, score=0.161079183284, total=   7.5s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.7, score=0.07815803848, total=   6.9s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.7, score=0.671651870827, total=   6.8s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.7, score=0.0386152777499, total=   9.0s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.7, score=0.181873358228, total=   6.5s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.7, score=0.159639285153, total=   6.7s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.7, score=0.0887081489098, total=   7.7s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.7, score=0.412437725027, total=   8.5s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.7, score=0.0408468279576, total=   7.6s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.7, score=0.146385393388, total=   6.3s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.7, score=0.164722613689, total=   6.6s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.7, score=0.0950128522414, total=   8.7s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.7, score=0.547107345861, total=  20.6s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.7, score=0.0470298752646, total=  19.0s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.7, score=0.110902011722, total=  20.0s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.7, score=0.157761130438, total=  19.3s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.7, score=0.10955549041, total=  19.8s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.7, score=0.424977077319, total=  18.4s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.7, score=0.0484530966446, total=  20.4s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.7, score=0.0973323129133, total=  21.2s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.7, score=0.160241955047, total=  20.2s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.7, score=0.0963908429999, total=  20.2s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.7, score=0.329202072192, total=  17.8s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.7, score=0.0450886007163, total=  18.7s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.7, score=0.0646389551796, total=  19.8s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.7, score=0.172265879858, total=  20.0s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.7, score=0.112192649896, total=  21.5s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.7, score=0.216992251148, total=  21.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.7, score=0.0439388741443, total=  18.6s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.7, score=0.05228943549, total=  17.9s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.7, score=0.155072574195, total=  18.1s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.7 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.7, score=0.0960913684269, total=  18.1s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.8, score=0.697371449767, total=   7.5s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.8, score=0.0380451313168, total=   7.5s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.8, score=0.131586109913, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.8, score=0.16127601537, total=   7.8s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.8, score=0.0803454018139, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.8, score=0.678758571212, total=   7.6s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.8, score=0.0382384493477, total=   7.6s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.8, score=0.146980741222, total=   7.8s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.8, score=0.153435085685, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.8, score=0.0694300323846, total=   7.3s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.8, score=0.683678960957, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.8, score=0.0396317925815, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.8, score=0.160717079434, total=   7.3s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.8, score=0.158522469101, total=   8.1s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.8, score=0.0885829088683, total=   7.1s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.8, score=0.500264680651, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.8, score=0.0412470771328, total=   6.9s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.8, score=0.155159239007, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.8, score=0.164115375367, total=   7.1s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.8, score=0.0917659977955, total=   8.4s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.8, score=0.557003829052, total=  23.2s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.8, score=0.046850219461, total=  24.6s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.8, score=0.108777576367, total=  20.6s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.8, score=0.16508029204, total=  26.0s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.8, score=0.107046024105, total=  26.2s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.8, score=0.409911299128, total=  26.1s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.8, score=0.0502813455084, total=  22.6s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.8, score=0.0968354343415, total=  23.7s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.8, score=0.168521122337, total=  22.6s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.8, score=0.0932109091547, total=  22.2s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.8, score=0.326928782019, total=  27.9s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.8, score=0.0457328380731, total=  20.9s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.8, score=0.0683069106504, total=  20.5s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.8, score=0.157634461939, total=  19.0s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.8, score=0.104903464643, total=  19.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.8, score=0.224521585476, total=  18.6s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.8, score=0.044927710842, total=  20.5s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.8, score=0.0526319092383, total=  20.4s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.8, score=0.160015760757, total=  19.5s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.8 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.8, score=0.10223241468, total=  19.1s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.9, score=0.706481247356, total=   7.9s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.9, score=0.0411964760859, total=   8.1s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.9, score=0.116227207292, total=   8.2s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.9, score=0.162788134258, total=   8.0s\n",
      "[CV] n_estimators=108, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.6, colsample_bytree=0.9, score=0.0893134775793, total=   8.7s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.9, score=0.665038063429, total=  10.1s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.9, score=0.0418975607791, total=   9.0s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.9, score=0.136540194476, total=   8.0s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.9, score=0.156520650956, total=   7.4s\n",
      "[CV] n_estimators=108, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.7, colsample_bytree=0.9, score=0.0786453233189, total=   7.7s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.9, score=0.696951086371, total=   7.5s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.9, score=0.0399974574801, total=   8.4s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.9, score=0.172743930888, total=   7.9s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.9, score=0.155777836793, total=   9.7s\n",
      "[CV] n_estimators=108, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.8, colsample_bytree=0.9, score=0.0717615269471, total=   9.5s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.9, score=0.492872652609, total=   8.7s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.9, score=0.0430669415835, total=   8.0s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.9, score=0.161278050073, total=   8.9s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.9, score=0.163630346997, total=   8.8s\n",
      "[CV] n_estimators=108, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=108, subsample=0.9, colsample_bytree=0.9, score=0.0912465764146, total=   8.3s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.9, score=0.543730379805, total=  21.9s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.9, score=0.0491096001906, total=  22.0s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.9, score=0.108327885701, total=  22.6s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.9, score=0.161680510059, total=  22.2s\n",
      "[CV] n_estimators=353, subsample=0.6, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.6, colsample_bytree=0.9, score=0.0977578215454, total=  26.4s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.9, score=0.41636993302, total=  22.4s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.9, score=0.0476850532639, total=  21.8s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.9, score=0.0958582662586, total=  20.7s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.9, score=0.166999551236, total=  23.9s\n",
      "[CV] n_estimators=353, subsample=0.7, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.7, colsample_bytree=0.9, score=0.0947858209949, total=  22.1s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.9, score=0.362663475938, total=  23.3s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.9, score=0.0463322255523, total=  24.9s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.9, score=0.065386938841, total=  26.5s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.9, score=0.165678441927, total=  28.3s\n",
      "[CV] n_estimators=353, subsample=0.8, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.8, colsample_bytree=0.9, score=0.100595152226, total=  26.3s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.9, score=0.242074078903, total=  23.0s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.9, score=0.0453372285896, total=  20.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.9, score=0.0493495011557, total=  21.3s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.9, score=0.169419426639, total=  23.7s\n",
      "[CV] n_estimators=353, subsample=0.9, colsample_bytree=0.9 ...........\n",
      "[CV]  n_estimators=353, subsample=0.9, colsample_bytree=0.9, score=0.0999413135806, total=  26.1s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 40.6min finished\n",
      "/Genomics/grid/users/anatf/custom-env/2.7.3/lib/python2.7/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[mean: 0.22555, std: 0.22351, params: {'n_estimators': 108, 'subsample': 0.6, 'colsample_bytree': 0.6}, mean: 0.22504, std: 0.24017, params: {'n_estimators': 108, 'subsample': 0.7, 'colsample_bytree': 0.6}, mean: 0.22617, std: 0.23428, params: {'n_estimators': 108, 'subsample': 0.8, 'colsample_bytree': 0.6}, mean: 0.19552, std: 0.16479, params: {'n_estimators': 108, 'subsample': 0.9, 'colsample_bytree': 0.6}, mean: 0.20147, std: 0.18151, params: {'n_estimators': 353, 'subsample': 0.6, 'colsample_bytree': 0.6}, mean: 0.15865, std: 0.12972, params: {'n_estimators': 353, 'subsample': 0.7, 'colsample_bytree': 0.6}, mean: 0.13518, std: 0.09412, params: {'n_estimators': 353, 'subsample': 0.8, 'colsample_bytree': 0.6}, mean: 0.11995, std: 0.07579, params: {'n_estimators': 353, 'subsample': 0.9, 'colsample_bytree': 0.6}, mean: 0.22613, std: 0.24358, params: {'n_estimators': 108, 'subsample': 0.6, 'colsample_bytree': 0.7}, mean: 0.22946, std: 0.23670, params: {'n_estimators': 108, 'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.22810, std: 0.22755, params: {'n_estimators': 108, 'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.17188, std: 0.12779, params: {'n_estimators': 108, 'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.19447, std: 0.17980, params: {'n_estimators': 353, 'subsample': 0.6, 'colsample_bytree': 0.7}, mean: 0.16548, std: 0.13452, params: {'n_estimators': 353, 'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.14468, std: 0.10217, params: {'n_estimators': 353, 'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.11288, std: 0.06531, params: {'n_estimators': 353, 'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.22172, std: 0.24156, params: {'n_estimators': 108, 'subsample': 0.6, 'colsample_bytree': 0.8}, mean: 0.21737, std: 0.23490, params: {'n_estimators': 108, 'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.22623, std: 0.23320, params: {'n_estimators': 108, 'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.19051, std: 0.16120, params: {'n_estimators': 108, 'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.19695, std: 0.18387, params: {'n_estimators': 353, 'subsample': 0.6, 'colsample_bytree': 0.8}, mean: 0.16375, std: 0.12880, params: {'n_estimators': 353, 'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.14070, std: 0.10051, params: {'n_estimators': 353, 'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.11687, std: 0.06777, params: {'n_estimators': 353, 'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.22320, std: 0.24483, params: {'n_estimators': 108, 'subsample': 0.6, 'colsample_bytree': 0.9}, mean: 0.21573, std: 0.22833, params: {'n_estimators': 108, 'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.22745, std: 0.23997, params: {'n_estimators': 108, 'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.19042, std: 0.15786, params: {'n_estimators': 108, 'subsample': 0.9, 'colsample_bytree': 0.9}, mean: 0.19212, std: 0.17941, params: {'n_estimators': 353, 'subsample': 0.6, 'colsample_bytree': 0.9}, mean: 0.16434, std: 0.13165, params: {'n_estimators': 353, 'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.14813, std: 0.11472, params: {'n_estimators': 353, 'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.12122, std: 0.07524, params: {'n_estimators': 353, 'subsample': 0.9, 'colsample_bytree': 0.9}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_test4 = {\n",
    " 'n_estimators':[optimized_n_est,optimized_n_est_new],\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=98, max_depth=opt_max_depth,\n",
    " min_child_weight=opt_min_child_weight, gamma=opt_gamma, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='average_precision',n_jobs=1,iid=False, cv=5,verbose=3)\n",
    "gsearch4.fit(X,y)\n",
    "print gsearch4.grid_scores_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsearch4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac3e5b5d5861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mgsearch4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gsearch4' is not defined"
     ]
    }
   ],
   "source": [
    "print gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

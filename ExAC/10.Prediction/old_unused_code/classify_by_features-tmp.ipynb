{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random as random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import zero_one_loss\n",
    "import sklearn.linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve,average_precision_score\n",
    "\n",
    "from sklearn import linear_model #TODO: more models\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "curr_dir = !pwd\n",
    "input_path = curr_dir[0]+\"/../9.Features_exploration/binding_df/10/\"\n",
    "filename = \"positions_features_10.31.17.csv\"\n",
    "bind_scores_num = 10\n",
    "\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "features_cols = features_all.columns[1:-bind_scores_num] #removing binding scores and domain name\n",
    "ligands = [\"dna\", \"dnabase\", \"dnabackbone\", \"rna\", \"rnabase\", \"rnabackbone\", \"peptide\", \"ion\", \"metabolite\"]\n",
    "#ligands = [\"dna\", \"rna\", \"peptide\", \"ion\", \"metabolite\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking input features doesn't have NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in features_cols:\n",
    "    nan_idx = np.where( np.isnan(features_all[col].tolist()) == True)[0]\n",
    "    if (len(nan_idx) > 0):\n",
    "        print col+\" has NaNs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking input features doesn't have Infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in features_cols:\n",
    "    inf_idx = np.where(np.isinf(features_all[col].tolist()) == True)[0]\n",
    "    if (len(inf_idx) > 0):\n",
    "        print col+\" has Inf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37359, 339)\n"
     ]
    }
   ],
   "source": [
    "non_binding_positions = features_all[features_all[\"max_binding_score\"] == 0]\n",
    "non_binding_positions = non_binding_positions.loc[:,features_cols]\n",
    "print non_binding_positions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bind_th = 0.1\n",
    "ligands_features_df = {}\n",
    "\n",
    "for ligand in ligands:\n",
    "    score_col_str = ligand+\"_binding_score\"\n",
    "    ligand_binding_df = features_all[features_all[score_col_str] >= bind_th]\n",
    "    ligands_features_df[ligand] = ligand_binding_df.loc[:,features_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset of positive examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ligands_features_df = pd.concat([ligands_features_df[\"dna\"], ligands_features_df[\"dnabase\"], ligands_features_df[\"dnabackbone\"], ligands_features_df[\"rna\"], ligands_features_df[\"rnabase\"], \n",
    "                                     ligands_features_df[\"rnabackbone\"], ligands_features_df[\"ion\"], ligands_features_df[\"peptide\"], ligands_features_df[\"metabolite\"]])\n",
    "all_ligands_features_df = all_ligands_features_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Down-sample\n",
    "def get_sample(ligand_bind_features,non_binding_positions):\n",
    "    negative_idx = range(0,len(non_binding_positions))\n",
    "    sampled_negative_idx = sample(iter(negative_idx), len(ligand_bind_features))\n",
    "    X = pd.concat([ligand_bind_features, non_binding_positions.iloc[sampled_negative_idx]])\n",
    "\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_bind_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    return [X,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished ligand dna\n",
      "Finished ligand rna\n",
      "Finished ligand peptide\n",
      "Finished ligand ion\n",
      "Finished ligand metabolite\n"
     ]
    }
   ],
   "source": [
    "## Linear Regression\n",
    "for ligand in ligands:\n",
    "    #Initialize dictionary\n",
    "    weights = defaultdict(list)\n",
    "    \n",
    "    # Set params\n",
    "    ligand_bind_features = ligands_features_df[ligand]\n",
    "    \n",
    "    X,y = get_sample(ligand_bind_features,non_binding_positions)\n",
    "    \n",
    "    #X = pd.concat([ligand_bind_features, non_binding_positions])\n",
    "    #y = [1]*ligand_bind_features.shape[0] + [0]*non_binding_positions.shape[0]\n",
    "    \n",
    "    # Fit model and get coefficients\n",
    "    model = LinearRegression().fit(X,y)\n",
    "    coeffs = model.coef_\n",
    "    \n",
    "    # Update dataframe\n",
    "    features_df.loc[\"Linreg_\"+ligand,:] = coeffs\n",
    "    print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "# List of features\n",
    "features_list = np.array([c.encode('ascii','ignore') for c in ligands_features_df['dna'].columns])\n",
    "# Dataframe to hold feature selection results - 1 indicates retention at the threshold\n",
    "features_df = pd.DataFrame(columns=features_list)\n",
    "\n",
    "for ligand in ligands:\n",
    "    # Down-sample\n",
    "    X,y = get_sample(ligands_features_df[ligand],non_binding_positions)\n",
    "    # Feature selection models\n",
    "    var_model = VarianceThreshold(threshold=(.3)).fit(X)\n",
    "    kbest_model = SelectKBest(k=200).fit(X,y)\n",
    "    trees_model = ExtraTreesClassifier().fit(X,y)\n",
    "    # Store results\n",
    "    features_df.loc[\"Vartest_0.1_\"+ligand] = np.asarray(var_model.get_support()).astype(int)\n",
    "    features_df.loc[\"kbest_200_\"+ligand] = np.asarray(kbest_model.get_support()).astype(int)\n",
    "    features_df.loc[\"Trees_\"+ligand,:] = np.asarray(trees_model.feature_importances_ > 1.0/len(features_list)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_maf_all</th>\n",
       "      <th>avg_maf_altered</th>\n",
       "      <th>maf_hist_0-0.001</th>\n",
       "      <th>maf_hist_0.001-0.005</th>\n",
       "      <th>maf_hist_0.005-0.01</th>\n",
       "      <th>maf_hist_0.01-0.02</th>\n",
       "      <th>maf_hist_0.02-0.04</th>\n",
       "      <th>maf_hist_0.04-0.06</th>\n",
       "      <th>maf_hist_0.06-0.08</th>\n",
       "      <th>maf_hist_0.08-0.1</th>\n",
       "      <th>...</th>\n",
       "      <th>aa_alt_avg_freq_prob_N</th>\n",
       "      <th>aa_alt_avg_freq_prob_P</th>\n",
       "      <th>aa_alt_avg_freq_prob_Q</th>\n",
       "      <th>aa_alt_avg_freq_prob_R</th>\n",
       "      <th>aa_alt_avg_freq_prob_S</th>\n",
       "      <th>aa_alt_avg_freq_prob_T</th>\n",
       "      <th>aa_alt_avg_freq_prob_V</th>\n",
       "      <th>aa_alt_avg_freq_prob_W</th>\n",
       "      <th>aa_alt_avg_freq_prob_Y</th>\n",
       "      <th>aa_alt_avg_freq_prob_*</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vartest_0.1_dna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbest_200_dna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trees_dna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vartest_0.1_rna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbest_200_rna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trees_rna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vartest_0.1_peptide</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbest_200_peptide</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trees_peptide</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vartest_0.1_ion</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbest_200_ion</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trees_ion</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vartest_0.1_metabolite</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kbest_200_metabolite</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trees_metabolite</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 298 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        avg_maf_all  avg_maf_altered  maf_hist_0-0.001  \\\n",
       "Vartest_0.1_dna                 0.0              0.0               1.0   \n",
       "kbest_200_dna                   0.0              0.0               1.0   \n",
       "Trees_dna                       0.0              1.0               0.0   \n",
       "Vartest_0.1_rna                 0.0              0.0               1.0   \n",
       "kbest_200_rna                   0.0              0.0               1.0   \n",
       "Trees_rna                       0.0              0.0               0.0   \n",
       "Vartest_0.1_peptide             0.0              0.0               1.0   \n",
       "kbest_200_peptide               1.0              1.0               1.0   \n",
       "Trees_peptide                   0.0              0.0               1.0   \n",
       "Vartest_0.1_ion                 0.0              0.0               1.0   \n",
       "kbest_200_ion                   0.0              0.0               1.0   \n",
       "Trees_ion                       0.0              1.0               0.0   \n",
       "Vartest_0.1_metabolite          0.0              0.0               1.0   \n",
       "kbest_200_metabolite            0.0              0.0               1.0   \n",
       "Trees_metabolite                0.0              0.0               0.0   \n",
       "\n",
       "                        maf_hist_0.001-0.005  maf_hist_0.005-0.01  \\\n",
       "Vartest_0.1_dna                          1.0                  0.0   \n",
       "kbest_200_dna                            1.0                  1.0   \n",
       "Trees_dna                                0.0                  0.0   \n",
       "Vartest_0.1_rna                          1.0                  0.0   \n",
       "kbest_200_rna                            1.0                  0.0   \n",
       "Trees_rna                                0.0                  0.0   \n",
       "Vartest_0.1_peptide                      1.0                  0.0   \n",
       "kbest_200_peptide                        1.0                  1.0   \n",
       "Trees_peptide                            0.0                  0.0   \n",
       "Vartest_0.1_ion                          1.0                  0.0   \n",
       "kbest_200_ion                            1.0                  1.0   \n",
       "Trees_ion                                0.0                  0.0   \n",
       "Vartest_0.1_metabolite                   1.0                  0.0   \n",
       "kbest_200_metabolite                     1.0                  0.0   \n",
       "Trees_metabolite                         0.0                  0.0   \n",
       "\n",
       "                        maf_hist_0.01-0.02  maf_hist_0.02-0.04  \\\n",
       "Vartest_0.1_dna                        0.0                 0.0   \n",
       "kbest_200_dna                          1.0                 1.0   \n",
       "Trees_dna                              0.0                 0.0   \n",
       "Vartest_0.1_rna                        0.0                 0.0   \n",
       "kbest_200_rna                          0.0                 0.0   \n",
       "Trees_rna                              0.0                 0.0   \n",
       "Vartest_0.1_peptide                    0.0                 0.0   \n",
       "kbest_200_peptide                      1.0                 1.0   \n",
       "Trees_peptide                          0.0                 0.0   \n",
       "Vartest_0.1_ion                        0.0                 0.0   \n",
       "kbest_200_ion                          0.0                 1.0   \n",
       "Trees_ion                              0.0                 0.0   \n",
       "Vartest_0.1_metabolite                 0.0                 0.0   \n",
       "kbest_200_metabolite                   0.0                 1.0   \n",
       "Trees_metabolite                       0.0                 0.0   \n",
       "\n",
       "                        maf_hist_0.04-0.06  maf_hist_0.06-0.08  \\\n",
       "Vartest_0.1_dna                        0.0                 0.0   \n",
       "kbest_200_dna                          0.0                 0.0   \n",
       "Trees_dna                              0.0                 0.0   \n",
       "Vartest_0.1_rna                        0.0                 0.0   \n",
       "kbest_200_rna                          1.0                 0.0   \n",
       "Trees_rna                              0.0                 0.0   \n",
       "Vartest_0.1_peptide                    0.0                 0.0   \n",
       "kbest_200_peptide                      1.0                 1.0   \n",
       "Trees_peptide                          0.0                 0.0   \n",
       "Vartest_0.1_ion                        0.0                 0.0   \n",
       "kbest_200_ion                          0.0                 0.0   \n",
       "Trees_ion                              0.0                 0.0   \n",
       "Vartest_0.1_metabolite                 0.0                 0.0   \n",
       "kbest_200_metabolite                   1.0                 0.0   \n",
       "Trees_metabolite                       0.0                 0.0   \n",
       "\n",
       "                        maf_hist_0.08-0.1           ...            \\\n",
       "Vartest_0.1_dna                       0.0           ...             \n",
       "kbest_200_dna                         1.0           ...             \n",
       "Trees_dna                             0.0           ...             \n",
       "Vartest_0.1_rna                       0.0           ...             \n",
       "kbest_200_rna                         0.0           ...             \n",
       "Trees_rna                             0.0           ...             \n",
       "Vartest_0.1_peptide                   0.0           ...             \n",
       "kbest_200_peptide                     1.0           ...             \n",
       "Trees_peptide                         0.0           ...             \n",
       "Vartest_0.1_ion                       0.0           ...             \n",
       "kbest_200_ion                         0.0           ...             \n",
       "Trees_ion                             0.0           ...             \n",
       "Vartest_0.1_metabolite                0.0           ...             \n",
       "kbest_200_metabolite                  0.0           ...             \n",
       "Trees_metabolite                      0.0           ...             \n",
       "\n",
       "                        aa_alt_avg_freq_prob_N  aa_alt_avg_freq_prob_P  \\\n",
       "Vartest_0.1_dna                            0.0                     0.0   \n",
       "kbest_200_dna                              0.0                     0.0   \n",
       "Trees_dna                                  0.0                     0.0   \n",
       "Vartest_0.1_rna                            0.0                     0.0   \n",
       "kbest_200_rna                              1.0                     0.0   \n",
       "Trees_rna                                  0.0                     0.0   \n",
       "Vartest_0.1_peptide                        0.0                     0.0   \n",
       "kbest_200_peptide                          0.0                     0.0   \n",
       "Trees_peptide                              0.0                     0.0   \n",
       "Vartest_0.1_ion                            0.0                     0.0   \n",
       "kbest_200_ion                              1.0                     1.0   \n",
       "Trees_ion                                  0.0                     0.0   \n",
       "Vartest_0.1_metabolite                     0.0                     0.0   \n",
       "kbest_200_metabolite                       0.0                     0.0   \n",
       "Trees_metabolite                           0.0                     0.0   \n",
       "\n",
       "                        aa_alt_avg_freq_prob_Q  aa_alt_avg_freq_prob_R  \\\n",
       "Vartest_0.1_dna                            0.0                     0.0   \n",
       "kbest_200_dna                              0.0                     1.0   \n",
       "Trees_dna                                  0.0                     0.0   \n",
       "Vartest_0.1_rna                            0.0                     0.0   \n",
       "kbest_200_rna                              0.0                     0.0   \n",
       "Trees_rna                                  0.0                     0.0   \n",
       "Vartest_0.1_peptide                        0.0                     0.0   \n",
       "kbest_200_peptide                          0.0                     0.0   \n",
       "Trees_peptide                              0.0                     0.0   \n",
       "Vartest_0.1_ion                            0.0                     0.0   \n",
       "kbest_200_ion                              0.0                     1.0   \n",
       "Trees_ion                                  0.0                     1.0   \n",
       "Vartest_0.1_metabolite                     0.0                     0.0   \n",
       "kbest_200_metabolite                       0.0                     0.0   \n",
       "Trees_metabolite                           0.0                     0.0   \n",
       "\n",
       "                        aa_alt_avg_freq_prob_S  aa_alt_avg_freq_prob_T  \\\n",
       "Vartest_0.1_dna                            0.0                     0.0   \n",
       "kbest_200_dna                              0.0                     0.0   \n",
       "Trees_dna                                  0.0                     1.0   \n",
       "Vartest_0.1_rna                            0.0                     0.0   \n",
       "kbest_200_rna                              0.0                     0.0   \n",
       "Trees_rna                                  0.0                     0.0   \n",
       "Vartest_0.1_peptide                        0.0                     0.0   \n",
       "kbest_200_peptide                          0.0                     0.0   \n",
       "Trees_peptide                              0.0                     1.0   \n",
       "Vartest_0.1_ion                            0.0                     0.0   \n",
       "kbest_200_ion                              0.0                     1.0   \n",
       "Trees_ion                                  0.0                     0.0   \n",
       "Vartest_0.1_metabolite                     0.0                     0.0   \n",
       "kbest_200_metabolite                       0.0                     1.0   \n",
       "Trees_metabolite                           0.0                     1.0   \n",
       "\n",
       "                        aa_alt_avg_freq_prob_V  aa_alt_avg_freq_prob_W  \\\n",
       "Vartest_0.1_dna                            0.0                     0.0   \n",
       "kbest_200_dna                              1.0                     0.0   \n",
       "Trees_dna                                  0.0                     0.0   \n",
       "Vartest_0.1_rna                            0.0                     0.0   \n",
       "kbest_200_rna                              1.0                     0.0   \n",
       "Trees_rna                                  1.0                     0.0   \n",
       "Vartest_0.1_peptide                        0.0                     0.0   \n",
       "kbest_200_peptide                          1.0                     0.0   \n",
       "Trees_peptide                              1.0                     0.0   \n",
       "Vartest_0.1_ion                            0.0                     0.0   \n",
       "kbest_200_ion                              1.0                     1.0   \n",
       "Trees_ion                                  0.0                     0.0   \n",
       "Vartest_0.1_metabolite                     0.0                     0.0   \n",
       "kbest_200_metabolite                       1.0                     0.0   \n",
       "Trees_metabolite                           1.0                     0.0   \n",
       "\n",
       "                        aa_alt_avg_freq_prob_Y  aa_alt_avg_freq_prob_*  \n",
       "Vartest_0.1_dna                            0.0                     0.0  \n",
       "kbest_200_dna                              0.0                     0.0  \n",
       "Trees_dna                                  0.0                     0.0  \n",
       "Vartest_0.1_rna                            0.0                     0.0  \n",
       "kbest_200_rna                              0.0                     0.0  \n",
       "Trees_rna                                  0.0                     0.0  \n",
       "Vartest_0.1_peptide                        0.0                     0.0  \n",
       "kbest_200_peptide                          0.0                     0.0  \n",
       "Trees_peptide                              0.0                     0.0  \n",
       "Vartest_0.1_ion                            0.0                     0.0  \n",
       "kbest_200_ion                              1.0                     1.0  \n",
       "Trees_ion                                  1.0                     0.0  \n",
       "Vartest_0.1_metabolite                     0.0                     0.0  \n",
       "kbest_200_metabolite                       0.0                     1.0  \n",
       "Trees_metabolite                           0.0                     0.0  \n",
       "\n",
       "[15 rows x 298 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df\n",
    "#sum(np.asarray(trees_model.feature_importances_ > 1.0/len(features_list)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg auc = 0.755498732495\n",
      "Finished dna KNN\n",
      "avg auc = 0.771279031672\n",
      "Finished dna SVM\n",
      "avg auc = 0.672961896089\n",
      "Finished dna Ridge\n",
      "avg auc = 0.771029777945\n",
      "Finished dna RF\n",
      "avg auc = 0.732873054291\n",
      "Finished dna Logistic\n",
      "avg auc = 0.68018520994\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.709177904435\n",
      "Finished rna KNN\n",
      "avg auc = 0.743670831341\n",
      "Finished rna SVM\n",
      "avg auc = 0.670825623788\n",
      "Finished rna Ridge\n",
      "avg auc = 0.787763293878\n",
      "Finished rna RF\n",
      "avg auc = 0.645935719448\n",
      "Finished rna Logistic\n",
      "avg auc = 0.65144428285\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.645909468074\n",
      "Finished peptide KNN\n",
      "avg auc = 0.65360250561\n",
      "Finished peptide SVM\n",
      "avg auc = 0.639598640555\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.64964290826\n",
      "Finished peptide RF\n",
      "avg auc = 0.642317410019\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.645379015212\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.704377725708\n",
      "Finished ion KNN\n",
      "avg auc = 0.711830565271\n",
      "Finished ion SVM\n",
      "avg auc = 0.692645533253\n",
      "Finished ion Ridge\n",
      "avg auc = 0.715619740662\n",
      "Finished ion RF\n",
      "avg auc = 0.681588431775\n",
      "Finished ion Logistic\n",
      "avg auc = 0.61149285963\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.605772345219\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.637339651204\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.597404886195\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.630730997663\n",
      "Finished metabolite RF\n",
      "avg auc = 0.602830382659\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.534149622444\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0\n",
      "avg auc = 0.748559872388\n",
      "Finished dna KNN\n",
      "avg auc = 0.763575759866\n",
      "Finished dna SVM\n",
      "avg auc = 0.700702201174\n",
      "Finished dna Ridge\n",
      "avg auc = 0.791977754418\n",
      "Finished dna RF\n",
      "avg auc = 0.777377613663\n",
      "Finished dna Logistic\n",
      "avg auc = 0.677521448751\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.703728173523\n",
      "Finished rna KNN\n",
      "avg auc = 0.74546690466\n",
      "Finished rna SVM\n",
      "avg auc = 0.681778798829\n",
      "Finished rna Ridge\n",
      "avg auc = 0.767795458737\n",
      "Finished rna RF\n",
      "avg auc = 0.639346120053\n",
      "Finished rna Logistic\n",
      "avg auc = 0.654417485031\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.638696197285\n",
      "Finished peptide KNN\n",
      "avg auc = 0.651318164291\n",
      "Finished peptide SVM\n",
      "avg auc = 0.637721175917\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.648518511789\n",
      "Finished peptide RF\n",
      "avg auc = 0.632841151396\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.65457325872\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.703313920158\n",
      "Finished ion KNN\n",
      "avg auc = 0.719102029986\n",
      "Finished ion SVM\n",
      "avg auc = 0.693302866341\n",
      "Finished ion Ridge\n",
      "avg auc = 0.710267587829\n",
      "Finished ion RF\n",
      "avg auc = 0.672627749676\n",
      "Finished ion Logistic\n",
      "avg auc = 0.603570647028\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.60160562351\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.641262430057\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.600584124436\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.630613540398\n",
      "Finished metabolite RF\n",
      "avg auc = 0.603547821828\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.541480142327\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0.0001\n",
      "avg auc = 0.743490509377\n",
      "Finished dna KNN\n",
      "avg auc = 0.772802820616\n",
      "Finished dna SVM\n",
      "avg auc = 0.694202513478\n",
      "Finished dna Ridge\n",
      "avg auc = 0.772650811055\n",
      "Finished dna RF\n",
      "avg auc = 0.761712952225\n",
      "Finished dna Logistic\n",
      "avg auc = 0.663795184263\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.688391006691\n",
      "Finished rna KNN\n",
      "avg auc = 0.735420716776\n",
      "Finished rna SVM\n",
      "avg auc = 0.667545935155\n",
      "Finished rna Ridge\n",
      "avg auc = 0.781221505604\n",
      "Finished rna RF\n",
      "avg auc = 0.654891392758\n",
      "Finished rna Logistic\n",
      "avg auc = 0.637352075718\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.646972388445\n",
      "Finished peptide KNN\n",
      "avg auc = 0.654585812602\n",
      "Finished peptide SVM\n",
      "avg auc = 0.63784063932\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.649497591555\n",
      "Finished peptide RF\n",
      "avg auc = 0.640015799829\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.641009335973\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.701014970453\n",
      "Finished ion KNN\n",
      "avg auc = 0.715295668104\n",
      "Finished ion SVM\n",
      "avg auc = 0.696278144663\n",
      "Finished ion Ridge\n",
      "avg auc = 0.715127250452\n",
      "Finished ion RF\n",
      "avg auc = 0.676126930289\n",
      "Finished ion Logistic\n",
      "avg auc = 0.608015842791\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.604130657381\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.632362843238\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.611853354205\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.63104718431\n",
      "Finished metabolite RF\n",
      "avg auc = 0.603539961861\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.540838653152\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0.0005\n",
      "avg auc = 0.757320945901\n",
      "Finished dna KNN\n",
      "avg auc = 0.783300423705\n",
      "Finished dna SVM\n",
      "avg auc = 0.674545559084\n",
      "Finished dna Ridge\n",
      "avg auc = 0.79923972105\n",
      "Finished dna RF\n",
      "avg auc = 0.774411093422\n",
      "Finished dna Logistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg auc = 0.688347244765\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.720456141653\n",
      "Finished rna KNN\n",
      "avg auc = 0.770528991061\n",
      "Finished rna SVM\n",
      "avg auc = 0.696062524849\n",
      "Finished rna Ridge\n",
      "avg auc = 0.779863563913\n",
      "Finished rna RF\n",
      "avg auc = 0.621242570828\n",
      "Finished rna Logistic\n",
      "avg auc = 0.63635786527\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.647054206641\n",
      "Finished peptide KNN\n",
      "avg auc = 0.658081187704\n",
      "Finished peptide SVM\n",
      "avg auc = 0.635929584661\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.651573577841\n",
      "Finished peptide RF\n",
      "avg auc = 0.650003952388\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.651801430795\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.70338641496\n",
      "Finished ion KNN\n",
      "avg auc = 0.715901154925\n",
      "Finished ion SVM\n",
      "avg auc = 0.702155179689\n",
      "Finished ion Ridge\n",
      "avg auc = 0.708214681515\n",
      "Finished ion RF\n",
      "avg auc = 0.675060691528\n",
      "Finished ion Logistic\n",
      "avg auc = 0.609119846006\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.590067494643\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.628156691933\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.612004292039\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.626742277293\n",
      "Finished metabolite RF\n",
      "avg auc = 0.598780659561\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.53745164687\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0.001\n",
      "avg auc = 0.745872403347\n",
      "Finished dna KNN\n",
      "avg auc = 0.794984733908\n",
      "Finished dna SVM\n",
      "avg auc = 0.728610543779\n",
      "Finished dna Ridge\n",
      "avg auc = 0.801022277774\n",
      "Finished dna RF\n",
      "avg auc = 0.744982224603\n",
      "Finished dna Logistic\n",
      "avg auc = 0.680300113368\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.717542478214\n",
      "Finished rna KNN\n",
      "avg auc = 0.755160315898\n",
      "Finished rna SVM\n",
      "avg auc = 0.691216493816\n",
      "Finished rna Ridge\n",
      "avg auc = 0.760247875341\n",
      "Finished rna RF\n",
      "avg auc = 0.613509331233\n",
      "Finished rna Logistic\n",
      "avg auc = 0.650067932272\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.650666967364\n",
      "Finished peptide KNN\n",
      "avg auc = 0.653775356823\n",
      "Finished peptide SVM\n",
      "avg auc = 0.649607457511\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.649513124165\n",
      "Finished peptide RF\n",
      "avg auc = 0.639931506724\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.654269501724\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.706923242818\n",
      "Finished ion KNN\n",
      "avg auc = 0.718856215707\n",
      "Finished ion SVM\n",
      "avg auc = 0.700085304951\n",
      "Finished ion Ridge\n",
      "avg auc = 0.712538033599\n",
      "Finished ion RF\n",
      "avg auc = 0.657121094993\n",
      "Finished ion Logistic\n",
      "avg auc = 0.60543375998\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.614846937463\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.640838070627\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.597757348536\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.625335891551\n",
      "Finished metabolite RF\n",
      "avg auc = 0.598597229199\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.523165393355\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0.003\n",
      "avg auc = 0.753642714552\n",
      "Finished dna KNN\n",
      "avg auc = 0.818358753461\n",
      "Finished dna SVM\n",
      "avg auc = 0.754518218637\n",
      "Finished dna Ridge\n",
      "avg auc = 0.802565902024\n",
      "Finished dna RF\n",
      "avg auc = 0.766598139448\n",
      "Finished dna Logistic\n",
      "avg auc = 0.708847458649\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "avg auc = 0.74839110699\n",
      "Finished rna KNN\n",
      "avg auc = 0.766424174452\n",
      "Finished rna SVM\n",
      "avg auc = 0.686843331936\n",
      "Finished rna Ridge\n",
      "avg auc = 0.7660842539\n",
      "Finished rna RF\n",
      "avg auc = 0.628717903209\n",
      "Finished rna Logistic\n",
      "avg auc = 0.624413164501\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "avg auc = 0.662605326748\n",
      "Finished peptide KNN\n",
      "avg auc = 0.667983252054\n",
      "Finished peptide SVM\n",
      "avg auc = 0.651285550622\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.641194622548\n",
      "Finished peptide RF\n",
      "avg auc = 0.65887208802\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.647824306913\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "avg auc = 0.718723024045\n",
      "Finished ion KNN\n",
      "avg auc = 0.71420631814\n",
      "Finished ion SVM\n",
      "avg auc = 0.716724789849\n",
      "Finished ion Ridge\n",
      "avg auc = 0.707871568106\n",
      "Finished ion RF\n",
      "avg auc = 0.667093017908\n",
      "Finished ion Logistic\n",
      "avg auc = 0.599652672567\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "avg auc = 0.608409283797\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.630365545602\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.625687451174\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.625037297864\n",
      "Finished metabolite RF\n",
      "avg auc = 0.60570787316\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.531936224002\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "Finished threshold: 0.004\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# Models with features removed for variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#thresh_list = [0.01, 0.05, 0.1, 0.3, 0.5]\n",
    "#thresh_list = [298, 275, 250, 200, 150, 100]\n",
    "thresh_list = [0, 0.0001, 0.0005, 0.001, 0.003, 0.004]\n",
    "\n",
    "for thresh in thresh_list:\n",
    "    for ligand in ligands:\n",
    "        #Initialize dictionary\n",
    "        pred_dict = defaultdict(list)\n",
    "        auc_dict = defaultdict(list)\n",
    "\n",
    "        # Remove features\n",
    "        X,y = get_sample(ligands_features_df[ligand],non_binding_positions)\n",
    "        #model = VarianceThreshold(threshold=thresh).fix(X)\n",
    "        #model = SelectKBest(k=thresh).fit(X,y)\n",
    "        model = ExtraTreesClassifier().fit(X,y)\n",
    "        #features_included = model.get_support()\n",
    "        features_included = model.feature_importances_ > thresh\n",
    "\n",
    "        # Run classifier\n",
    "        test_model(pred_dict, auc_dict, ligands_features_df[ligand], ligand, features_included)\n",
    "\n",
    "        pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "        auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "\n",
    "        #Save to file\n",
    "        pred_df.to_csv(curr_dir[0]+\"/feature_select_df/\"+ligand+\"_0.1_trees_\"+str(thresh)+\".csv\", sep='\\t')\n",
    "        auc_df.to_csv(curr_dir[0]+\"/feature_select_df/\"+ligand+\"_0.1_auc_trees_\"+str(thresh)+\".csv\", sep='\\t')\n",
    "\n",
    "        print \"Finished ligand \"+ligand\n",
    "    print(\"Finished threshold: \"+str(thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [174 195] are constant.\n",
      "  UserWarning)\n",
      "//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "## Select K best\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "for ligand in ligands:\n",
    "    ligand_bind_features = ligands_features_df[ligand]\n",
    "    X,y = get_sample(ligand_bind_features,non_binding_positions)\n",
    "    #X = pd.concat([ligand_bind_features, non_binding_positions])\n",
    "    #y = [1]*ligand_bind_features.shape[0] + [0]*non_binding_positions.shape[0]\n",
    "    \n",
    "    model = SelectKBest(k=100).fit(X, y)\n",
    "    features_df.loc[\"100Best_\"+ligand] = [int(i) for i in model.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Tree-based -- Importances add to one\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "for ligand in ligands:\n",
    "    ligand_bind_features = ligands_features_df[ligand]\n",
    "    X,y = get_sample(ligand_bind_features,non_binding_positions)\n",
    "    #X = pd.concat([ligand_bind_features, non_binding_positions])\n",
    "    #y = [1]*ligand_bind_features.shape[0] + [0]*non_binding_positions.shape[0]\n",
    "    model = ExtraTreesClassifier().fit(X,y)\n",
    "    features_df.loc[\"Trees_\"+ligand,:] = model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier for a particular ligand-binding\n",
    "#### Test different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(iterator, k):\n",
    "    \"\"\"\n",
    "    Samples k elements from an iterable object.\n",
    "\n",
    "    :param iterator: an object that is iterable\n",
    "    :param k: the number of items to sample\n",
    "    \"\"\"\n",
    "    # fill the reservoir to start\n",
    "    result = [next(iterator) for _ in range(k)]\n",
    "\n",
    "    n = k - 1\n",
    "    for item in iterator:\n",
    "        n += 1\n",
    "        s = random.randint(0, n)\n",
    "        if s < k:\n",
    "            result[s] = item\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(pred_dict, auc_dict, auprc_dict, ligand_bind_features, ligand_name, features=[]):\n",
    "    class_idx = 1\n",
    "    \n",
    "    # Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        print(\"hi\")\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "    \n",
    "    classifiers = {}\n",
    "    classifiers[\"Logistic\"] = LogisticRegression()\n",
    "    classifiers[\"RF\"] = ensemble.RandomForestRegressor(n_estimators=1000)  \n",
    "    classifiers[\"KNN\"] = neighbors.KNeighborsRegressor(n_neighbors=100)\n",
    "    classifiers[\"Lasso\"] = linear_model.Lasso()\n",
    "    classifiers[\"Ridge\"] = linear_model.RidgeClassifier()\n",
    "    classifiers[\"SVM\"] = svm.SVC(kernel='rbf', probability=True)\n",
    "    \n",
    "    predict_th = 0.5\n",
    "    models_req_scaling = [\"SVM\", \"KNN\"]\n",
    "    \n",
    "    for classifier in classifiers.keys():\n",
    "        #print \"starting \"+ligand_name+\": \"+classifier\n",
    "        model = classifiers[classifier]\n",
    "        auc_sum = 0\n",
    "        #Create X and y\n",
    "        X = pd.concat([ligand_bind_features.iloc[:,features], non_binding_positions.iloc[:,features]])\n",
    "        #X = pd.concat([ligand_bind_features, non_binding_positions])\n",
    "        \n",
    "        if (classifier in models_req_scaling):\n",
    "            X = pd.DataFrame(scale(X)) #Is z-scoring the data needed?\n",
    "\n",
    "        y = [1] * ligand_bind_features.shape[0]\n",
    "        y.extend([0] * non_binding_positions.shape[0])\n",
    "        y = np.array(y)\n",
    "\n",
    "        binding_skf = StratifiedKFold(n_splits=10)\n",
    "        pred_idx = 1\n",
    "\n",
    "        for train_index, test_index in binding_skf.split(X, y):\n",
    "            X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            #Down-sample negative examples to have balanced classes\n",
    "            negative_idx = np.where(y_train == 0)[0].tolist()\n",
    "            positive_idx = np.where(y_train == 1)[0].tolist()\n",
    "            sampled_negative_idx = sample(iter(negative_idx), len(positive_idx))\n",
    "            X_train_sampled = pd.concat([X_train.iloc[positive_idx], X_train.iloc[sampled_negative_idx]])\n",
    "            y_train_sampled = np.append(y_train[positive_idx], [0] * len(positive_idx))\n",
    "            \n",
    "            #fit to training data\n",
    "            model = classifiers[classifier]\n",
    "            model.fit(X_train_sampled, y_train_sampled)\n",
    "            probs_list = []\n",
    "\n",
    "            if (classifier == \"Logistic\" or classifier == \"SVM\"):\n",
    "                probs = model.predict_proba(X_test)\n",
    "                predicted = log_predict_threshold(probs, predict_th, class_idx)\n",
    "                for l in probs:\n",
    "                    probs_list.append(l[1])\n",
    "            elif (classifier == \"Ridge\"):\n",
    "                probs = model.decision_function(X_test)\n",
    "                predicted = model.predict(X_test)\n",
    "                probs_list = probs\n",
    "            else:\n",
    "                probs = model.predict(X_test)\n",
    "                predicted = predict_threshold(probs, predict_th)\n",
    "                probs_list = probs\n",
    "\n",
    "            #predicted = model.predict(X_test)\n",
    "\n",
    "            pred_dict[\"pred\"].extend(predicted)\n",
    "            pred_dict[\"obs\"].extend(y_test)\n",
    "\n",
    "            pred_dict[\"prob\"].extend(probs_list)\n",
    "\n",
    "            fold_list = [pred_idx] * len(predicted)\n",
    "            pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "            model_list = [classifier] * len(predicted)\n",
    "            pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "            if (classifier == \"Logistic\" or classifier == \"SVM\"):\n",
    "                #print \"auc= \"+str(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "                auc_dict[classifier].append(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "                precision, recall, _ = precision_recall_curve(y_test, probs[:, 1])\n",
    "                \n",
    "            else:\n",
    "                #print \"auc= \"+str(metrics.roc_auc_score(y_test, probs))\n",
    "                auc_dict[classifier].append(metrics.roc_auc_score(y_test, probs))\n",
    "                precision, recall, _ = precision_recall_curve(y_test, probs)\n",
    "            auprc_dict[classifier].append(auc(recall, precision))\n",
    "\n",
    "            pred_idx += 1\n",
    "\n",
    "        avg_auc = np.sum(auc_dict[classifier])/10.0\n",
    "        print \"avg auc = \"+str(avg_auc)\n",
    "        \n",
    "        avg_auprc = np.sum(auprc_dict[classifier])/10.0\n",
    "        print \"avg auprc = \"+str(avg_auprc)\n",
    "            \n",
    "        print \"Finished \"+ligand+\" \"+classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "avg auc = 0.764830354018\n",
      "avg auprc = 0.128723116193\n",
      "Finished dna KNN\n",
      "avg auc = 0.798495593462\n",
      "avg auprc = 0.166570355688\n",
      "Finished dna SVM\n",
      "avg auc = 0.7715361163\n",
      "avg auprc = 0.117364298815\n",
      "Finished dna Ridge\n",
      "avg auc = 0.773961469971\n",
      "avg auprc = 0.115054848008\n",
      "Finished dna RF\n",
      "avg auc = 0.692476210105\n",
      "avg auprc = 0.0967993617873\n",
      "Finished dna Logistic\n",
      "avg auc = 0.690364407821\n",
      "avg auprc = 0.0888991834969\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "hi\n",
      "avg auc = 0.748157129778\n",
      "avg auprc = 0.0845604568557\n",
      "Finished dnabase KNN\n",
      "avg auc = 0.771946050363\n",
      "avg auprc = 0.101442184819\n",
      "Finished dnabase SVM\n",
      "avg auc = 0.669622446559\n",
      "avg auprc = 0.0417423807579\n",
      "Finished dnabase Ridge\n",
      "avg auc = 0.80610280268\n",
      "avg auprc = 0.0666340206723\n",
      "Finished dnabase RF\n",
      "avg auc = 0.685293161939\n",
      "avg auprc = 0.0542089451769\n",
      "Finished dnabase Logistic\n",
      "avg auc = 0.695469182016\n",
      "avg auprc = 0.0576660129236\n",
      "Finished dnabase Lasso\n",
      "Finished ligand dnabase\n",
      "hi\n",
      "avg auc = 0.785872047976\n",
      "avg auprc = 0.131439058363\n",
      "Finished dnabackbone KNN\n",
      "avg auc = 0.806104735536\n",
      "avg auprc = 0.168096504145\n",
      "Finished dnabackbone SVM\n",
      "avg auc = 0.773538559749\n",
      "avg auprc = 0.107934876702\n",
      "Finished dnabackbone Ridge\n",
      "avg auc = 0.790553017618\n",
      "avg auprc = 0.122617968939\n",
      "Finished dnabackbone RF\n",
      "avg auc = 0.698760856423\n",
      "avg auprc = 0.0900087044986\n",
      "Finished dnabackbone Logistic\n",
      "avg auc = 0.703130174802\n",
      "avg auprc = 0.0752391955765\n",
      "Finished dnabackbone Lasso\n",
      "Finished ligand dnabackbone\n",
      "hi\n",
      "avg auc = 0.731157764534\n",
      "avg auprc = 0.111731496175\n",
      "Finished rna KNN\n",
      "avg auc = 0.751074785827\n",
      "avg auprc = 0.0551710760954\n",
      "Finished rna SVM\n",
      "avg auc = 0.747247175019\n",
      "avg auprc = 0.102458430113\n",
      "Finished rna Ridge\n",
      "avg auc = 0.790567562025\n",
      "avg auprc = 0.0798749209264\n",
      "Finished rna RF\n",
      "avg auc = 0.600135189082\n",
      "avg auprc = 0.0767394503834\n",
      "Finished rna Logistic\n",
      "avg auc = 0.644768113957\n",
      "avg auprc = 0.0621944157435\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "hi\n",
      "avg auc = 0.715504271859\n",
      "avg auprc = 0.0714086887063\n",
      "Finished rnabase KNN\n",
      "avg auc = 0.756840052779\n",
      "avg auprc = 0.030512355854\n",
      "Finished rnabase SVM\n",
      "avg auc = 0.639687066696\n",
      "avg auprc = 0.0398238103223\n",
      "Finished rnabase Ridge\n",
      "avg auc = 0.787460502109\n",
      "avg auprc = 0.0375245247536\n",
      "Finished rnabase RF\n",
      "avg auc = 0.626392427657\n",
      "avg auprc = 0.062462386435\n",
      "Finished rnabase Logistic\n",
      "avg auc = 0.643352240845\n",
      "avg auprc = 0.0294902991752\n",
      "Finished rnabase Lasso\n",
      "Finished ligand rnabase\n",
      "hi\n",
      "avg auc = 0.71414673719\n",
      "avg auprc = 0.0850135677792\n",
      "Finished rnabackbone KNN\n",
      "avg auc = 0.763922609736\n",
      "avg auprc = 0.0431193032898\n",
      "Finished rnabackbone SVM\n",
      "avg auc = 0.768375578197\n",
      "avg auprc = 0.0881463947233\n",
      "Finished rnabackbone Ridge\n",
      "avg auc = 0.795686245494\n",
      "avg auprc = 0.0801540600248\n",
      "Finished rnabackbone RF\n",
      "avg auc = 0.58374009981\n",
      "avg auprc = 0.039226411533\n",
      "Finished rnabackbone Logistic\n",
      "avg auc = 0.600903114702\n",
      "avg auprc = 0.0356182180268\n",
      "Finished rnabackbone Lasso\n",
      "Finished ligand rnabackbone\n",
      "hi\n",
      "avg auc = 0.650068257459\n",
      "avg auprc = 0.183220661326\n",
      "Finished peptide KNN\n",
      "avg auc = 0.657827537103\n",
      "avg auprc = 0.124032652554\n",
      "Finished peptide SVM\n",
      "avg auc = 0.630889742958\n",
      "avg auprc = 0.139318163688\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.640976661306\n",
      "avg auprc = 0.130294307537\n",
      "Finished peptide RF\n",
      "avg auc = 0.642740920752\n",
      "avg auprc = 0.165237909842\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.649701227479\n",
      "avg auprc = 0.17517826726\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "hi\n",
      "avg auc = 0.706536106792\n",
      "avg auprc = 0.20068139555\n",
      "Finished ion KNN\n",
      "avg auc = 0.716533163564\n",
      "avg auprc = 0.172311579956\n",
      "Finished ion SVM\n",
      "avg auc = 0.699917197817\n",
      "avg auprc = 0.160195402825\n",
      "Finished ion Ridge\n",
      "avg auc = 0.701601813186\n",
      "avg auprc = 0.193671404458\n",
      "Finished ion RF\n",
      "avg auc = 0.664994837441\n",
      "avg auprc = 0.150951091612\n",
      "Finished ion Logistic\n",
      "avg auc = 0.609078908847\n",
      "avg auprc = 0.0984708891271\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "hi\n",
      "avg auc = 0.609003271841\n",
      "avg auprc = 0.0933176231746\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.637145636778\n",
      "avg auprc = 0.101691035163\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.614207237848\n",
      "avg auprc = 0.0979468259724\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.63570545117\n",
      "avg auprc = 0.107469306957\n",
      "Finished metabolite RF\n",
      "avg auc = 0.606341982158\n",
      "avg auprc = 0.100580993943\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.524423183364\n",
      "avg auprc = 0.0777779570104\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "CPU times: user 3h 12min 3s, sys: 2min 20s, total: 3h 14min 24s\n",
      "Wall time: 3h 5min 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for ligand in ligands:\n",
    "    \n",
    "    #ligand = \"dnabase\"\n",
    "    #Initialize dictionary\n",
    "    pred_dict = defaultdict(list)\n",
    "    auc_dict = defaultdict(list)\n",
    "    auprc_dict = defaultdict(list)\n",
    "    \n",
    "    test_model(pred_dict, auc_dict, auprc_dict, ligands_features_df[ligand], ligand)\n",
    "    \n",
    "    pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "    auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "    auprc_df = pd.DataFrame.from_dict(auprc_dict)\n",
    "    \n",
    "    #Save to file\n",
    "    pred_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1.csv\", sep='\\t')\n",
    "    auc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1_auc.csv\", sep='\\t')\n",
    "    auprc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1_auprc.csv\", sep='\\t')\n",
    "    \n",
    "    print \"Finished ligand \"+ligand\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier for ligands- combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting all_ligands\n",
      "hi\n",
      "avg auc = 0.630632077625\n",
      "avg auprc = 0.266079636518\n",
      "Finished all_ligands KNN\n",
      "avg auc = 0.652877778631\n",
      "avg auprc = 0.272998904606\n",
      "Finished all_ligands SVM\n",
      "avg auc = 0.64174167816\n",
      "avg auprc = 0.279256020232\n",
      "Finished all_ligands Ridge\n",
      "avg auc = 0.628908409877\n",
      "avg auprc = 0.251377487205\n",
      "Finished all_ligands RF\n",
      "avg auc = 0.590373830767\n",
      "avg auprc = 0.263350802157\n",
      "Finished all_ligands Logistic\n",
      "avg auc = 0.583926036946\n",
      "avg auprc = 0.250205267642\n",
      "Finished all_ligands Lasso\n",
      "CPU times: user 3h 43min 52s, sys: 16.6 s, total: 3h 44min 8s\n",
      "Wall time: 3h 42min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_dict = defaultdict(list)\n",
    "auc_dict = defaultdict(list)\n",
    "auprc_dict = defaultdict(list)\n",
    "\n",
    "ligand = \"all_ligands\"\n",
    "print \"Starting all_ligands\"\n",
    "test_model(pred_dict, auc_dict, auprc_dict, all_ligands_features_df, ligand)\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "auprc_df = pd.DataFrame.from_dict(auprc_dict)\n",
    "\n",
    "#Save to file\n",
    "pred_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1.csv\", sep='\\t')\n",
    "auc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1_auc.csv\", sep='\\t')\n",
    "auprc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_0.1_auprc.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict without the most conserved positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = 643\n",
      "hi\n",
      "avg auc = 0.753515280818\n",
      "avg auprc = 0.090082693265\n",
      "Finished dna KNN\n",
      "avg auc = 0.773948716203\n",
      "avg auprc = 0.13535452596\n",
      "Finished dna SVM\n",
      "avg auc = 0.760963304856\n",
      "avg auprc = 0.126490168357\n",
      "Finished dna Ridge\n",
      "avg auc = 0.762135824511\n",
      "avg auprc = 0.0979357495207\n",
      "Finished dna RF\n",
      "avg auc = 0.692370696979\n",
      "avg auprc = 0.0844068296964\n",
      "Finished dna Logistic\n",
      "avg auc = 0.688980907691\n",
      "avg auprc = 0.078198742127\n",
      "Finished dna Lasso\n",
      "Finished ligand dna\n",
      "shape = 241\n",
      "hi\n",
      "avg auc = 0.728183940079\n",
      "avg auprc = 0.0795176295513\n",
      "Finished dnabase KNN\n",
      "avg auc = 0.761036794722\n",
      "avg auprc = 0.0572367418724\n",
      "Finished dnabase SVM\n",
      "avg auc = 0.659274798277\n",
      "avg auprc = 0.0478662636617\n",
      "Finished dnabase Ridge\n",
      "avg auc = 0.804137166289\n",
      "avg auprc = 0.0405892994931\n",
      "Finished dnabase RF\n",
      "avg auc = 0.689096152335\n",
      "avg auprc = 0.0658911321308\n",
      "Finished dnabase Logistic\n",
      "avg auc = 0.682180494462\n",
      "avg auprc = 0.0553499999266\n",
      "Finished dnabase Lasso\n",
      "Finished ligand dnabase\n",
      "shape = 535\n",
      "hi\n",
      "avg auc = 0.769711754916\n",
      "avg auprc = 0.0924662159159\n",
      "Finished dnabackbone KNN\n",
      "avg auc = 0.793534738819\n",
      "avg auprc = 0.14008298232\n",
      "Finished dnabackbone SVM\n",
      "avg auc = 0.777744622022\n",
      "avg auprc = 0.106952330614\n",
      "Finished dnabackbone Ridge\n",
      "avg auc = 0.793954543275\n",
      "avg auprc = 0.112976396182\n",
      "Finished dnabackbone RF\n",
      "avg auc = 0.689328965988\n",
      "avg auprc = 0.085382265438\n",
      "Finished dnabackbone Logistic\n",
      "avg auc = 0.6983452449\n",
      "avg auprc = 0.0640972793845\n",
      "Finished dnabackbone Lasso\n",
      "Finished ligand dnabackbone\n",
      "shape = 584\n",
      "hi\n",
      "avg auc = 0.717007761101\n",
      "avg auprc = 0.0886882424881\n",
      "Finished rna KNN\n",
      "avg auc = 0.76455415157\n",
      "avg auprc = 0.0523789221784\n",
      "Finished rna SVM\n",
      "avg auc = 0.731574889123\n",
      "avg auprc = 0.0861459578589\n",
      "Finished rna Ridge\n",
      "avg auc = 0.796250014485\n",
      "avg auprc = 0.0709091470486\n",
      "Finished rna RF\n",
      "avg auc = 0.644464346539\n",
      "avg auprc = 0.0561651405137\n",
      "Finished rna Logistic\n",
      "avg auc = 0.645797666548\n",
      "avg auprc = 0.0486949997603\n",
      "Finished rna Lasso\n",
      "Finished ligand rna\n",
      "shape = 300\n",
      "hi\n",
      "avg auc = 0.72195774485\n",
      "avg auprc = 0.0566378304577\n",
      "Finished rnabase KNN\n",
      "avg auc = 0.762120977367\n",
      "avg auprc = 0.0242776144533\n",
      "Finished rnabase SVM\n",
      "avg auc = 0.696225589008\n",
      "avg auprc = 0.0524149367404\n",
      "Finished rnabase Ridge\n",
      "avg auc = 0.801841574721\n",
      "avg auprc = 0.0502699495878\n",
      "Finished rnabase RF\n",
      "avg auc = 0.625702276391\n",
      "avg auprc = 0.0452563737242\n",
      "Finished rnabase Logistic\n",
      "avg auc = 0.651481972859\n",
      "avg auprc = 0.0281723688491\n",
      "Finished rnabase Lasso\n",
      "Finished ligand rnabase\n",
      "shape = 431\n",
      "hi\n",
      "avg auc = 0.700364907954\n",
      "avg auprc = 0.0779715003938\n",
      "Finished rnabackbone KNN\n",
      "avg auc = 0.755969137126\n",
      "avg auprc = 0.0370647778009\n",
      "Finished rnabackbone SVM\n",
      "avg auc = 0.760825862631\n",
      "avg auprc = 0.0631622092009\n",
      "Finished rnabackbone Ridge\n",
      "avg auc = 0.785640819052\n",
      "avg auprc = 0.0804475584175\n",
      "Finished rnabackbone RF\n",
      "avg auc = 0.611818650764\n",
      "avg auprc = 0.0478809971559\n",
      "Finished rnabackbone Logistic\n",
      "avg auc = 0.655083029745\n",
      "avg auprc = 0.0302971254502\n",
      "Finished rnabackbone Lasso\n",
      "Finished ligand rnabackbone\n",
      "shape = 1995\n",
      "hi\n",
      "avg auc = 0.657183693343\n",
      "avg auprc = 0.18202997765\n",
      "Finished peptide KNN\n",
      "avg auc = 0.669626316529\n",
      "avg auprc = 0.115189411901\n",
      "Finished peptide SVM\n",
      "avg auc = 0.660763623401\n",
      "avg auprc = 0.138255203392\n",
      "Finished peptide Ridge\n",
      "avg auc = 0.676734221452\n",
      "avg auprc = 0.146199800362\n",
      "Finished peptide RF\n",
      "avg auc = 0.639020523607\n",
      "avg auprc = 0.159957486888\n",
      "Finished peptide Logistic\n",
      "avg auc = 0.64964241144\n",
      "avg auprc = 0.160356526329\n",
      "Finished peptide Lasso\n",
      "Finished ligand peptide\n",
      "shape = 1216\n",
      "hi\n",
      "avg auc = 0.634976229406\n",
      "avg auprc = 0.064094159951\n",
      "Finished ion KNN\n",
      "avg auc = 0.644223371074\n",
      "avg auprc = 0.0626474441497\n",
      "Finished ion SVM\n",
      "avg auc = 0.632263080712\n",
      "avg auprc = 0.0602911534015\n",
      "Finished ion Ridge\n",
      "avg auc = 0.670240608219\n",
      "avg auprc = 0.0782189012176\n",
      "Finished ion RF\n",
      "avg auc = 0.599100365287\n",
      "avg auprc = 0.0621519558175\n",
      "Finished ion Logistic\n",
      "avg auc = 0.570497338942\n",
      "avg auprc = 0.0537472278494\n",
      "Finished ion Lasso\n",
      "Finished ligand ion\n",
      "shape = 1807\n",
      "hi\n",
      "avg auc = 0.58209952733\n",
      "avg auprc = 0.0647094280356\n",
      "Finished metabolite KNN\n",
      "avg auc = 0.624302962251\n",
      "avg auprc = 0.0749939209031\n",
      "Finished metabolite SVM\n",
      "avg auc = 0.621864002627\n",
      "avg auprc = 0.0837075877107\n",
      "Finished metabolite Ridge\n",
      "avg auc = 0.630948404126\n",
      "avg auprc = 0.0736707168536\n",
      "Finished metabolite RF\n",
      "avg auc = 0.571155207793\n",
      "avg auprc = 0.0747344122232\n",
      "Finished metabolite Logistic\n",
      "avg auc = 0.534891041923\n",
      "avg auprc = 0.064725577555\n",
      "Finished metabolite Lasso\n",
      "Finished ligand metabolite\n",
      "CPU times: user 2h 39min 13s, sys: 38.5 s, total: 2h 39min 52s\n",
      "Wall time: 2h 32min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for ligand in ligands:\n",
    "    \n",
    "    pred_dict = defaultdict(list)\n",
    "    auc_dict = defaultdict(list)\n",
    "    auprc_dict = defaultdict(list)\n",
    "    \n",
    "    ligands_features_df_not_con = ligands_features_df[ligand][ligands_features_df[ligand][\"pfam_prob_max\"] <= 0.5]\n",
    "    print \"shape = \"+str(ligands_features_df_not_con.shape[0])\n",
    "    \n",
    "    test_model(pred_dict, auc_dict, auprc_dict, ligands_features_df_not_con, ligand+\"_not_con\")\n",
    "    \n",
    "    pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "    auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "    auprc_df = auprc_df = pd.DataFrame.from_dict(auprc_dict)\n",
    "    \n",
    "    #Save to file\n",
    "    pred_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1.csv\", sep='\\t')\n",
    "    auc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1_auc.csv\", sep='\\t')\n",
    "    auprc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1_auprc.csv\", sep='\\t')\n",
    "    \n",
    "    print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict all ligands together without the most conserved positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape = 5554\n",
      "hi\n",
      "avg auc = 0.60893547414\n",
      "avg auprc = 0.228060714192\n",
      "Finished all_ligands KNN\n",
      "avg auc = 0.646094934738\n",
      "avg auprc = 0.221615568947\n",
      "Finished all_ligands SVM\n",
      "avg auc = 0.645545150528\n",
      "avg auprc = 0.238669225285\n",
      "Finished all_ligands Ridge\n",
      "avg auc = 0.635969235775\n",
      "avg auprc = 0.221519678271\n",
      "Finished all_ligands RF\n",
      "avg auc = 0.575912688949\n",
      "avg auprc = 0.226384566005\n",
      "Finished all_ligands Logistic\n",
      "avg auc = 0.582321934915\n",
      "avg auprc = 0.212216893367\n",
      "Finished all_ligands Lasso\n",
      "CPU times: user 3h 1min 15s, sys: 13 s, total: 3h 1min 28s\n",
      "Wall time: 3h 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class_idx = 1 #binding==1\n",
    "\n",
    "all_ligands_features_df_not_con = all_ligands_features_df[all_ligands_features_df[\"pfam_prob_max\"] <= 0.5]\n",
    "\n",
    "pred_dict = defaultdict(list)\n",
    "auc_dict = defaultdict(list)\n",
    "auprc_dict = defaultdict(list)\n",
    "\n",
    "ligand = \"all_ligands\"\n",
    "print \"shape = \"+str(all_ligands_features_df_not_con.shape[0])\n",
    "\n",
    "test_model(pred_dict, auc_dict, auprc_dict, all_ligands_features_df_not_con, ligand)\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "\n",
    "#Save to file\n",
    "pred_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1.csv\", sep='\\t')\n",
    "auc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1_auc.csv\", sep='\\t')\n",
    "auprc_df.to_csv(curr_dir[0]+\"/ligand_df/\"+ligand+\"_not_con_0.1_auprc.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>model</th>\n",
       "      <th>obs</th>\n",
       "      <th>pred</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>KNN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257448</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257449</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257450</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257451</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.456137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257452</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257453</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257454</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257455</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257456</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257457</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257458</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257459</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257460</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257461</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257462</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.463210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257463</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257464</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.506009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257465</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257466</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257467</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.450595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257468</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.498062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257469</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257470</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.616759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257471</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257472</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.464015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257473</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257474</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257475</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257476</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257477</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.457348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>257478 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fold  model  obs  pred      prob\n",
       "0          1    KNN    1     1  0.500000\n",
       "1          1    KNN    1     0  0.430000\n",
       "2          1    KNN    1     0  0.470000\n",
       "3          1    KNN    1     0  0.440000\n",
       "4          1    KNN    1     0  0.480000\n",
       "5          1    KNN    1     1  0.560000\n",
       "6          1    KNN    1     0  0.480000\n",
       "7          1    KNN    1     0  0.410000\n",
       "8          1    KNN    1     0  0.320000\n",
       "9          1    KNN    1     1  0.510000\n",
       "10         1    KNN    1     1  0.520000\n",
       "11         1    KNN    1     1  0.570000\n",
       "12         1    KNN    1     0  0.340000\n",
       "13         1    KNN    1     0  0.420000\n",
       "14         1    KNN    1     0  0.460000\n",
       "15         1    KNN    1     0  0.420000\n",
       "16         1    KNN    1     0  0.420000\n",
       "17         1    KNN    1     0  0.350000\n",
       "18         1    KNN    1     0  0.480000\n",
       "19         1    KNN    1     1  0.540000\n",
       "20         1    KNN    1     1  0.620000\n",
       "21         1    KNN    1     0  0.480000\n",
       "22         1    KNN    1     0  0.460000\n",
       "23         1    KNN    1     1  0.550000\n",
       "24         1    KNN    1     0  0.460000\n",
       "25         1    KNN    1     0  0.480000\n",
       "26         1    KNN    1     1  0.520000\n",
       "27         1    KNN    1     1  0.590000\n",
       "28         1    KNN    1     1  0.520000\n",
       "29         1    KNN    1     1  0.550000\n",
       "...      ...    ...  ...   ...       ...\n",
       "257448    10  Lasso    0     0  0.476019\n",
       "257449    10  Lasso    0     0  0.476337\n",
       "257450    10  Lasso    0     0  0.478941\n",
       "257451    10  Lasso    0     0  0.456137\n",
       "257452    10  Lasso    0     0  0.471038\n",
       "257453    10  Lasso    0     0  0.469566\n",
       "257454    10  Lasso    0     0  0.458196\n",
       "257455    10  Lasso    0     0  0.450231\n",
       "257456    10  Lasso    0     1  0.540880\n",
       "257457    10  Lasso    0     0  0.499856\n",
       "257458    10  Lasso    0     0  0.459233\n",
       "257459    10  Lasso    0     1  0.502440\n",
       "257460    10  Lasso    0     0  0.465049\n",
       "257461    10  Lasso    0     1  0.516400\n",
       "257462    10  Lasso    0     0  0.463210\n",
       "257463    10  Lasso    0     1  0.541758\n",
       "257464    10  Lasso    0     1  0.506009\n",
       "257465    10  Lasso    0     1  0.550303\n",
       "257466    10  Lasso    0     1  0.504974\n",
       "257467    10  Lasso    0     0  0.450595\n",
       "257468    10  Lasso    0     0  0.498062\n",
       "257469    10  Lasso    0     0  0.485656\n",
       "257470    10  Lasso    0     1  0.616759\n",
       "257471    10  Lasso    0     1  0.504806\n",
       "257472    10  Lasso    0     0  0.464015\n",
       "257473    10  Lasso    0     0  0.497919\n",
       "257474    10  Lasso    0     0  0.476736\n",
       "257475    10  Lasso    0     0  0.485617\n",
       "257476    10  Lasso    0     0  0.469489\n",
       "257477    10  Lasso    0     0  0.457348\n",
       "\n",
       "[257478 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this point: \"testing code\" - can be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc= 0.63821638431\n",
      "auc= 0.828210851648\n",
      "auc= 0.821619352869\n",
      "auc= 0.738435555895\n",
      "auc= 0.812001450326\n",
      "auc= 0.768181557956\n",
      "auc= 0.603431166749\n",
      "auc= 0.373750047708\n",
      "auc= 0.915027098202\n",
      "auc= 0.870978913725\n",
      "auc_avg = 0.736985237939\n"
     ]
    }
   ],
   "source": [
    "classifiers = {}\n",
    "ligand_bind_features = ligands_features_df[\"dna\"]\n",
    "ligand = \"DNA\"\n",
    "class_idx = 1 #binding==1\n",
    "#classifiers[\"Ridge\"] = linear_model.RidgeClassifier()\n",
    "#classifiers[\"Logistic\"] = LogisticRegression()\n",
    "#classifiers[\"RandomForest\"] = ensemble.RandomForestRegressor(n_estimators=1000)  \n",
    "classifiers[\"KNN\"] = neighbors.KNeighborsRegressor(n_neighbors=100)\n",
    "#classifiers[\"Lasso\"] = linear_model.Lasso()\n",
    "predict_th = 0.5\n",
    "#classifiers[\"SVM\"] = svm.SVC(kernel='rbf', probability=True)\n",
    "\n",
    "models_req_scaling = [\"SVM\", \"KNN\"]\n",
    "\n",
    "auc_sum = 0\n",
    "pred_dict = defaultdict(list)\n",
    "\n",
    "for classifier in classifiers.keys():\n",
    "    model = classifiers[classifier]\n",
    "\n",
    "    #Create X and y\n",
    "    X = pd.concat([ligand_bind_features, non_binding_positions])\n",
    "    \n",
    "    if (classifier in models_req_scaling):\n",
    "        X = pd.DataFrame(scale(X)) #Is z-scoring the data needed?\n",
    "        \n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * non_binding_positions.shape[0])\n",
    "    y = np.array(y)\n",
    "\n",
    "    binding_skf = StratifiedKFold(n_splits=10)\n",
    "    pred_idx = 1\n",
    "\n",
    "    for train_index, test_index in binding_skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        #Down-sample negative examples to have balanced classes\n",
    "        negative_idx = np.where(y_train == 0)[0].tolist()\n",
    "        positive_idx = np.where(y_train == 1)[0].tolist()\n",
    "        sampled_negative_idx = sample(iter(negative_idx), len(positive_idx))\n",
    "        X_train_sampled = pd.concat([X_train.iloc[positive_idx], X_train.iloc[sampled_negative_idx]])\n",
    "        y_train_sampled = np.append(y_train[positive_idx], [0] * len(positive_idx))\n",
    "\n",
    "        model = classifiers[classifier]\n",
    "        model.fit(X_train_sampled, y_train_sampled)\n",
    "        probs_list = []\n",
    "\n",
    "        if (classifier == \"Logistic\" or classifier == \"SVM\"):\n",
    "            probs = model.predict_proba(X_test)\n",
    "            predicted = log_predict_threshold(probs, predict_th, class_idx)\n",
    "            for l in probs:\n",
    "                probs_list.append(l[1])\n",
    "        elif (classifier == \"Ridge\"):\n",
    "            probs = model.decision_function(X_test)\n",
    "            predicted = model.predict(X_test)\n",
    "            probs_list = probs\n",
    "        else:\n",
    "            probs = model.predict(X_test)\n",
    "            predicted = predict_threshold(probs, predict_th)\n",
    "            probs_list = probs\n",
    "\n",
    "        #predicted = model.predict(X_test)\n",
    "\n",
    "        pred_dict[\"pred\"].extend(predicted)\n",
    "        pred_dict[\"obs\"].extend(y_test)\n",
    "\n",
    "        pred_dict[\"prob\"].extend(probs_list)\n",
    "\n",
    "        fold_list = [pred_idx] * len(predicted)\n",
    "        pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "        model_list = [classifier+\"_\"+ligand] * len(predicted)\n",
    "        pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "        #print (pred_idx)\n",
    "        pred_idx += 1\n",
    "        \n",
    "        #print \"accuracy = \"+str(metrics.accuracy_score(y_test, predicted))\n",
    "        if (classifier == \"Logistic\" or classifier == \"SVM\"):\n",
    "            print \"auc= \"+str(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "            auc_sum += metrics.roc_auc_score(y_test, probs[:, 1])\n",
    "        else:\n",
    "            print \"auc= \"+str(metrics.roc_auc_score(y_test, probs))\n",
    "            auc_sum += metrics.roc_auc_score(y_test, probs)\n",
    "        #print metrics.classification_report(y_test, predicted) \n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "print \"auc_avg = \"+str(auc_sum/10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3772, 5)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[pred_df[\"fold\"] == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8929667990598773"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the dataset into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classes_by_threshold_3(features_table, bind_th, struct_th):\n",
    "    \"\"\"Given a features table, binding score threshold and Pfam emission prob. threshold,\n",
    "    return tables of 3 classes:\n",
    "    1) structural- positions with Pfam emission prob. >= th\n",
    "    2) binding - positions with binding score >= th\n",
    "    3) neutral - all other positions\"\"\"\n",
    "    \n",
    "    structural = features_table[features_table[\"pfam_prob_max\"] >= struct_th]\n",
    "    non_struct = features_table[features_table[\"pfam_prob_max\"] < struct_th]\n",
    "    binding = non_struct[non_struct[\"binding_score\"] >= bind_th]\n",
    "    neutral = non_struct[non_struct[\"binding_score\"] < bind_th]\n",
    "    del structural[\"binding_score\"]\n",
    "    del binding[\"binding_score\"]\n",
    "    del neutral[\"binding_score\"]\n",
    "    \n",
    "    return (structural, binding, neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classes_by_threshold_2(features_table, bind_th):\n",
    "    \"\"\"Given a features table, binding score threshold and Pfam emission prob. threshold,\n",
    "    return tables of 2 classes:\n",
    "    1) binding - positions with binding score >= th\n",
    "    2) non_binding - all other positions\"\"\"\n",
    "    \n",
    "    binding = features_table[features_table[\"binding_score\"] >= bind_th]\n",
    "    non_binding = features_table[features_table[\"binding_score\"] < bind_th]\n",
    "    del binding[\"binding_score\"]\n",
    "    del neutral[\"binding_score\"]\n",
    "    \n",
    "    return (binding, non_binding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add labeles vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_labels(features_table, label):\n",
    "    \"Add label column with label as data\"\n",
    "    labeld_table = features_table\n",
    "    labeled_table[\"label\"] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to change in the model:\n",
    "##### 1) binding threshold:\n",
    "From that binding score threshold the truth value is defined as \"binding\".\n",
    "##### 2) structural threshold\n",
    "From what Pfam emission prob. the position is conserved and defined as \"structural\"\n",
    "##### 3) Include/Ignore structural\n",
    "Include \"Structural\" as a third class or no.\n",
    "##### 4) Probability for predicting binding\n",
    "From what prob of the classification model something will be classified as \"binding\"\n",
    "##### 5) Classification algorithm\n",
    "Which classification algorithm to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_predict_threshold(probs, predict_th, class_idx):\n",
    "    \n",
    "    predicted = []\n",
    "    for i in range(len(probs)):\n",
    "        if (probs[i][class_idx] >= predict_th):\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "        \n",
    "    return np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_threshold(probs, predict_th):\n",
    "    \n",
    "    predicted = []\n",
    "    for i in range(len(probs)):\n",
    "        if (probs[i] >= predict_th):\n",
    "            predicted.append(1)\n",
    "        else:\n",
    "            predicted.append(0)\n",
    "        \n",
    "    return np.array(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test binding threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binding size = 7538\n",
      "neutral size = 41880\n",
      "binding size = 4948\n",
      "neutral size = 44470\n",
      "binding size = 2183\n",
      "neutral size = 47235\n",
      "binding size = 815\n",
      "neutral size = 48603\n",
      "binding size = 303\n",
      "neutral size = 49115\n",
      "binding size = 115\n",
      "neutral size = 49303\n",
      "CPU times: user 2min 55s, sys: 28.6 s, total: 3min 24s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bind_th_list = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "struct_th = 0.5\n",
    "predict_th = 0.5\n",
    "class_idx = 1 #binding==1\n",
    "features_table = features_all\n",
    "\n",
    "classifiers = {}\n",
    "#classifiers[\"Logistic\"] = LogisticRegression()\n",
    "#classifiers[\"RandomForest\"] = ensemble.RandomForestRegressor(n_estimators=100)  \n",
    "#classifiers[\"KNN\"] = neighbors.KNeighborsRegressor(n_neighbors=150)\n",
    "#classifiers[\"Lasso\"] = linear_model.Lasso()\n",
    "classifiers[\"Ridge\"] = linear_model.Ridge()\n",
    "#classifiers[\"SVM.linear\"] = svm.LinearSVC()\n",
    "\n",
    "pred_dict = defaultdict(list)\n",
    "\n",
    "roc_sum = 0\n",
    "\n",
    "#Get only the features columns\n",
    "features_table = features_table.loc[:,features_cols]\n",
    "\n",
    "for bind_th in bind_th_list:\n",
    "    \n",
    "    #Divide dataset by binding score and delete binding score\n",
    "    (structural, binding, neutral) = classes_by_threshold_3(features_table, bind_th, struct_th)\n",
    "    print \"binding size = \"+str(binding.shape[0])\n",
    "    print \"neutral size = \"+str(neutral.shape[0])\n",
    "    #Create X and y\n",
    "    X = pd.concat([binding, neutral])\n",
    "    y = [1] * binding.shape[0]\n",
    "    y.extend([0] * neutral.shape[0])\n",
    "    y = np.array(y)\n",
    "\n",
    "    binding_skf = StratifiedKFold(n_splits=10)\n",
    "    pred_idx = 1\n",
    "\n",
    "    for train_index, test_index in binding_skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        for classifier in classifiers.keys():\n",
    "            model = classifiers[classifier]\n",
    "            model.fit(X_train, y_train)\n",
    "            probs_list = []\n",
    "\n",
    "            if (classifier == \"Logistic\"):\n",
    "                probs = model.predict_proba(X_test)\n",
    "                predicted = log_predict_threshold(probs, predict_th, class_idx)\n",
    "                for l in probs:\n",
    "                    probs_list.append(l[1])\n",
    "            else:\n",
    "                probs = model.predict(X_test)\n",
    "                predicted = predict_threshold(probs, predict_th)\n",
    "                probs_list = probs\n",
    "\n",
    "            #predicted = model.predict(X_test)\n",
    "\n",
    "            pred_dict[\"pred\"].extend(predicted)\n",
    "            pred_dict[\"obs\"].extend(y_test)\n",
    "\n",
    "            pred_dict[\"prob\"].extend(probs_list)\n",
    "\n",
    "            fold_list = [pred_idx] * len(predicted)\n",
    "            pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "            model_list = [classifier+\"_\"+str(bind_th)] * len(predicted)\n",
    "            pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "        #print (pred_idx)\n",
    "        pred_idx += 1\n",
    "    \n",
    "    #print metrics.accuracy_score(y_test, predicted)\n",
    "    #print metrics.roc_auc_score(y_test, probs[:, 1])\n",
    "    #print metrics.classification_report(y_test, predicted)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "\n",
    "#Save to file\n",
    "pred_df.to_csv(curr_dir[0]+\"/bind_df/Ridge_st0.5_df.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test structural threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binding size = 4044\n",
      "neutral size = 37283\n",
      "binding size = 4630\n",
      "neutral size = 42239\n",
      "binding size = 4978\n",
      "neutral size = 44692\n",
      "binding size = 5222\n",
      "neutral size = 46185\n",
      "binding size = 5400\n",
      "neutral size = 47121\n",
      "CPU times: user 9.87 s, sys: 276 ms, total: 10.1 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "struct_th_list = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "bind_th = 0.1\n",
    "predict_th = 0.5\n",
    "class_idx = 1 #binding==1\n",
    "features_table = features_all_binding_first\n",
    "\n",
    "classifiers = {}\n",
    "#classifiers[\"Logistic\"] = LogisticRegression()\n",
    "#classifiers[\"RandomForest\"] = ensemble.RandomForestRegressor(n_estimators=100)  \n",
    "#classifiers[\"KNN\"] = neighbors.KNeighborsRegressor(n_neighbors=150)\n",
    "#classifiers[\"Lasso\"] = linear_model.Lasso()\n",
    "classifiers[\"Ridge\"] = linear_model.Ridge()\n",
    "#classifiers[\"SVM.RBF\"] = svm.SVR(kernel='rbf')\n",
    "\n",
    "pred_dict = defaultdict(list)\n",
    "\n",
    "roc_sum = 0\n",
    "\n",
    "#Get only the features columns\n",
    "features_table = features_table.loc[:,features_cols]\n",
    "\n",
    "for struct_th in struct_th_list:\n",
    "    \n",
    "    #Divide dataset by binding score and delete binding score\n",
    "    (structural, binding, neutral) = classes_by_threshold_3(features_table, bind_th, struct_th)\n",
    "    print \"binding size = \"+str(binding.shape[0])\n",
    "    print \"neutral size = \"+str(neutral.shape[0])\n",
    "    #Create X and y\n",
    "    X = pd.concat([binding, neutral])\n",
    "    y = [1] * binding.shape[0]\n",
    "    y.extend([0] * neutral.shape[0])\n",
    "    y = np.array(y)\n",
    "\n",
    "    structural_skf = StratifiedKFold(n_splits=10)\n",
    "    pred_idx = 1\n",
    "\n",
    "    for train_index, test_index in structural_skf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        for classifier in classifiers.keys():\n",
    "            model = classifiers[classifier]\n",
    "            model.fit(X_train, y_train)\n",
    "            probs_list = []\n",
    "\n",
    "            if (classifier == \"Logistic\"):\n",
    "                probs = model.predict_proba(X_test)\n",
    "                predicted = log_predict_threshold(probs, predict_th, class_idx)\n",
    "                for l in probs:\n",
    "                    probs_list.append(l[1])\n",
    "            else:\n",
    "                probs = model.predict(X_test)\n",
    "                predicted = predict_threshold(probs, predict_th)\n",
    "                probs_list = probs\n",
    "\n",
    "            pred_dict[\"pred\"].extend(predicted)\n",
    "            pred_dict[\"obs\"].extend(y_test)\n",
    "\n",
    "            pred_dict[\"prob\"].extend(probs_list)\n",
    "\n",
    "            fold_list = [pred_idx] * len(predicted)\n",
    "            pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "            model_list = [classifier+\"_\"+str(struct_th)] * len(predicted)\n",
    "            pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "        #print (pred_idx)\n",
    "        pred_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "\n",
    "#Save to file\n",
    "pred_df.to_csv(curr_dir[0]+\"/struct_df/Ridge_b0.75_df.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  498,   499,   500, ..., 49667, 49668, 49669])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Leave-one-domain-out\n",
    "zinc = features_all_binding_first[features_all_binding_first[\"domain_name\"] == \"zf-C2H2\"]\n",
    "test_features = zinc.loc[:,[\"avg_maf_all\", \"alter_num_aa_norm\", \"alter_num_dna_norm\", \"BLOSUM_avg\",\"pseudo_dNdS\", \"Pfam_emission_prob\"]]\n",
    "test_scores = zinc.loc[:,[\"binding_score\"]]\n",
    "test_scores_list = test_scores[\"binding_score\"].tolist()\n",
    "\n",
    "non_zinc = features_all_binding_first[features_all_binding_first[\"domain_name\"] != \"zf-C2H2\"]\n",
    "train_features = non_zinc.loc[:,[\"avg_maf_all\", \"alter_num_aa_norm\", \"alter_num_dna_norm\", \"BLOSUM_avg\",\"pseudo_dNdS\", \"Pfam_emission_prob\"]]\n",
    "train_scores = non_zinc.loc[:,[\"binding_score\"]]\n",
    "train_scores_list = train_scores[\"binding_score\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = ensemble.RandomForestRegressor(n_estimators=20)\n",
    "classifier.fit(train_features,train_scores_list)\n",
    "predictions = classifier.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07184824,  0.13221474,  0.07100531,  0.08462587,  0.03292043,\n",
       "        0.04369969,  0.03312264,  0.07531634,  0.01546092,  0.01624991,\n",
       "        0.66402111,  0.07683871,  0.02855051,  0.04870269,  0.05690733,\n",
       "        0.59407069,  0.51117707,  0.0226684 ,  0.02145087,  0.55608137,\n",
       "        0.02160144,  0.0816579 ,  0.01485516])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mean_sq_error = 0.32& 0.567"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEbCAYAAABgLnslAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV0rAywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff0740cdc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Random Forest\"\n",
    "xs = test_scores_list\n",
    "ys = predictions\n",
    "results = sm.OLS(ys,sm.add_constant(xs)).fit() # gather all statistics (only used for our analysis)\n",
    "# compute root mean squared error and R\n",
    "mean_sq_error = np.mean((test_scores_list-predictions)**2)\n",
    "r = np.corrcoef(test_scores_list,predictions)[0][1]\n",
    "print name+\" mean_sq_error = \"+str(round(np.sqrt(mean_sq_error),3)) +  \"& \" + str(round(r**2,3)) , # A LaTeX table friendly printing format\n",
    "# Plot the prediction error PDF\n",
    "hist,bin_edges = np.histogram((test_scores_list-predictions),bins=100,density=True)\n",
    "plt.title(name + ': Prediction error PDF')\n",
    "plt.xlabel('Error value')\n",
    "plt.ylabel('Probablity Density')    \n",
    "plt.scatter(bin_edges[:-1],hist)\n",
    "plt.xlim(min(bin_edges), max(bin_edges))\n",
    "plt.ylim(min(hist), max(hist))\n",
    "plt.tight_layout()\n",
    "#plt.savefig(my_path+\"/\"+name+\"_prediction_plot.png\",dpi=200,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100\n",
      "Finished 200\n",
      "Finished 300\n",
      "Finished 400\n",
      "Finished 500\n",
      "Finished 600\n",
      "Finished 700\n",
      "Finished 800"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "cnt = 1\n",
    "binding_skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "tprs = []\n",
    "sum_auc = 0\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "y_real = []\n",
    "y_proba = []\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for b_train_index, b_test_index in binding_skf.split(binding_features, binding_lables):\n",
    "    binding_X_train, binding_X_test = binding_features.iloc[b_train_index,:], binding_features.iloc[b_test_index,:]\n",
    "    binding_y_train, binding_y_test = binding_lables[b_train_index], binding_lables[b_test_index]\n",
    "    \n",
    "    \n",
    "    neutral_big_skf = StratifiedKFold(n_splits=8)\n",
    "    for n_ignore_index, n_eight_index in neutral_big_skf.split(neutral_features, neutral_lables):\n",
    "        neutral_eight_features = neutral_features.iloc[n_eight_index,:]\n",
    "        neutral_eight_labels = neutral_lables[n_eight_index]\n",
    "        \n",
    "        neutral_small_skf = StratifiedKFold(n_splits=10)\n",
    "        for n_train_index, n_test_index in neutral_small_skf.split(neutral_eight_features, neutral_eight_labels):\n",
    "            neutral_X_train, neutral_X_test = neutral_eight_features.iloc[n_train_index,:], neutral_eight_features.iloc[n_train_index,:]\n",
    "            neutral_y_train, neutral_y_test = neutral_eight_labels[n_train_index], neutral_eight_labels[n_train_index]\n",
    "            \n",
    "            X_train = pd.concat([binding_X_train, neutral_X_train])\n",
    "            X_test = pd.concat([binding_X_test, neutral_X_test])\n",
    "            y_train = pd.concat([binding_y_train, neutral_y_train])\n",
    "            y_test = pd.concat([binding_y_test, neutral_y_test])\n",
    "    \n",
    "            classifier = LogisticRegression() #- 10.66%\n",
    "            #classifier = KNeighborsClassifier(n_neighbors=2)\n",
    "            classifier.fit(X_train,y_train)\n",
    "            y_pred = classifier.predict_proba(X_test)\n",
    "            #y_pred = classifier.predict(X_test)\n",
    "    \n",
    "            #ROC curve calculations\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
    "            #fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "            sum_auc += auc(fpr, tpr)\n",
    "            #plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "            tpr = interp(base_fpr, fpr, tpr)\n",
    "            tpr[0] = 0.0\n",
    "            tprs.append(tpr)\n",
    "            \n",
    "            y_proba.append(y_pred[:,1])\n",
    "            y_real.append(y_test)\n",
    "            \n",
    "            cnt += 1\n",
    "            if (cnt % 100 == 0):\n",
    "                print \"Finished \"+str(cnt)\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "avg_auc = sum_auc/float(cnt)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "\n",
    "plt.plot(base_fpr, mean_tprs, 'b')\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_real = np.concatenate(y_real)\n",
    "y_proba = np.concatenate(y_proba)\n",
    "precision, recall, _ = precision_recall_curve(y_real, y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28140708991498403"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pr = auc(recall, precision)\n",
    "auc_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63996056671302903"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNeighborsClassifier(n_neighbors=3) - avg_auc = 0.66720473460640295\n",
    "KNeighborsClassifier(n_neighbors=5) - avg_auc = 0.63996056671302903\n",
    "KNeighborsClassifier(n_neighbors=10) - avg_auc = 0.61487235644402483\n",
    "LogisticRegression() - avg_auc = 0.60508881221502731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60508881221502731"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11018793274\n",
      "0.108803165183\n",
      "0.107856718781\n",
      "0.107856718781\n",
      "0.107460914308\n",
      "0.111023154562\n",
      "0.107263012072\n",
      "0.109835741144\n",
      "0.107856718781\n",
      "0.0878685929151\n",
      "Average error: 10.66%\n"
     ]
    }
   ],
   "source": [
    "#Split to train and test indices\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "averageError = 0.0\n",
    "\n",
    "for train_index, test_index in skf.split(binding_neutral_best_features, binding_neutral_labels):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = binding_neutral_best_features.iloc[train_index,:], binding_neutral_best_features.iloc[test_index,:]\n",
    "    y_train, y_test = binding_neutral_labels[train_index], binding_neutral_labels[test_index]\n",
    "    \n",
    "    #classifier = svm.SVC()- 11.57%\n",
    "    classifier = LogisticRegression() #- 10.66%\n",
    "    #classifier = KNeighborsClassifier(n_neighbors=10) - 10.84%\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    error = zero_one_loss(y_test, y_pred)\n",
    "    print error\n",
    "    averageError += (1./k) * error\n",
    "    \n",
    "print \"Average error: %4.2f%s\" % (100 * averageError,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5053,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n",
      "Finished skf\n"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "X = binding_neutral_best_features\n",
    "y = binding_neutral_labels\n",
    "\n",
    "k=10\n",
    "skf = StratifiedKFold(n_splits=k)\n",
    "\n",
    "tprs = []\n",
    "sum_auc = 0\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for train_index, test_index in skf.split(binding_neutral_best_features, binding_neutral_labels):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = binding_neutral_best_features.iloc[train_index,:], binding_neutral_best_features.iloc[test_index,:]\n",
    "    y_train, y_test = binding_neutral_labels[train_index], binding_neutral_labels[test_index]\n",
    "    \n",
    "    classifier = LogisticRegression(class_weight = \"balanced\") #- 10.66%\n",
    "    classifier.fit(X_train,y_train)\n",
    "    y_pred = classifier.predict_proba(X_test)\n",
    "    \n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
    "    sum_auc += auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "    tpr = interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    tprs.append(tpr)\n",
    "    \n",
    "    print \"Finished skf\"\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "avg_auc = sum_auc/float(k)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "\n",
    "plt.plot(base_fpr, mean_tprs, 'b')\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_dict ={}\n",
    "predictions_dict[\"svm\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(predictions_dict,label):\n",
    "    plt.clf()\n",
    "    fig,ax = plt.subplots()        \n",
    "    plt.xlabel('False Positive Rate',fontsize=17)\n",
    "    plt.ylabel('True Positive Rate',fontsize=17)\n",
    "    ax.set_title(\"ROC Curve\",fontsize=20)\n",
    "    fig.set_size_inches(10.0, 10.0, forward=True)\n",
    "    i=0\n",
    "    for key in predictions_dict.keys():\n",
    "        pred = predictions_dict[key]\n",
    "        fpr, tpr, thresholds = roc_curve(label, pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr,  label= '{0}. Area: {1}'.format(key,round(roc_auc,2)),linestyle='--',linewidth=2,marker = markers[i%len(markers)],color = colors[i%len(colors)])\n",
    "        i+=1\n",
    "        #plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"roc_curve.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(predictions_dict,label):\n",
    "    plt.clf()\n",
    "    fig,ax = plt.subplots()        \n",
    "    ax.set_xlabel(\"Recell\",fontsize=17)\n",
    "    ax.set_ylabel(\"Precision\",fontsize=17)\n",
    "    ax.set_title(\"Precision-Recall Curve\",fontsize=20)\n",
    "    fig.set_size_inches(10.0, 10.0, forward=True)\n",
    "    i=0\n",
    "    for key in predictions_dict.keys():\n",
    "        precision, recall, thresholds = precision_recall_curve(label, predictions_dict[key])\n",
    "        mean_precision = np.mean(precision)\n",
    "        mean_recall = np.mean(recall)\n",
    "        f1_score = 2*mean_precision*mean_recall/(mean_precision+mean_recall)\n",
    "        average_precision = average_precision_score(label, predictions_dict[key])\n",
    "        plt.plot(recall, precision, label='{0}. Avg. precision: {1}, F1 score: {2}'.format(key,round(average_precision,2),round(f1_score,2)),linestyle='--',linewidth=2,marker = markers[i%len(markers)],color = colors[i%len(colors)])\n",
    "        i+=1\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.15])        \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.savefig(\"precision_recall_curve.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_inds(y ,train_proportion=0.9):\n",
    "    '''Generates indices, making random stratified split into training set and testing sets\n",
    "    with proportions train_proportion and (1-train_proportion) of initial sample.\n",
    "    y is any iterable indicating classes of each observation in the sample.\n",
    "    Initial proportions of classes inside training and \n",
    "    testing sets are preserved (stratified sampling).\n",
    "    '''\n",
    "\n",
    "    y=np.array(y)\n",
    "    train_inds = np.zeros(len(y),dtype=bool)\n",
    "    test_inds = np.zeros(len(y),dtype=bool)\n",
    "    values = np.unique(y)\n",
    "    for value in values:\n",
    "        value_inds = np.nonzero(y==value)[0]\n",
    "        np.random.shuffle(value_inds)\n",
    "        n = int(train_proportion*len(value_inds))\n",
    "\n",
    "        train_inds[value_inds[:n]]=True\n",
    "        test_inds[value_inds[n:]]=True\n",
    "\n",
    "    return train_inds,test_inds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

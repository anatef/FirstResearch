{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ, getcwd\n",
    "import sys\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve, precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Import utils functions\n",
    "curr_dir = !pwd\n",
    "sys.path.append(curr_dir[0]+\"/utils\")\n",
    "from prop_threshold_funcs import create_negatives_datasets, create_positives_datasets\n",
    "from prediction_general_funcs import ligands, score_cols_suffix, get_features_cols\n",
    "from CV_funcs import add_domain_name_from_table_idx, calc_CV_idx_iterative\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_features_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a1222370fa7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mfeatures_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#Features columns names, without the labels (the binding scores)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mfeatures_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_features_cols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"all samples positions #: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_features_cols' is not defined"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "input_path = curr_dir[0]+\"/domains_similarity/filtered_features_table/\"\n",
    "filename = \"windowed_positions_features_mediode_filter_06.20.18.csv\"\n",
    "out_dir = \"mediode_NegLigand_NoFilter\"\n",
    "\n",
    "#flags for creating negatives\n",
    "zero_prop = True\n",
    "no_prop = True\n",
    "all_ligands = False\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "#Features columns names, without the labels (the binding scores)\n",
    "features_cols = get_features_cols(features_all)\n",
    "\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#CV splits dictionary\n",
    "with open(curr_dir[0]+\"/CV_splits/domain_10_splits_dict.pik\", 'rb') as handle:\n",
    "        splits_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:41680\n",
      "dnabase non-binding #:42089\n",
      "dnabackbone non-binding #:41689\n",
      "rna non-binding #:41613\n",
      "rnabase non-binding #:41828\n",
      "rnabackbone non-binding #:41619\n",
      "peptide non-binding #:38794\n",
      "ion non-binding #:37525\n",
      "metabolite non-binding #:37463\n",
      "sm non-binding #:30978\n"
     ]
    }
   ],
   "source": [
    "ligands_negatives_df = create_negatives_datasets(zero_prop, no_prop, features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 239\n",
      "dnabase #: 170\n",
      "dnabackbone #: 244\n",
      "rna #: 125\n",
      "rnabase #: 98\n",
      "rnabackbone #: 120\n",
      "peptide #: 462\n",
      "ion #: 727\n",
      "metabolite #: 504\n",
      "sm #: 708\n"
     ]
    }
   ],
   "source": [
    "prec_th = 0.5\n",
    "ligands_positives_df = create_positives_datasets(prec_th, features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dna\n",
      "fold = 1\n",
      "classifier_method = Logistic\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dna\"\n",
    "print \"ligand = \"+ligand\n",
    "    \n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    fold = environ['fold']\n",
    "except:\n",
    "    fold = \"1\"\n",
    "print \"fold = \"+fold\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"Logistic\"\n",
    "print \"classifier_method = \"+classifier_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models tested (and their hyper-parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "if (classifier_method == \"XGB\"):\n",
    "    ligand_pos = ligands_features_df[ligand].shape[0]\n",
    "    ligand_neg = ligands_negatives_df[ligand].shape[0]\n",
    "    scale_weight = ligand_neg/float(ligand_pos)\n",
    "    classifiers[\"XGB\"] = XGBClassifier(n_estimators=1000, n_jobs=-1, random_state=0, max_depth=6, min_child_weight=0.05, colsample_bytree=0.5, scale_pos_weight=scale_weight)\n",
    "elif (classifier_method == \"RF\"):\n",
    "    classifiers[\"RF\"] = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=0)  \n",
    "elif(classifier_method == \"Logistic\"):\n",
    "    classifiers[\"Logistic\"] = LogisticRegression(C=0.1, random_state=0, n_jobs=-1)\n",
    "elif (classifier_method == \"KNN\"):\n",
    "    classifiers[\"KNN\"] = KNeighborsClassifier(n_neighbors=100, n_jobs=-1)\n",
    "elif (classifier_method == \"ADA\"):\n",
    "    classifiers[\"ADA\"] = AdaBoostClassifier(n_estimators=1000, random_state=0)\n",
    "elif (classifier_method == \"SVM\"):\n",
    "    classifiers[\"SVM\"] = SVC(kernel='rbf', probability=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_domain_auc(y_test, pred_probs, domain_pred_dict, pred_idx, classifier):\n",
    "    \"\"\"\n",
    "    Compute the average per_domain auc and auprc for the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    y_test_copy = y_test.copy(deep=True)\n",
    "    y_test_copy[\"pred_probs\"] = pred_probs\n",
    "    \n",
    "    domain_auc_list = []\n",
    "    domain_auprc_list = []\n",
    "    domain_auprc_ratio_list = []\n",
    "    domain_name_list = []\n",
    "    \n",
    "    idx = y_test.index\n",
    "    y_test_copy[\"domain_name\"] = [x[:x.rfind(\"_\")] for x in idx]\n",
    "    domains_list = y_test_copy[\"domain_name\"].unique().tolist()\n",
    "    \n",
    "        \n",
    "    for domain_name in domains_list:\n",
    "        \n",
    "        #Get only the domain positions\n",
    "        domain_df = y_test_copy[y_test_copy[\"domain_name\"] == domain_name]\n",
    "\n",
    "        #Find the binding positions of this domain\n",
    "        bind_list = domain_df[domain_df[\"label\"] == 1].index\n",
    "        bind_idx = [int(x[len(domain_name)+1:]) for x in bind_list]\n",
    "        bind_num = len(bind_idx)\n",
    "        if (bind_num == 0):\n",
    "            #No binding positions in this domain - skipping\"\n",
    "            continue\n",
    "        \n",
    "        domain_pred_dict[\"obs\"].extend(domain_df[\"label\"])\n",
    "        domain_pred_dict[\"prob\"].extend(domain_df[\"pred_probs\"])\n",
    "        fold_list = [pred_idx] * len(domain_df[\"pred_probs\"])\n",
    "        domain_pred_dict[\"fold\"].extend(fold_list)\n",
    "        model_list = [classifier] * len(domain_df[\"pred_probs\"])\n",
    "        domain_pred_dict[\"model\"].extend(model_list)\n",
    "        domain_str_list = [domain_name] * len(domain_df[\"pred_probs\"])\n",
    "        domain_pred_dict[\"domain\"].extend(domain_str_list)\n",
    "    \n",
    "        #Compute domain AUC\n",
    "        domain_auc = roc_auc_score(domain_df[\"label\"], domain_df[\"pred_probs\"])\n",
    "        domain_auc_list.append(domain_auc)\n",
    "        #Compute domain AUPRC\n",
    "        precision, recall, thresholds = precision_recall_curve(domain_df[\"label\"], domain_df[\"pred_probs\"])\n",
    "        domain_auprc = auc(recall, precision)\n",
    "        domain_auprc_list.append(domain_auprc)\n",
    "        #Add positives fraction to list\n",
    "        pos_frac_ratio = bind_num/float(domain_df.shape[0])\n",
    "        #Add ratio of AUPRC and positives fraction to list\n",
    "        domain_auprc_ratio_list.append(domain_auprc/float(pos_frac_ratio))\n",
    "        #Add domain name for AUC/AUPRC/Ratio tables\n",
    "        domain_name_list.append(domain_name)\n",
    "        \n",
    "    #Compute the means for the lists \n",
    "    domain_auc_mean = np.mean(domain_auc_list)\n",
    "    domain_auprc_mean = np.mean(domain_auprc_list)\n",
    "    domain_auprc_ratio_mean = np.mean(domain_auprc_ratio_list)\n",
    "    \n",
    "    return (domain_auc_mean, domain_auprc_mean, domain_auprc_ratio_mean, domain_auc_list, domain_auprc_list, domain_auprc_ratio_list, domain_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_iterative_fixed(pred_dict, domain_pred_dict, auc_dict, auprc_dict, domain_auc_mean_dict, domain_auprc_mean_dict, domain_auprc_ratio_mean_dict, domain_auc_dict, domain_auprc_dict, domain_auprc_ratio_dict,\n",
    "                               ligand_bind_features, ligand_negatives_features, ligand_name, features=[]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test different models in 10-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "        \n",
    "    #Arranging the features table by the CV order, for each model\n",
    "    features_pred_dfs = dict.fromkeys(classifiers.keys())\n",
    "    \n",
    "    models_req_scaling = [\"SVM\", \"KNN\", \"Logistic\"]\n",
    "\n",
    "    classifier = classifier_method\n",
    "    model = classifiers[classifier]\n",
    "    features_pred_dfs[classifier] = pd.DataFrame()\n",
    "\n",
    "    #Create X and y with included features\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    y_df = pd.DataFrame(y)\n",
    "    y_df.index = X.index\n",
    "    y_df.columns = [\"label\"]\n",
    "    \n",
    "    #Get the fold indices\n",
    "    cv_idx = calc_CV_idx_iterative(X, splits_dict)\n",
    "    k = (int(fold)-1)\n",
    "    \n",
    "    pred_idx = k+1\n",
    "    print \"fold #: \"+str(pred_idx)\n",
    "    test_index = cv_idx[k][\"test\"]\n",
    "    train_index = cv_idx[k][\"train\"]\n",
    "    X_train, X_test = X.loc[train_index,:], X.loc[test_index,:]\n",
    "    y_train, y_test = y_df.loc[train_index,:], y_df.loc[test_index,:]\n",
    "    \n",
    "    if (classifier in models_req_scaling):\n",
    "        cols = X_train.columns\n",
    "        scaler = StandardScaler() \n",
    "        #scale only using the training data\n",
    "        scaler.fit(X_train) \n",
    "        X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "        # apply same transformation to test data\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "        #Restoring indices after scaling\n",
    "        X_train.index = train_index \n",
    "        X_test.index = test_index \n",
    "        #Restoring features names\n",
    "        X_train.columns = cols\n",
    "        X_test.columns = cols\n",
    "\n",
    "    #No down-sampling\n",
    "    X_train_sampled = X_train\n",
    "    y_train_sampled = y_train\n",
    "\n",
    "    #fit to training data\n",
    "    model = classifiers[classifier]\n",
    "    model.fit(X_train_sampled, y_train_sampled[\"label\"])\n",
    "\n",
    "    probs_list = []\n",
    "    probs = model.predict_proba(X_test)\n",
    "    for l in probs:\n",
    "        probs_list.append(l[1])\n",
    "\n",
    "    pred_dict[\"obs\"].extend(y_test[\"label\"])\n",
    "    pred_dict[\"prob\"].extend(probs_list)\n",
    "    fold_list = [pred_idx] * len(probs_list)\n",
    "    pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "    model_list = [classifier] * len(probs_list)\n",
    "    pred_dict[\"model\"].extend(model_list)\n",
    "\n",
    "    #Update auc auprc dictionaries\n",
    "    auc_dict[classifier].append(roc_auc_score(y_test[\"label\"], probs[:, 1]))\n",
    "    precision, recall, _ = precision_recall_curve(y_test[\"label\"], probs[:, 1])\n",
    "    auprc_dict[classifier].append(auc(recall, precision))\n",
    "    \n",
    "    #Compute per domain AUC and AUPRC\n",
    "    (domain_auc_mean, domain_auprc_mean, domain_auprc_ratio_mean, domain_auc_list, domain_auprc_list, domain_auprc_ratio_list, domain_name_list) = compute_per_domain_auc(y_test, probs[:, 1], domain_pred_dict,pred_idx, classifier)\n",
    "    \n",
    "    #Update relevant dictionaries for per-domain folds mean\n",
    "    domain_auc_mean_dict[classifier].append(domain_auc_mean)\n",
    "    domain_auprc_mean_dict[classifier].append(domain_auprc_mean)\n",
    "    domain_auprc_ratio_mean_dict[classifier].append(domain_auprc_ratio_mean)\n",
    "    \n",
    "    #Update relevant dictionaries for per-domain individual metrices scores\n",
    "    domain_auc_dict[classifier].extend(domain_auc_list)\n",
    "    domain_auc_dict[\"domain\"].extend(domain_name_list)\n",
    "    domain_auprc_dict[classifier].extend(domain_auprc_list)\n",
    "    domain_auprc_dict[\"domain\"].extend(domain_name_list)\n",
    "    domain_auprc_ratio_dict[classifier].extend(domain_auprc_ratio_list)\n",
    "    domain_auprc_ratio_dict[\"domain\"].extend(domain_name_list)\n",
    "    \n",
    "    #Update features table\n",
    "    features_pred_dfs[classifier] = features_pred_dfs[classifier].append(X_test)\n",
    "    pred_idx += 1\n",
    "\n",
    "    print \"AUC = \"+str(auc_dict[classifier][-1])\n",
    "    print \"AUPRC = \"+str(auprc_dict[classifier][-1])\n",
    "    print \"domain AUC mean = \"+str(domain_auc_mean_dict[classifier][-1])\n",
    "    print \"domain AUPRC mean = \"+str(domain_auprc_mean_dict[classifier][-1])\n",
    "    print \"domain AUPRC ratio mean = \"+str(domain_auprc_ratio_mean_dict[classifier][-1])\n",
    "\n",
    "    print \"Finished \"+ligand+\" \"+classifier+\" fold: \"+fold\n",
    "    \n",
    "    return features_pred_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_predictions(ligand, ordered_features, pred_df):\n",
    "    \n",
    "    pred_res = pred_df.copy(deep=True)\n",
    "    for classifier in classifiers.keys():\n",
    "        classifier = classifier_method\n",
    "        model_pred = pred_res[pred_res[\"model\"] == classifier]\n",
    "        model_pred.index = ordered_features[classifier].index\n",
    "        \n",
    "        #Creating the combined table\n",
    "        features_pred = pd.concat([ordered_features[classifier], model_pred], axis=1)\n",
    "        \n",
    "        #Saving\n",
    "        features_pred.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/features_pred_tables/\"+ligand+\"_\"+classifier+\"_features_pred.csv\", sep='\\t')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #: 1\n",
      "AUC = 0.870498753117\n",
      "AUPRC = 0.542709843076\n",
      "domain AUC mean = 0.727567083856\n",
      "domain AUPRC mean = 0.417446795021\n",
      "domain AUPRC ratio mean = 2.12114967993\n",
      "Finished dna Logistic fold: 1\n",
      "Finished ligand dna\n",
      "CPU times: user 44.9 s, sys: 1.2 s, total: 46.1 s\n",
      "Wall time: 45.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Initialize dictionary\n",
    "pred_dict = defaultdict(list)\n",
    "domain_pred_dict = defaultdict(list)\n",
    "auc_dict = defaultdict(list)\n",
    "auprc_dict = defaultdict(list)\n",
    "domain_auc_mean_dict = defaultdict(list)\n",
    "domain_auprc_mean_dict = defaultdict(list)\n",
    "domain_auprc_ratio_mean_dict = defaultdict(list)\n",
    "domain_auc_dict = defaultdict(list)\n",
    "domain_auprc_dict = defaultdict(list)\n",
    "domain_auprc_ratio_dict = defaultdict(list)\n",
    "downsample_method = \"NoDown\"\n",
    "\n",
    "ordered_features = test_model_iterative_fixed(pred_dict, domain_pred_dict, auc_dict, auprc_dict, domain_auc_mean_dict, domain_auprc_mean_dict, domain_auprc_ratio_mean_dict, domain_auc_dict, domain_auprc_dict, domain_auprc_ratio_dict, ligands_features_df[ligand], ligands_negatives_df[ligand], ligand)\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "domain_pred_df = pd.DataFrame.from_dict(domain_pred_dict)\n",
    "#global matrics dfs\n",
    "auc_df = pd.DataFrame.from_dict(auc_dict)\n",
    "auprc_df = pd.DataFrame.from_dict(auprc_dict)\n",
    "#per domain mean dfs\n",
    "domain_auc_mean_df = pd.DataFrame.from_dict(domain_auc_mean_dict)\n",
    "domain_auprc_mean_df = pd.DataFrame.from_dict(domain_auprc_mean_dict)\n",
    "domain_auprc_ratio_mean_df = pd.DataFrame.from_dict(domain_auprc_ratio_mean_dict)\n",
    "#per domain dfs\n",
    "domain_auc_df = pd.DataFrame.from_dict(domain_auc_dict)\n",
    "domain_auprc_df = pd.DataFrame.from_dict(domain_auprc_dict)\n",
    "domain_auprc_ratio_df= pd.DataFrame.from_dict(domain_auprc_ratio_dict)\n",
    "\n",
    "#Save to file\n",
    "pred_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w.csv\", sep='\\t')\n",
    "domain_pred_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_d.csv\", sep='\\t')\n",
    "\n",
    "auc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_auc.csv\", sep='\\t')\n",
    "auprc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_auprc.csv\", sep='\\t')\n",
    "\n",
    "domain_auc_mean_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_dm_auc.csv\", sep='\\t')\n",
    "domain_auprc_mean_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_dm_auprc.csv\", sep='\\t')\n",
    "domain_auprc_ratio_mean_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_dm_auprc_ratio.csv\", sep='\\t')\n",
    "\n",
    "domain_auc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUP>RC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_d_auc.csv\", sep='\\t')\n",
    "domain_auprc_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_d_auprc.csv\", sep='\\t')\n",
    "domain_auprc_ratio_df.to_csv(curr_dir[0]+\"/pred_AUC_AUPRC/\"+out_dir+\"/\"+downsample_method+\"/05.11.2018_domain_CV/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_10w_d_auprc_ratio.csv\", sep='\\t')\n",
    "\n",
    "#Combine features and pred results to a unified table\n",
    "#combine_features_predictions(ligand, ordered_features, pred_df)\n",
    "\n",
    "print \"Finished ligand \"+ligand"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

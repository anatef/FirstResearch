{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from os import environ\n",
    "import sys\n",
    "\n",
    "#Classifier imports\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, RandomForestRegressor, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#ML framework imports\n",
    "from sklearn.metrics import auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Neural Net imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "#Import utils functions\n",
    "curr_dir = !pwd\n",
    "sys.path.append(curr_dir[0]+\"/../utils\")\n",
    "from prop_threshold_funcs import create_negatives_datasets, create_positives_datasets, create_positives_datasets_combined, create_negatives_datasets_combined\n",
    "from prediction_general_funcs import ligands, score_cols_suffix, get_features_cols, remove_unimportant_features\n",
    "from CV_funcs import add_domain_name_from_table_idx, calc_CV_idx_iterative\n",
    "from generate_models_dict import generate_models_dict\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all samples positions #: 44872\n"
     ]
    }
   ],
   "source": [
    "curr_dir = !pwd\n",
    "pfam_version = \"31\"\n",
    "datafile_date = \"08.06.18\"\n",
    "input_path = curr_dir[0]+\"/../domains_similarity/filtered_features_table/\"\n",
    "filename = \"windowed_positions_features_mediode_filter_\"+datafile_date+\".csv\"\n",
    "out_dir = \"mediode_NegLigand_NoFilter\"\n",
    "\n",
    "#flags for creating negatives\n",
    "zero_prop = True\n",
    "no_prop = True\n",
    "all_ligands = False\n",
    "prec_th = 0.25\n",
    "folds_num = 5\n",
    "ligands = [\"dna\", \"rna\", \"ion\", \"peptide\", \"sm\"]\n",
    "\n",
    "#Features table\n",
    "features_all = pd.read_csv(input_path+filename, sep='\\t', index_col=0)\n",
    "#Features columns names, without the labels (the binding scores)\n",
    "features_cols = get_features_cols(features_all)\n",
    "remove_unimportant_features(features_all, features_cols)\n",
    "\n",
    "print \"all samples positions #: \"+str(features_all.shape[0])\n",
    "\n",
    "#CV splits dictionary\n",
    "# with open(curr_dir[0]+\"/CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_\"+str(prec_th)+\"_prec_dict.pik\", 'rb') as handle:\n",
    "#         splits_dict = pickle.load(handle)\n",
    "with open(curr_dir[0]+\"/../CV_splits/pfam-v\"+pfam_version+\"/domain_\"+str(folds_num)+\"_folds_combined_dna0.5_rna0.25_ion0.75_prec_dict.pik\", 'rb') as handle:\n",
    "        splits_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna non-binding #:43886\n",
      "dnabase non-binding #:44418\n",
      "dnabackbone non-binding #:44021\n",
      "dna combined non binding #: 43884\n",
      "rna non-binding #:43727\n",
      "rnabase non-binding #:44154\n",
      "rnabackbone non-binding #:43944\n",
      "rna combined non binding #: 43720\n",
      "peptide non-binding #:41105\n",
      "ion non-binding #:39630\n",
      "metabolite non-binding #:39638\n",
      "druglike non-binding #:35018\n",
      "sm non-binding #:32697\n"
     ]
    }
   ],
   "source": [
    "ligands_negatives_df = create_negatives_datasets_combined(zero_prop, no_prop, features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets of positive examples by ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna #: 369\n",
      "dnabase #: 161\n",
      "dnabackbone #: 245\n",
      "dna combined #: 397\n",
      "rna #: 450\n",
      "rnabase #: 290\n",
      "rnabackbone #: 306\n",
      "rna combined #: 531\n",
      "peptide #: 436\n",
      "ion #: 351\n",
      "metabolite #: 522\n",
      "druglike #: 763\n",
      "sm #: 825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anat/anaconda2/lib/python2.7/site-packages/pandas/core/frame.py:1997: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"DataFrame index.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "ligands_positives_df = create_positives_datasets_combined(features_all, features_cols, all_ligands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of positive examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ligands pos#: 2322\n"
     ]
    }
   ],
   "source": [
    "all_ligands_positives_df = pd.concat([ligands_positives_df[\"dna\"], ligands_positives_df[\"rna\"], ligands_positives_df[\"ion\"], ligands_positives_df[\"peptide\"], ligands_positives_df[\"sm\"]])                                    \n",
    "all_ligands_positives_df = all_ligands_positives_df.drop_duplicates()\n",
    "print \"all_ligands pos#: \"+str(all_ligands_positives_df.shape[0])\n",
    "ligands_positives_df[\"all_ligands\"] = all_ligands_positives_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of negative examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ligands neg#: 44855\n"
     ]
    }
   ],
   "source": [
    "all_ligands_negatives_df = pd.concat([ligands_negatives_df[\"dna\"], ligands_negatives_df[\"rna\"], ligands_negatives_df[\"ion\"], ligands_negatives_df[\"peptide\"], ligands_negatives_df[\"sm\"]])                                    \n",
    "all_ligands_negatives_df = all_ligands_negatives_df.drop_duplicates()\n",
    "print \"all_ligands neg#: \"+str(all_ligands_negatives_df.shape[0])\n",
    "ligands_negatives_df[\"all_ligands\"] = all_ligands_negatives_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of all positions examples examples - all ligands combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ligands #: 44855\n"
     ]
    }
   ],
   "source": [
    "all_positions_used_df = pd.concat([ligands_positives_df[\"all_ligands\"], ligands_negatives_df[\"all_ligands\"]])\n",
    "all_positions_used_df = all_positions_used_df.drop_duplicates()\n",
    "print \"all_ligands #: \"+str(all_ligands_negatives_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets of missing positions (for each ligand: positions that are in the training of other ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dna has 585 missing positions\n",
      "rna has 615 missing positions\n",
      "ion has 4885 missing positions\n",
      "peptide has 3325 missing positions\n",
      "sm has 11344 missing positions\n"
     ]
    }
   ],
   "source": [
    "ligands_missing_df = {}\n",
    "\n",
    "for ligand in ligands:\n",
    "    #All the ligand positions together\n",
    "    ligand_df = pd.concat([ligands_negatives_df[ligand],  ligands_positives_df[ligand]])\n",
    "    ligand_df = ligand_df.drop_duplicates()\n",
    "    \n",
    "    #Find indices of the missing positions\n",
    "    idx_diff = pd.Index.difference(all_positions_used_df.index, ligand_df.index)\n",
    "    \n",
    "    #Save a table with all the missing positions\n",
    "    ligands_missing_df[ligand] = all_positions_used_df.loc[idx_diff]\n",
    "    \n",
    "    print ligand+\" has \"+str(ligands_missing_df[ligand].shape[0])+\" missing positions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading env input for downsampler technique, ligand and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ligand = dna\n",
      "fold = 1\n",
      "classifier_method = ADA\n"
     ]
    }
   ],
   "source": [
    "#Reading the ligand input\n",
    "try:\n",
    "    ligand = environ['ligand']\n",
    "except:\n",
    "    ligand = \"dna\"\n",
    "print \"ligand = \"+ligand\n",
    "\n",
    "#Reading the downsampler input\n",
    "try: \n",
    "    fold = environ['fold']\n",
    "except:\n",
    "    fold = \"1\"\n",
    "print \"fold = \"+fold\n",
    "\n",
    "#Reading the classifier input\n",
    "try: \n",
    "    classifier_method = environ['classifier']\n",
    "except:\n",
    "    classifier_method = \"ADA\"\n",
    "print \"classifier_method = \"+classifier_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = len(features_cols)\n",
    "models_dict = generate_models_dict(ligand, ligands, ligands_positives_df, ligands_negatives_df, folds_num, no_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the missing positions, each time with a different folds training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_iterative_fixed(pred_dict, ligand_bind_features, ligand_negatives_features, ligand_missing_df, ligand_name, features=[]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test different models in 10-folds cross-validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Default: Exclude no features\n",
    "    if len(features) == 0:\n",
    "        features = np.ones([ligand_bind_features.shape[1],]).astype(bool)\n",
    "        \n",
    "    #Arranging the features table by the CV order, for each model\n",
    "    features_pred_dfs = dict.fromkeys(models_dict.keys())\n",
    "    \n",
    "    models_req_scaling = [\"SVM\", \"KNN\", \"Logistic\", \"NN\"]\n",
    "\n",
    "    classifier = classifier_method\n",
    "    features_pred_dfs[classifier] = pd.DataFrame()\n",
    "\n",
    "    #Create X and y with included features\n",
    "    X = pd.concat([ligand_bind_features.iloc[:,features], ligand_negatives_features.iloc[:,features]])\n",
    "    y = [1] * ligand_bind_features.shape[0]\n",
    "    y.extend([0] * ligand_negatives_features.shape[0])\n",
    "    y = np.array(y)\n",
    "    y_df = pd.DataFrame(y)\n",
    "    y_df.index = X.index\n",
    "    y_df.columns = [\"label\"]\n",
    "    \n",
    "    #Get the fold indices\n",
    "    cv_idx = calc_CV_idx_iterative(X, splits_dict)\n",
    "    k = (int(fold)-1)\n",
    "    \n",
    "    pred_idx = k+1\n",
    "    print \"fold #: \"+str(pred_idx)\n",
    "    test_index = cv_idx[k][\"test\"]\n",
    "    train_index = cv_idx[k][\"train\"]\n",
    "    X_train, X_test = X.loc[train_index,:], X.loc[test_index,:]\n",
    "    y_train, y_test = y_df.loc[train_index,:], y_df.loc[test_index,:]\n",
    "    \n",
    "    if (classifier in models_req_scaling):\n",
    "        cols = X_train.columns\n",
    "        scaler = StandardScaler() \n",
    "        #scale only using the training data\n",
    "        scaler.fit(X_train) \n",
    "        X_train = pd.DataFrame(scaler.transform(X_train))\n",
    "        # apply same transformation to test data\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test))\n",
    "        #Restoring indices after scaling\n",
    "        X_train.index = train_index \n",
    "        X_test.index = test_index \n",
    "        #Restoring features names\n",
    "        X_train.columns = cols\n",
    "        X_test.columns = cols\n",
    "\n",
    "    #No down-sampling\n",
    "    X_train_sampled = X_train\n",
    "    y_train_sampled = y_train\n",
    "\n",
    "    #fit to training data\n",
    "    model = models_dict[classifier][ligand][int(fold)]\n",
    "    \n",
    "    #pos and neg numbers in the training\n",
    "    no_pos = np.count_nonzero(y_train_sampled[\"label\"] == 1)\n",
    "    no_neg = np.count_nonzero(y_train_sampled[\"label\"] == 0)  \n",
    "    if classifier == \"NN\":     \n",
    "        #weight vector for NN\n",
    "        if model.weight == \"balanced\":              \n",
    "            #weight vector\n",
    "            neg_weight = float(no_pos) / float(no_neg + no_pos) \n",
    "            pos_weight = 1 - neg_weight\n",
    "        elif model.weight == \"0.1\":\n",
    "            neg_weight = 10\n",
    "            pos_weight = 1\n",
    "        elif model.weight == \"None\":\n",
    "            neg_weight = 1\n",
    "            pos_weight = 1\n",
    "\n",
    "        weight = torch.Tensor([neg_weight, pos_weight])\n",
    "        model.fit(X_train_sampled, y_train_sampled[\"label\"], weight)\n",
    "        probs_list = model.predict_proba(X_test)\n",
    "    \n",
    "    elif classifier == \"ADA\":\n",
    "        print \"fiting calibrated model\"\n",
    "        calib_model = CalibratedClassifierCV(base_estimator=model)\n",
    "        calib_model.fit(X_train_sampled, y_train_sampled[\"label\"])\n",
    "        probs_list = []\n",
    "        probs = calib_model.predict_proba(ligand_missing_df)\n",
    "        for l in probs:\n",
    "            probs_list.append(l[1])\n",
    "    else:\n",
    "        \n",
    "        model.fit(X_train_sampled, y_train_sampled[\"label\"])\n",
    "        probs_list = []\n",
    "        probs = model.predict_proba(ligand_missing_df)\n",
    "        for l in probs:\n",
    "            probs_list.append(l[1])\n",
    "\n",
    "    pred_dict[\"prob\"].extend(probs_list)\n",
    "    fold_list = [pred_idx] * len(probs_list)\n",
    "    pred_dict[\"fold\"].extend(fold_list)\n",
    "\n",
    "    model_list = [classifier] * len(probs_list)\n",
    "    pred_dict[\"model\"].extend(model_list)\n",
    "    \n",
    "    #Adding the position number to the table to help with analysis\n",
    "    pred_dict[\"idx\"].extend(ligand_missing_df.index)\n",
    "    \n",
    "    #Update features table\n",
    "    features_pred_dfs[classifier] = features_pred_dfs[classifier].append(ligand_missing_df)\n",
    "    pred_idx += 1\n",
    "\n",
    "    print \"Finished \"+ligand+\" \"+classifier+\" fold: \"+fold\n",
    "    \n",
    "    return (features_pred_dfs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features_predictions(ligand, ordered_features, pred_df):\n",
    "    \n",
    "    pred_res = pred_df.copy(deep=True)\n",
    "    for classifier in classifiers.keys():\n",
    "        classifier = classifier_method\n",
    "        model_pred = pred_res[pred_res[\"model\"] == classifier]\n",
    "        model_pred.index = ordered_features[classifier].index\n",
    "        \n",
    "        #Creating the combined table\n",
    "        features_pred = pd.concat([ordered_features[classifier], model_pred], axis=1)\n",
    "        \n",
    "        #Saving\n",
    "        features_pred.to_csv(curr_dir[0]+\"/between_1st_level_pred/features_pred_tables/\"+ligand+\"_\"+classifier+\"_features_pred.csv\", sep='\\t')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for each ligand seperatelly - every training set split will predict for the between labels data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold #: 1\n",
      "fiting calibrated model\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5d141d9098ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu'\\nligand = \"dna\"\\nfor fold in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\\n    pred_dict = defaultdict(list)\\n    downsample_method = \"NoDown\"\\n\\n    (ordered_features, model) = test_model_iterative_fixed(pred_dict, ligands_positives_df[ligand], ligands_negatives_df[ligand], ligands_missing_df[ligand], ligand)\\n\\n    pred_df = pd.DataFrame.from_dict(pred_dict)\\n\\n    #Save to file\\n    out_dirname = \"comb_dna0.5_rna0.25_ion0.75\"\\n\\n    pred_df.to_csv(curr_dir[0]+\"/missing_predictions/\"+datafile_date+\"_\"+out_dirname+\"/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_\"+str(folds_num)+\"w.csv\", sep=\\'\\\\t\\')\\n\\n    print \"Finished ligand \"+ligand'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/anat/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2118\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2119\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2120\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2121\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/anat/anaconda2/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anat/anaconda2/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1177\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-c164c290e69b>\u001b[0m in \u001b[0;36mtest_model_iterative_fixed\u001b[1;34m(pred_dict, ligand_bind_features, ligand_negatives_features, ligand_missing_df, ligand_name, features)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcalib_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_sampled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mprobs_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalib_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mligands_missing_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mprobs_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anat/anaconda2/lib/python2.7/site-packages/sklearn/calibration.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"classes_\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"calibrated_classifiers_\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         X = check_array(X, accept_sparse=['csc', 'csr', 'coo'],\n\u001b[1;32m--> 213\u001b[1;33m                         force_all_finite=False)\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;31m# Compute the arithmetic mean of the predictions of the calibrated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# classifiers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anat/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;31m# make sure we actually converted to numeric:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"O\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pred_dict = defaultdict(list)\n",
    "downsample_method = \"NoDown\"\n",
    "\n",
    "(ordered_features, model) = test_model_iterative_fixed(pred_dict, ligands_positives_df[ligand], ligands_negatives_df[ligand], ligands_missing_df[ligand], ligand)\n",
    "\n",
    "pred_df = pd.DataFrame.from_dict(pred_dict)\n",
    "\n",
    "#Save to file\n",
    "out_dirname = \"comb_dna0.5_rna0.25_ion0.75\"\n",
    "\n",
    "pred_df.to_csv(curr_dir[0]+\"/missing_predictions/\"+datafile_date+\"_\"+out_dirname+\"/per_fold/\"+ligand+\"_\"+classifier_method+\"_fold\"+fold+\"_\"+str(folds_num)+\"w.csv\", sep='\\t')\n",
    "\n",
    "print \"Finished ligand \"+ligand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(585, 753)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ligands_missing_df[ligand].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/anat/anaconda2/lib/python27.zip', '/home/anat/anaconda2/lib/python2.7', '/home/anat/anaconda2/lib/python2.7/plat-linux2', '/home/anat/anaconda2/lib/python2.7/lib-tk', '/home/anat/anaconda2/lib/python2.7/lib-old', '/home/anat/anaconda2/lib/python2.7/lib-dynload', '/home/anat/.local/lib/python2.7/site-packages', '/home/anat/anaconda2/lib/python2.7/site-packages', '/home/anat/anaconda2/lib/python2.7/site-packages/Sphinx-1.3.5-py2.7.egg', '/home/anat/anaconda2/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg', '/home/anat/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/anat/.ipython', '/home/anat/Research/ExAC/10.Prediction/stacking/../utils']\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
